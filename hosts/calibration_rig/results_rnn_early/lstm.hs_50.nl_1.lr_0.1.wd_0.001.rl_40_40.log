[2017-12-14 08:27:47] Experiment lstm.hs_50.nl_1.lr_0.1.wd_0.001.rl_40_40 logging started.
[2017-12-14 08:27:47] 
                       *** Starting Experiment lstm.hs_50.nl_1.lr_0.1.wd_0.001.rl_40_40 ***
                      
[2017-12-14 08:27:47] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 50  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.1  
                      [               num_epochs] 300  
                      [               num_layers] 1  
                      [        regression_layers] [40, 40]  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-14 08:27:47] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 50, batch_first=True)
                        (linear1): Linear (50 -> 40)
                        (linear2): Linear (40 -> 40)
                        (final): Linear (40 -> 1)
                      )
[2017-12-14 08:27:47]  *** Training on GPU ***
[2017-12-14 08:28:57] Epoch 0001 mean train/dev loss: 46574.4701 / 1176.1633
[2017-12-14 08:28:57] Checkpointing model...
[2017-12-14 08:28:57] Model Checkpointing finished.
[2017-12-14 08:30:07] Epoch 0002 mean train/dev loss: 711.4639 / 547.3237
[2017-12-14 08:30:07] Checkpointing model...
[2017-12-14 08:30:07] Model Checkpointing finished.
[2017-12-14 08:31:17] Epoch 0003 mean train/dev loss: 409.5713 / 769.7646
[2017-12-14 08:31:17] Checkpointing model...
[2017-12-14 08:31:18] Model Checkpointing finished.
[2017-12-14 08:32:28] Epoch 0004 mean train/dev loss: 408.8797 / 635.3604
[2017-12-14 08:32:28] Checkpointing model...
[2017-12-14 08:32:28] Model Checkpointing finished.
[2017-12-14 08:33:38] Epoch 0005 mean train/dev loss: 538.3438 / 519.4077
[2017-12-14 08:33:38] Checkpointing model...
[2017-12-14 08:33:38] Model Checkpointing finished.
[2017-12-14 08:34:49] Epoch 0006 mean train/dev loss: 401.2941 / 388.1670
[2017-12-14 08:35:59] Epoch 0007 mean train/dev loss: 334.4479 / 485.7792
[2017-12-14 08:37:09] Epoch 0008 mean train/dev loss: 366.2750 / 400.9638
[2017-12-14 08:38:19] Epoch 0009 mean train/dev loss: 471.9194 / 464.7586
[2017-12-14 08:39:29] Epoch 0010 mean train/dev loss: 305.4763 / 347.6521
[2017-12-14 08:39:29] Checkpointing model...
[2017-12-14 08:39:30] Model Checkpointing finished.
[2017-12-14 08:40:39] Epoch 0011 mean train/dev loss: 217.1974 / 254.5555
[2017-12-14 08:41:49] Epoch 0012 mean train/dev loss: 501.2677 / 529.3086
[2017-12-14 08:43:00] Epoch 0013 mean train/dev loss: 311.2271 / 455.6295
[2017-12-14 08:44:10] Epoch 0014 mean train/dev loss: 226.1625 / 289.0852
[2017-12-14 08:45:20] Epoch 0015 mean train/dev loss: 212.8693 / 548.5987
[2017-12-14 08:45:20] Learning rate decayed by 0.5000
[2017-12-14 08:45:20] Checkpointing model...
[2017-12-14 08:45:20] Model Checkpointing finished.
[2017-12-14 08:46:31] Epoch 0016 mean train/dev loss: 191.4748 / 171.9946
[2017-12-14 08:47:42] Epoch 0017 mean train/dev loss: 136.8050 / 133.4866
[2017-12-14 08:48:52] Epoch 0018 mean train/dev loss: 164.3820 / 160.4256
[2017-12-14 08:50:02] Epoch 0019 mean train/dev loss: 133.6157 / 134.9291
[2017-12-14 08:51:12] Epoch 0020 mean train/dev loss: 128.9884 / 140.0578
[2017-12-14 08:51:12] Checkpointing model...
[2017-12-14 08:51:13] Model Checkpointing finished.
[2017-12-14 08:52:23] Epoch 0021 mean train/dev loss: 145.5865 / 177.4531
[2017-12-14 08:53:33] Epoch 0022 mean train/dev loss: 158.5303 / 179.4951
[2017-12-14 08:54:43] Epoch 0023 mean train/dev loss: 159.0826 / 124.2752
[2017-12-14 08:55:53] Epoch 0024 mean train/dev loss: 139.8570 / 151.6084
[2017-12-14 08:57:03] Epoch 0025 mean train/dev loss: 130.5212 / 134.8613
[2017-12-14 08:57:03] Checkpointing model...
[2017-12-14 08:57:04] Model Checkpointing finished.
[2017-12-14 08:58:14] Epoch 0026 mean train/dev loss: 125.2480 / 118.0295
[2017-12-14 08:59:24] Epoch 0027 mean train/dev loss: 153.5160 / 138.4199
[2017-12-14 09:00:34] Epoch 0028 mean train/dev loss: 159.8816 / 134.1315
[2017-12-14 09:01:45] Epoch 0029 mean train/dev loss: 172.1784 / 160.0942
[2017-12-14 09:02:55] Epoch 0030 mean train/dev loss: 151.4040 / 120.7627
[2017-12-14 09:02:55] Learning rate decayed by 0.5000
[2017-12-14 09:02:55] Checkpointing model...
[2017-12-14 09:02:56] Model Checkpointing finished.
[2017-12-14 09:04:06] Epoch 0031 mean train/dev loss: 108.7448 / 134.8713
[2017-12-14 09:05:17] Epoch 0032 mean train/dev loss: 108.7480 / 118.4103
[2017-12-14 09:06:27] Epoch 0033 mean train/dev loss: 106.6021 / 112.2314
[2017-12-14 09:07:37] Epoch 0034 mean train/dev loss: 109.9941 / 153.5463
[2017-12-14 09:08:48] Epoch 0035 mean train/dev loss: 127.3551 / 110.1460
[2017-12-14 09:08:48] Checkpointing model...
[2017-12-14 09:08:48] Model Checkpointing finished.
[2017-12-14 09:09:58] Epoch 0036 mean train/dev loss: 109.1439 / 125.6338
[2017-12-14 09:11:08] Epoch 0037 mean train/dev loss: 112.3462 / 120.9254
[2017-12-14 09:12:19] Epoch 0038 mean train/dev loss: 104.1081 / 154.7164
[2017-12-14 09:13:29] Epoch 0039 mean train/dev loss: 123.8674 / 117.2921
[2017-12-14 09:14:40] Epoch 0040 mean train/dev loss: 114.9223 / 124.3586
[2017-12-14 09:14:40] Checkpointing model...
[2017-12-14 09:14:40] Model Checkpointing finished.
[2017-12-14 09:15:51] Epoch 0041 mean train/dev loss: 107.5421 / 105.0633
[2017-12-14 09:17:01] Epoch 0042 mean train/dev loss: 102.6463 / 111.0009
[2017-12-14 09:18:12] Epoch 0043 mean train/dev loss: 122.3847 / 142.2858
[2017-12-14 09:19:23] Epoch 0044 mean train/dev loss: 115.3321 / 132.9929
[2017-12-14 09:20:34] Epoch 0045 mean train/dev loss: 102.6689 / 131.7939
[2017-12-14 09:20:34] Learning rate decayed by 0.5000
[2017-12-14 09:20:34] Checkpointing model...
[2017-12-14 09:20:35] Model Checkpointing finished.
[2017-12-14 09:21:45] Epoch 0046 mean train/dev loss: 99.4320 / 109.3975
[2017-12-14 09:22:56] Epoch 0047 mean train/dev loss: 100.2027 / 101.8007
[2017-12-14 09:24:06] Epoch 0048 mean train/dev loss: 92.9501 / 102.1108
[2017-12-14 09:25:16] Epoch 0049 mean train/dev loss: 93.7694 / 111.8736
[2017-12-14 09:26:27] Epoch 0050 mean train/dev loss: 95.1651 / 106.1559
[2017-12-14 09:26:27] Checkpointing model...
[2017-12-14 09:26:27] Model Checkpointing finished.
[2017-12-14 09:27:37] Epoch 0051 mean train/dev loss: 95.3608 / 115.2831
[2017-12-14 09:28:48] Epoch 0052 mean train/dev loss: 97.8744 / 98.8695
[2017-12-14 09:29:58] Epoch 0053 mean train/dev loss: 98.1568 / 110.3448
[2017-12-14 09:31:08] Epoch 0054 mean train/dev loss: 106.4297 / 100.4983
[2017-12-14 09:32:18] Epoch 0055 mean train/dev loss: 105.6335 / 102.5512
[2017-12-14 09:32:18] Checkpointing model...
[2017-12-14 09:32:18] Model Checkpointing finished.
[2017-12-14 09:33:29] Epoch 0056 mean train/dev loss: 99.6074 / 105.1732
[2017-12-14 09:34:40] Epoch 0057 mean train/dev loss: 95.6716 / 101.7570
[2017-12-14 09:35:51] Epoch 0058 mean train/dev loss: 98.3538 / 102.3126
[2017-12-14 09:37:01] Epoch 0059 mean train/dev loss: 102.2483 / 114.4231
[2017-12-14 09:38:11] Epoch 0060 mean train/dev loss: 96.3592 / 122.4989
[2017-12-14 09:38:11] Learning rate decayed by 0.5000
[2017-12-14 09:38:11] Checkpointing model...
[2017-12-14 09:38:12] Model Checkpointing finished.
[2017-12-14 09:39:22] Epoch 0061 mean train/dev loss: 93.2222 / 98.3060
[2017-12-14 09:40:32] Epoch 0062 mean train/dev loss: 94.0116 / 101.3090
[2017-12-14 09:41:43] Epoch 0063 mean train/dev loss: 89.6873 / 100.5549
[2017-12-14 09:42:54] Epoch 0064 mean train/dev loss: 90.7300 / 97.9863
[2017-12-14 09:44:03] Epoch 0065 mean train/dev loss: 88.9433 / 102.0597
[2017-12-14 09:44:03] Checkpointing model...
[2017-12-14 09:44:04] Model Checkpointing finished.
[2017-12-14 09:45:14] Epoch 0066 mean train/dev loss: 88.3814 / 96.4569
[2017-12-14 09:46:24] Epoch 0067 mean train/dev loss: 88.3827 / 105.5034
[2017-12-14 09:47:35] Epoch 0068 mean train/dev loss: 88.0126 / 102.8898
[2017-12-14 09:48:46] Epoch 0069 mean train/dev loss: 90.4989 / 96.5618
[2017-12-14 09:49:57] Epoch 0070 mean train/dev loss: 87.7111 / 97.5371
[2017-12-14 09:49:57] Checkpointing model...
[2017-12-14 09:49:57] Model Checkpointing finished.
[2017-12-14 09:51:08] Epoch 0071 mean train/dev loss: 86.6844 / 97.7537
[2017-12-14 09:52:18] Epoch 0072 mean train/dev loss: 88.1816 / 105.6528
[2017-12-14 09:53:29] Epoch 0073 mean train/dev loss: 90.9510 / 96.8802
[2017-12-14 09:54:40] Epoch 0074 mean train/dev loss: 89.4351 / 94.5458
[2017-12-14 09:55:51] Epoch 0075 mean train/dev loss: 91.5792 / 112.5276
[2017-12-14 09:55:51] Learning rate decayed by 0.5000
[2017-12-14 09:55:51] Checkpointing model...
[2017-12-14 09:55:51] Model Checkpointing finished.
[2017-12-14 09:57:02] Epoch 0076 mean train/dev loss: 87.1458 / 100.8692
[2017-12-14 09:58:12] Epoch 0077 mean train/dev loss: 83.9559 / 100.3463
[2017-12-14 09:59:22] Epoch 0078 mean train/dev loss: 84.6826 / 92.5437
[2017-12-14 10:00:32] Epoch 0079 mean train/dev loss: 86.8563 / 104.8579
[2017-12-14 10:01:42] Epoch 0080 mean train/dev loss: 85.4972 / 100.5015
[2017-12-14 10:01:42] Checkpointing model...
[2017-12-14 10:01:42] Model Checkpointing finished.
[2017-12-14 10:02:53] Epoch 0081 mean train/dev loss: 82.6413 / 92.1167
[2017-12-14 10:04:03] Epoch 0082 mean train/dev loss: 84.1568 / 92.8083
[2017-12-14 10:05:13] Epoch 0083 mean train/dev loss: 84.8809 / 94.2297
[2017-12-14 10:06:24] Epoch 0084 mean train/dev loss: 88.0987 / 94.4515
[2017-12-14 10:07:35] Epoch 0085 mean train/dev loss: 82.9038 / 90.6587
[2017-12-14 10:07:35] Checkpointing model...
[2017-12-14 10:07:35] Model Checkpointing finished.
[2017-12-14 10:08:45] Epoch 0086 mean train/dev loss: 83.8170 / 93.4258
[2017-12-14 10:09:55] Epoch 0087 mean train/dev loss: 83.2839 / 94.7529
[2017-12-14 10:11:04] Epoch 0088 mean train/dev loss: 83.4119 / 95.7882
[2017-12-14 10:12:14] Epoch 0089 mean train/dev loss: 84.9274 / 99.0433
[2017-12-14 10:13:23] Epoch 0090 mean train/dev loss: 83.8884 / 94.7122
[2017-12-14 10:13:23] Learning rate decayed by 0.5000
[2017-12-14 10:13:23] Checkpointing model...
[2017-12-14 10:13:24] Model Checkpointing finished.
[2017-12-14 10:14:34] Epoch 0091 mean train/dev loss: 81.9549 / 95.3111
[2017-12-14 10:15:44] Epoch 0092 mean train/dev loss: 81.3405 / 104.7188
[2017-12-14 10:16:54] Epoch 0093 mean train/dev loss: 83.9683 / 96.5141
[2017-12-14 10:18:04] Epoch 0094 mean train/dev loss: 83.6168 / 96.4640
[2017-12-14 10:19:14] Epoch 0095 mean train/dev loss: 82.0661 / 95.4578
[2017-12-14 10:19:14] Checkpointing model...
[2017-12-14 10:19:14] Model Checkpointing finished.
[2017-12-14 10:20:25] Epoch 0096 mean train/dev loss: 80.5091 / 99.2510
[2017-12-14 10:21:35] Epoch 0097 mean train/dev loss: 82.6767 / 91.8413
[2017-12-14 10:22:45] Epoch 0098 mean train/dev loss: 82.8644 / 92.9746
[2017-12-14 10:23:55] Epoch 0099 mean train/dev loss: 80.6227 / 92.0053
[2017-12-14 10:25:05] Epoch 0100 mean train/dev loss: 81.6284 / 93.4472
[2017-12-14 10:25:05] Checkpointing model...
[2017-12-14 10:25:05] Model Checkpointing finished.
[2017-12-14 10:26:15] Epoch 0101 mean train/dev loss: 82.8116 / 95.3027
[2017-12-14 10:27:25] Epoch 0102 mean train/dev loss: 81.9952 / 92.0911
[2017-12-14 10:28:35] Epoch 0103 mean train/dev loss: 81.0391 / 89.5615
[2017-12-14 10:29:45] Epoch 0104 mean train/dev loss: 80.9186 / 92.5494
[2017-12-14 10:30:55] Epoch 0105 mean train/dev loss: 81.8977 / 90.9575
[2017-12-14 10:30:55] Learning rate decayed by 0.5000
[2017-12-14 10:30:55] Checkpointing model...
[2017-12-14 10:30:55] Model Checkpointing finished.
[2017-12-14 10:32:06] Epoch 0106 mean train/dev loss: 79.8345 / 97.0453
[2017-12-14 10:33:16] Epoch 0107 mean train/dev loss: 79.6329 / 96.6339
[2017-12-14 10:34:25] Epoch 0108 mean train/dev loss: 80.2783 / 94.6451
[2017-12-14 10:35:35] Epoch 0109 mean train/dev loss: 78.6491 / 94.5902
[2017-12-14 10:36:46] Epoch 0110 mean train/dev loss: 79.5118 / 91.6477
[2017-12-14 10:36:46] Checkpointing model...
[2017-12-14 10:36:46] Model Checkpointing finished.
[2017-12-14 10:37:56] Epoch 0111 mean train/dev loss: 78.8727 / 90.1303
[2017-12-14 10:39:06] Epoch 0112 mean train/dev loss: 78.9980 / 93.4145
[2017-12-14 10:40:16] Epoch 0113 mean train/dev loss: 79.0124 / 92.8242
[2017-12-14 10:41:26] Epoch 0114 mean train/dev loss: 79.9631 / 94.6997
[2017-12-14 10:42:36] Epoch 0115 mean train/dev loss: 79.7405 / 92.7995
[2017-12-14 10:42:36] Checkpointing model...
[2017-12-14 10:42:36] Model Checkpointing finished.
[2017-12-14 10:43:46] Epoch 0116 mean train/dev loss: 80.9306 / 93.2739
[2017-12-14 10:44:57] Epoch 0117 mean train/dev loss: 79.0920 / 91.4784
[2017-12-14 10:46:07] Epoch 0118 mean train/dev loss: 78.5608 / 89.6295
[2017-12-14 10:47:17] Epoch 0119 mean train/dev loss: 79.6382 / 91.2271
[2017-12-14 10:48:27] Epoch 0120 mean train/dev loss: 78.9424 / 90.3922
[2017-12-14 10:48:27] Learning rate decayed by 0.5000
[2017-12-14 10:48:27] Checkpointing model...
[2017-12-14 10:48:27] Model Checkpointing finished.
[2017-12-14 10:49:37] Epoch 0121 mean train/dev loss: 78.9534 / 91.6627
[2017-12-14 10:50:48] Epoch 0122 mean train/dev loss: 77.8158 / 93.6788
[2017-12-14 10:51:57] Epoch 0123 mean train/dev loss: 77.6069 / 93.1663
[2017-12-14 10:53:07] Epoch 0124 mean train/dev loss: 78.6621 / 91.5695
[2017-12-14 10:54:17] Epoch 0125 mean train/dev loss: 77.6462 / 90.3555
[2017-12-14 10:54:17] Checkpointing model...
[2017-12-14 10:54:18] Model Checkpointing finished.
[2017-12-14 10:55:28] Epoch 0126 mean train/dev loss: 77.8048 / 95.2711
[2017-12-14 10:56:38] Epoch 0127 mean train/dev loss: 77.9455 / 90.1663
[2017-12-14 10:57:48] Epoch 0128 mean train/dev loss: 78.1180 / 95.7361
[2017-12-14 10:58:57] Epoch 0129 mean train/dev loss: 77.6882 / 95.4884
[2017-12-14 11:00:07] Epoch 0130 mean train/dev loss: 78.0472 / 90.1875
[2017-12-14 11:00:07] Checkpointing model...
[2017-12-14 11:00:08] Model Checkpointing finished.
[2017-12-14 11:01:18] Epoch 0131 mean train/dev loss: 78.7291 / 93.3707
[2017-12-14 11:02:28] Epoch 0132 mean train/dev loss: 77.9960 / 91.5822
[2017-12-14 11:03:39] Epoch 0133 mean train/dev loss: 77.9496 / 92.6831
[2017-12-14 11:04:50] Epoch 0134 mean train/dev loss: 77.7479 / 93.1406
[2017-12-14 11:06:00] Epoch 0135 mean train/dev loss: 77.8844 / 90.8868
[2017-12-14 11:06:00] Learning rate decayed by 0.5000
[2017-12-14 11:06:00] Checkpointing model...
[2017-12-14 11:06:01] Model Checkpointing finished.
[2017-12-14 11:07:11] Epoch 0136 mean train/dev loss: 77.1685 / 88.9581
[2017-12-14 11:08:21] Epoch 0137 mean train/dev loss: 77.3206 / 92.3603
[2017-12-14 11:09:31] Epoch 0138 mean train/dev loss: 76.9480 / 93.0576
[2017-12-14 11:10:41] Epoch 0139 mean train/dev loss: 77.5376 / 89.8802
[2017-12-14 11:11:52] Epoch 0140 mean train/dev loss: 77.6125 / 88.7456
[2017-12-14 11:11:52] Checkpointing model...
[2017-12-14 11:11:52] Model Checkpointing finished.
[2017-12-14 11:13:03] Epoch 0141 mean train/dev loss: 77.4001 / 89.8155
[2017-12-14 11:14:13] Epoch 0142 mean train/dev loss: 77.3063 / 90.0361
[2017-12-14 11:15:24] Epoch 0143 mean train/dev loss: 77.2910 / 90.7161
[2017-12-14 11:16:34] Epoch 0144 mean train/dev loss: 77.0552 / 91.4485
[2017-12-14 11:17:45] Epoch 0145 mean train/dev loss: 76.8452 / 92.0316
[2017-12-14 11:17:45] Checkpointing model...
[2017-12-14 11:17:45] Model Checkpointing finished.
[2017-12-14 11:18:56] Epoch 0146 mean train/dev loss: 76.9426 / 91.8842
[2017-12-14 11:20:06] Epoch 0147 mean train/dev loss: 77.1626 / 89.5425
[2017-12-14 11:21:17] Epoch 0148 mean train/dev loss: 77.4178 / 90.9058
[2017-12-14 11:22:27] Epoch 0149 mean train/dev loss: 76.9341 / 90.2034
[2017-12-14 11:23:38] Epoch 0150 mean train/dev loss: 77.0160 / 89.5773
[2017-12-14 11:23:38] Learning rate decayed by 0.5000
[2017-12-14 11:23:38] Checkpointing model...
[2017-12-14 11:23:38] Model Checkpointing finished.
[2017-12-14 11:24:49] Epoch 0151 mean train/dev loss: 76.8276 / 93.9363
[2017-12-14 11:25:59] Epoch 0152 mean train/dev loss: 76.9104 / 93.5483
[2017-12-14 11:27:10] Epoch 0153 mean train/dev loss: 76.7349 / 91.3465
[2017-12-14 11:28:20] Epoch 0154 mean train/dev loss: 76.8024 / 91.2835
[2017-12-14 11:29:30] Epoch 0155 mean train/dev loss: 76.6131 / 90.5008
[2017-12-14 11:29:30] Checkpointing model...
[2017-12-14 11:29:31] Model Checkpointing finished.
[2017-12-14 11:30:41] Epoch 0156 mean train/dev loss: 76.6452 / 92.9855
[2017-12-14 11:31:51] Epoch 0157 mean train/dev loss: 76.5262 / 91.4507
[2017-12-14 11:33:01] Epoch 0158 mean train/dev loss: 76.7028 / 91.6576
[2017-12-14 11:34:12] Epoch 0159 mean train/dev loss: 76.6669 / 91.6807
[2017-12-14 11:35:22] Epoch 0160 mean train/dev loss: 76.7953 / 90.6109
[2017-12-14 11:35:22] Checkpointing model...
[2017-12-14 11:35:22] Model Checkpointing finished.
[2017-12-14 11:36:33] Epoch 0161 mean train/dev loss: 76.4772 / 91.2598
[2017-12-14 11:37:43] Epoch 0162 mean train/dev loss: 76.7712 / 91.1252
[2017-12-14 11:38:54] Epoch 0163 mean train/dev loss: 76.8593 / 91.5424
[2017-12-14 11:40:04] Epoch 0164 mean train/dev loss: 76.6560 / 92.5292
[2017-12-14 11:41:14] Epoch 0165 mean train/dev loss: 76.5711 / 89.7206
[2017-12-14 11:41:14] Learning rate decayed by 0.5000
[2017-12-14 11:41:14] Checkpointing model...
[2017-12-14 11:41:14] Model Checkpointing finished.
[2017-12-14 11:42:24] Epoch 0166 mean train/dev loss: 76.3670 / 91.4273
[2017-12-14 11:43:34] Epoch 0167 mean train/dev loss: 76.3537 / 91.8160
[2017-12-14 11:44:43] Epoch 0168 mean train/dev loss: 76.3207 / 91.4804
[2017-12-14 11:45:53] Epoch 0169 mean train/dev loss: 76.3727 / 91.3035
[2017-12-14 11:47:04] Epoch 0170 mean train/dev loss: 76.3511 / 90.2017
[2017-12-14 11:47:04] Checkpointing model...
[2017-12-14 11:47:05] Model Checkpointing finished.
[2017-12-14 11:48:14] Epoch 0171 mean train/dev loss: 76.3536 / 91.4022
[2017-12-14 11:49:23] Epoch 0172 mean train/dev loss: 76.4525 / 91.2529
[2017-12-14 11:50:32] Epoch 0173 mean train/dev loss: 76.4118 / 90.9228
[2017-12-14 11:51:42] Epoch 0174 mean train/dev loss: 76.2683 / 92.0147
[2017-12-14 11:52:52] Epoch 0175 mean train/dev loss: 76.4817 / 91.0650
[2017-12-14 11:52:52] Checkpointing model...
[2017-12-14 11:52:52] Model Checkpointing finished.
[2017-12-14 11:54:02] Epoch 0176 mean train/dev loss: 76.4286 / 91.3944
[2017-12-14 11:55:12] Epoch 0177 mean train/dev loss: 76.3558 / 90.9960
[2017-12-14 11:56:21] Epoch 0178 mean train/dev loss: 76.4417 / 91.8535
[2017-12-14 11:57:31] Epoch 0179 mean train/dev loss: 76.2913 / 90.6393
[2017-12-14 11:58:40] Epoch 0180 mean train/dev loss: 76.2270 / 91.7742
[2017-12-14 11:58:40] Learning rate decayed by 0.5000
[2017-12-14 11:58:40] Checkpointing model...
[2017-12-14 11:58:41] Model Checkpointing finished.
[2017-12-14 11:59:48] Epoch 0181 mean train/dev loss: 76.3583 / 91.4944
[2017-12-14 11:59:48] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-14 11:59:48] 
                       *** Training finished *** 
[2017-12-14 11:59:55] Dev MSE: 91.4944
[2017-12-14 12:00:54] Training MSE: 76.1578
[2017-12-14 12:00:56] Experiment lstm.hs_50.nl_1.lr_0.1.wd_0.001.rl_40_40 logging ended.
