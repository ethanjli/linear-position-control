[2017-12-14 15:35:51] Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40 logging started.
[2017-12-14 15:35:51] 
                       *** Starting Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40 ***
                      
[2017-12-14 15:35:51] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 20  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.1  
                      [               num_epochs] 300  
                      [               num_layers] 1  
                      [        regression_layers] [40]  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-14 15:35:54] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 20, batch_first=True)
                        (linear1): Linear (20 -> 40)
                        (final): Linear (40 -> 1)
                      )
[2017-12-14 15:35:54]  *** Training on GPU ***
[2017-12-14 15:36:55] Epoch 0001 mean train/dev loss: 88615.0538 / 10672.3174
[2017-12-14 15:36:55] Checkpointing model...
[2017-12-14 15:36:56] Model Checkpointing finished.
[2017-12-14 15:37:58] Epoch 0002 mean train/dev loss: 9480.1334 / 4703.2471
[2017-12-14 15:37:58] Checkpointing model...
[2017-12-14 15:37:58] Model Checkpointing finished.
[2017-12-14 15:38:59] Epoch 0003 mean train/dev loss: 2023.8592 / 1271.8956
[2017-12-14 15:38:59] Checkpointing model...
[2017-12-14 15:38:59] Model Checkpointing finished.
[2017-12-14 15:40:01] Epoch 0004 mean train/dev loss: 713.7770 / 703.2433
[2017-12-14 15:40:01] Checkpointing model...
[2017-12-14 15:40:02] Model Checkpointing finished.
[2017-12-14 15:41:00] Epoch 0005 mean train/dev loss: 553.3118 / 639.4272
[2017-12-14 15:41:00] Checkpointing model...
[2017-12-14 15:41:00] Model Checkpointing finished.
[2017-12-14 15:41:59] Epoch 0006 mean train/dev loss: 411.3389 / 506.7439
[2017-12-14 15:43:02] Epoch 0007 mean train/dev loss: 304.7860 / 530.5530
[2017-12-14 15:44:05] Epoch 0008 mean train/dev loss: 278.4602 / 362.6561
[2017-12-14 15:45:03] Epoch 0009 mean train/dev loss: 204.4863 / 287.8523
[2017-12-14 15:46:04] Epoch 0010 mean train/dev loss: 205.7269 / 345.3890
[2017-12-14 15:46:04] Checkpointing model...
[2017-12-14 15:46:04] Model Checkpointing finished.
[2017-12-14 15:47:07] Epoch 0011 mean train/dev loss: 270.8608 / 430.6603
[2017-12-14 15:48:07] Epoch 0012 mean train/dev loss: 200.6075 / 257.0392
[2017-12-14 15:49:11] Epoch 0013 mean train/dev loss: 191.3265 / 223.8175
[2017-12-14 15:50:12] Epoch 0014 mean train/dev loss: 172.2345 / 244.6792
[2017-12-14 15:51:13] Epoch 0015 mean train/dev loss: 176.6642 / 229.8534
[2017-12-14 15:51:13] Learning rate decayed by 0.5000
[2017-12-14 15:51:13] Checkpointing model...
[2017-12-14 15:51:13] Model Checkpointing finished.
[2017-12-14 15:52:14] Epoch 0016 mean train/dev loss: 160.6821 / 249.9545
[2017-12-14 15:53:12] Epoch 0017 mean train/dev loss: 139.3427 / 209.5617
[2017-12-14 15:54:14] Epoch 0018 mean train/dev loss: 135.4164 / 218.1299
[2017-12-14 15:55:15] Epoch 0019 mean train/dev loss: 138.1905 / 219.5875
[2017-12-14 15:56:16] Epoch 0020 mean train/dev loss: 135.3698 / 196.9132
[2017-12-14 15:56:16] Checkpointing model...
[2017-12-14 15:56:16] Model Checkpointing finished.
[2017-12-14 15:57:18] Epoch 0021 mean train/dev loss: 132.5010 / 178.5756
[2017-12-14 15:58:20] Epoch 0022 mean train/dev loss: 128.8414 / 192.1714
[2017-12-14 15:59:21] Epoch 0023 mean train/dev loss: 128.4919 / 199.4829
[2017-12-14 16:00:23] Epoch 0024 mean train/dev loss: 130.6775 / 169.0825
[2017-12-14 16:01:26] Epoch 0025 mean train/dev loss: 153.4811 / 184.4243
[2017-12-14 16:01:26] Checkpointing model...
[2017-12-14 16:01:26] Model Checkpointing finished.
[2017-12-14 16:02:31] Epoch 0026 mean train/dev loss: 124.3881 / 186.6224
[2017-12-14 16:03:36] Epoch 0027 mean train/dev loss: 135.0286 / 162.7767
[2017-12-14 16:04:38] Epoch 0028 mean train/dev loss: 122.9518 / 174.5836
[2017-12-14 16:05:43] Epoch 0029 mean train/dev loss: 146.9926 / 200.1432
[2017-12-14 16:06:47] Epoch 0030 mean train/dev loss: 132.0816 / 198.9473
[2017-12-14 16:06:47] Learning rate decayed by 0.5000
[2017-12-14 16:06:47] Checkpointing model...
[2017-12-14 16:06:48] Model Checkpointing finished.
[2017-12-14 16:07:51] Epoch 0031 mean train/dev loss: 115.4136 / 180.6754
[2017-12-14 16:08:53] Epoch 0032 mean train/dev loss: 117.9815 / 177.6157
[2017-12-14 16:09:55] Epoch 0033 mean train/dev loss: 118.6448 / 162.5289
[2017-12-14 16:10:59] Epoch 0034 mean train/dev loss: 107.9960 / 157.7245
[2017-12-14 16:12:01] Epoch 0035 mean train/dev loss: 106.3641 / 159.2605
[2017-12-14 16:12:01] Checkpointing model...
[2017-12-14 16:12:01] Model Checkpointing finished.
[2017-12-14 16:13:06] Epoch 0036 mean train/dev loss: 106.1994 / 159.4028
[2017-12-14 16:14:09] Epoch 0037 mean train/dev loss: 104.5527 / 153.1987
[2017-12-14 16:15:12] Epoch 0038 mean train/dev loss: 116.3156 / 152.7413
[2017-12-14 16:16:10] Epoch 0039 mean train/dev loss: 107.4988 / 146.2735
[2017-12-14 16:17:13] Epoch 0040 mean train/dev loss: 103.0759 / 151.7165
[2017-12-14 16:17:13] Checkpointing model...
[2017-12-14 16:17:13] Model Checkpointing finished.
[2017-12-14 16:18:15] Epoch 0041 mean train/dev loss: 99.1750 / 164.8213
[2017-12-14 16:19:20] Epoch 0042 mean train/dev loss: 108.8486 / 160.3122
[2017-12-14 16:20:20] Epoch 0043 mean train/dev loss: 107.5939 / 175.8323
[2017-12-14 16:21:22] Epoch 0044 mean train/dev loss: 115.4749 / 171.7701
[2017-12-14 16:22:25] Epoch 0045 mean train/dev loss: 110.2278 / 156.8772
[2017-12-14 16:22:25] Learning rate decayed by 0.5000
[2017-12-14 16:22:25] Checkpointing model...
[2017-12-14 16:22:25] Model Checkpointing finished.
[2017-12-14 16:23:29] Epoch 0046 mean train/dev loss: 98.3233 / 143.7698
[2017-12-14 16:24:32] Epoch 0047 mean train/dev loss: 97.3451 / 144.1900
[2017-12-14 16:25:35] Epoch 0048 mean train/dev loss: 98.4756 / 156.9664
[2017-12-14 16:26:38] Epoch 0049 mean train/dev loss: 95.7673 / 148.9635
[2017-12-14 16:27:38] Epoch 0050 mean train/dev loss: 93.9897 / 144.9053
[2017-12-14 16:27:38] Checkpointing model...
[2017-12-14 16:27:38] Model Checkpointing finished.
[2017-12-14 16:28:43] Epoch 0051 mean train/dev loss: 92.8996 / 155.2522
[2017-12-14 16:29:46] Epoch 0052 mean train/dev loss: 93.8360 / 144.4378
[2017-12-14 16:30:48] Epoch 0053 mean train/dev loss: 94.6933 / 149.8542
[2017-12-14 16:31:48] Epoch 0054 mean train/dev loss: 91.9128 / 144.3602
[2017-12-14 16:32:51] Epoch 0055 mean train/dev loss: 89.2040 / 152.5751
[2017-12-14 16:32:51] Checkpointing model...
[2017-12-14 16:32:51] Model Checkpointing finished.
[2017-12-14 16:33:51] Epoch 0056 mean train/dev loss: 91.5584 / 146.8982
[2017-12-14 16:34:52] Epoch 0057 mean train/dev loss: 93.5828 / 143.1619
[2017-12-14 16:35:52] Epoch 0058 mean train/dev loss: 90.5025 / 140.8431
[2017-12-14 16:36:55] Epoch 0059 mean train/dev loss: 87.3954 / 135.0559
[2017-12-14 16:37:56] Epoch 0060 mean train/dev loss: 85.7036 / 138.3333
[2017-12-14 16:37:56] Learning rate decayed by 0.5000
[2017-12-14 16:37:56] Checkpointing model...
[2017-12-14 16:37:57] Model Checkpointing finished.
[2017-12-14 16:38:57] Epoch 0061 mean train/dev loss: 88.4759 / 144.2650
[2017-12-14 16:39:58] Epoch 0062 mean train/dev loss: 86.6098 / 144.2762
[2017-12-14 16:40:59] Epoch 0063 mean train/dev loss: 85.0582 / 136.8510
[2017-12-14 16:41:59] Epoch 0064 mean train/dev loss: 82.9905 / 134.5571
[2017-12-14 16:43:00] Epoch 0065 mean train/dev loss: 85.4607 / 136.7754
[2017-12-14 16:43:00] Checkpointing model...
[2017-12-14 16:43:01] Model Checkpointing finished.
[2017-12-14 16:44:01] Epoch 0066 mean train/dev loss: 85.4871 / 130.7202
[2017-12-14 16:45:06] Epoch 0067 mean train/dev loss: 83.3898 / 131.1362
[2017-12-14 16:46:08] Epoch 0068 mean train/dev loss: 82.4772 / 129.0567
[2017-12-14 16:47:08] Epoch 0069 mean train/dev loss: 83.4115 / 134.1156
[2017-12-14 16:48:07] Epoch 0070 mean train/dev loss: 82.2878 / 126.7731
[2017-12-14 16:48:07] Checkpointing model...
[2017-12-14 16:48:07] Model Checkpointing finished.
[2017-12-14 16:49:08] Epoch 0071 mean train/dev loss: 83.0735 / 131.2838
[2017-12-14 16:50:08] Epoch 0072 mean train/dev loss: 82.2837 / 137.9482
[2017-12-14 16:51:09] Epoch 0073 mean train/dev loss: 83.0389 / 127.6093
[2017-12-14 16:52:11] Epoch 0074 mean train/dev loss: 82.8602 / 130.8461
[2017-12-14 16:53:14] Epoch 0075 mean train/dev loss: 83.2920 / 125.5922
[2017-12-14 16:53:14] Learning rate decayed by 0.5000
[2017-12-14 16:53:14] Checkpointing model...
[2017-12-14 16:53:15] Model Checkpointing finished.
[2017-12-14 16:54:16] Epoch 0076 mean train/dev loss: 79.2226 / 126.1432
[2017-12-14 16:55:17] Epoch 0077 mean train/dev loss: 79.5582 / 126.3917
[2017-12-14 16:56:15] Epoch 0078 mean train/dev loss: 80.1030 / 130.4239
[2017-12-14 16:57:16] Epoch 0079 mean train/dev loss: 79.0676 / 126.6833
[2017-12-14 16:58:16] Epoch 0080 mean train/dev loss: 78.6260 / 121.9300
[2017-12-14 16:58:16] Checkpointing model...
[2017-12-14 16:58:17] Model Checkpointing finished.
[2017-12-14 16:59:18] Epoch 0081 mean train/dev loss: 79.9464 / 125.0950
[2017-12-14 17:00:18] Epoch 0082 mean train/dev loss: 80.1878 / 128.5812
[2017-12-14 17:01:23] Epoch 0083 mean train/dev loss: 79.1608 / 124.3582
[2017-12-14 17:02:24] Epoch 0084 mean train/dev loss: 81.2861 / 127.8162
[2017-12-14 17:03:27] Epoch 0085 mean train/dev loss: 78.6810 / 128.9974
[2017-12-14 17:03:27] Checkpointing model...
[2017-12-14 17:03:27] Model Checkpointing finished.
[2017-12-14 17:04:31] Epoch 0086 mean train/dev loss: 80.3114 / 125.7677
[2017-12-14 17:05:32] Epoch 0087 mean train/dev loss: 78.5221 / 127.7472
[2017-12-14 17:06:34] Epoch 0088 mean train/dev loss: 79.3601 / 124.6416
[2017-12-14 17:07:36] Epoch 0089 mean train/dev loss: 77.5786 / 127.3869
[2017-12-14 17:08:39] Epoch 0090 mean train/dev loss: 78.1875 / 126.2603
[2017-12-14 17:08:39] Learning rate decayed by 0.5000
[2017-12-14 17:08:39] Checkpointing model...
[2017-12-14 17:08:39] Model Checkpointing finished.
[2017-12-14 17:09:39] Epoch 0091 mean train/dev loss: 77.6379 / 123.2655
[2017-12-14 17:10:42] Epoch 0092 mean train/dev loss: 77.3054 / 122.8867
[2017-12-14 17:11:42] Epoch 0093 mean train/dev loss: 76.0821 / 122.5858
[2017-12-14 17:12:41] Epoch 0094 mean train/dev loss: 76.4757 / 126.5641
[2017-12-14 17:13:40] Epoch 0095 mean train/dev loss: 76.0294 / 126.2063
[2017-12-14 17:13:40] Checkpointing model...
[2017-12-14 17:13:40] Model Checkpointing finished.
[2017-12-14 17:14:43] Epoch 0096 mean train/dev loss: 75.9331 / 128.8626
[2017-12-14 17:15:45] Epoch 0097 mean train/dev loss: 76.7870 / 125.5847
[2017-12-14 17:16:45] Epoch 0098 mean train/dev loss: 77.3023 / 124.2218
[2017-12-14 17:17:49] Epoch 0099 mean train/dev loss: 77.0075 / 133.6569
[2017-12-14 17:18:51] Epoch 0100 mean train/dev loss: 76.1051 / 123.0049
[2017-12-14 17:18:51] Checkpointing model...
[2017-12-14 17:18:51] Model Checkpointing finished.
[2017-12-14 17:19:54] Epoch 0101 mean train/dev loss: 76.4212 / 129.9722
[2017-12-14 17:20:56] Epoch 0102 mean train/dev loss: 76.1786 / 128.8674
[2017-12-14 17:21:58] Epoch 0103 mean train/dev loss: 76.4414 / 127.2005
[2017-12-14 17:22:59] Epoch 0104 mean train/dev loss: 76.3768 / 129.9217
[2017-12-14 17:24:01] Epoch 0105 mean train/dev loss: 75.7806 / 127.8038
[2017-12-14 17:24:01] Learning rate decayed by 0.5000
[2017-12-14 17:24:01] Checkpointing model...
[2017-12-14 17:24:02] Model Checkpointing finished.
[2017-12-14 17:25:02] Epoch 0106 mean train/dev loss: 75.6071 / 128.0919
[2017-12-14 17:26:02] Epoch 0107 mean train/dev loss: 75.2655 / 126.8614
[2017-12-14 17:27:03] Epoch 0108 mean train/dev loss: 74.7917 / 127.9541
[2017-12-14 17:28:04] Epoch 0109 mean train/dev loss: 74.4797 / 126.0902
[2017-12-14 17:29:06] Epoch 0110 mean train/dev loss: 74.7633 / 129.2845
[2017-12-14 17:29:06] Checkpointing model...
[2017-12-14 17:29:06] Model Checkpointing finished.
[2017-12-14 17:30:08] Epoch 0111 mean train/dev loss: 74.6493 / 125.5455
[2017-12-14 17:31:08] Epoch 0112 mean train/dev loss: 74.5171 / 128.5789
[2017-12-14 17:32:10] Epoch 0113 mean train/dev loss: 74.5572 / 129.3281
[2017-12-14 17:33:11] Epoch 0114 mean train/dev loss: 74.6189 / 127.5667
[2017-12-14 17:34:09] Epoch 0115 mean train/dev loss: 74.9482 / 129.6729
[2017-12-14 17:34:09] Checkpointing model...
[2017-12-14 17:34:10] Model Checkpointing finished.
[2017-12-14 17:35:13] Epoch 0116 mean train/dev loss: 74.5057 / 128.8711
[2017-12-14 17:36:13] Epoch 0117 mean train/dev loss: 74.3198 / 127.2926
[2017-12-14 17:37:14] Epoch 0118 mean train/dev loss: 74.1125 / 128.0361
[2017-12-14 17:38:17] Epoch 0119 mean train/dev loss: 74.2134 / 128.8820
[2017-12-14 17:39:15] Epoch 0120 mean train/dev loss: 74.0925 / 126.7858
[2017-12-14 17:39:15] Learning rate decayed by 0.5000
[2017-12-14 17:39:15] Checkpointing model...
[2017-12-14 17:39:15] Model Checkpointing finished.
[2017-12-14 17:40:18] Epoch 0121 mean train/dev loss: 74.1927 / 127.1164
[2017-12-14 17:40:18] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-14 17:40:18] 
                       *** Training finished *** 
[2017-12-14 17:40:24] Dev MSE: 127.1164
[2017-12-14 17:41:15] Training MSE: 73.6403
[2017-12-14 17:41:17] Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40 logging ended.
