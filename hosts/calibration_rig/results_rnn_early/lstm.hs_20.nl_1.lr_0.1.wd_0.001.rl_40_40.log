[2017-12-14 15:35:51] Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40_40 logging started.
[2017-12-14 15:35:51] 
                       *** Starting Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40_40 ***
                      
[2017-12-14 15:35:51] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 20  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.1  
                      [               num_epochs] 300  
                      [               num_layers] 1  
                      [        regression_layers] [40, 40]  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-14 15:35:54] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 20, batch_first=True)
                        (linear1): Linear (20 -> 40)
                        (linear2): Linear (40 -> 40)
                        (final): Linear (40 -> 1)
                      )
[2017-12-14 15:35:54]  *** Training on GPU ***
[2017-12-14 15:36:53] Epoch 0001 mean train/dev loss: 68043.7250 / 15396.4824
[2017-12-14 15:36:53] Checkpointing model...
[2017-12-14 15:36:54] Model Checkpointing finished.
[2017-12-14 15:37:55] Epoch 0002 mean train/dev loss: 7954.7797 / 2923.3926
[2017-12-14 15:37:55] Checkpointing model...
[2017-12-14 15:37:56] Model Checkpointing finished.
[2017-12-14 15:38:56] Epoch 0003 mean train/dev loss: 1631.4422 / 1184.1626
[2017-12-14 15:38:56] Checkpointing model...
[2017-12-14 15:38:56] Model Checkpointing finished.
[2017-12-14 15:39:59] Epoch 0004 mean train/dev loss: 806.3629 / 803.9022
[2017-12-14 15:39:59] Checkpointing model...
[2017-12-14 15:39:59] Model Checkpointing finished.
[2017-12-14 15:41:03] Epoch 0005 mean train/dev loss: 546.0906 / 572.9072
[2017-12-14 15:41:03] Checkpointing model...
[2017-12-14 15:41:03] Model Checkpointing finished.
[2017-12-14 15:42:06] Epoch 0006 mean train/dev loss: 467.8568 / 893.3294
[2017-12-14 15:43:02] Epoch 0007 mean train/dev loss: 475.4486 / 403.5182
[2017-12-14 15:44:02] Epoch 0008 mean train/dev loss: 438.1957 / 542.1092
[2017-12-14 15:45:04] Epoch 0009 mean train/dev loss: 421.7169 / 466.2151
[2017-12-14 15:46:06] Epoch 0010 mean train/dev loss: 508.6618 / 380.2972
[2017-12-14 15:46:06] Checkpointing model...
[2017-12-14 15:46:06] Model Checkpointing finished.
[2017-12-14 15:47:09] Epoch 0011 mean train/dev loss: 366.3777 / 454.2157
[2017-12-14 15:48:12] Epoch 0012 mean train/dev loss: 272.3434 / 595.7586
[2017-12-14 15:49:16] Epoch 0013 mean train/dev loss: 278.4020 / 224.0585
[2017-12-14 15:50:18] Epoch 0014 mean train/dev loss: 272.9046 / 222.1519
[2017-12-14 15:51:19] Epoch 0015 mean train/dev loss: 272.4661 / 219.2077
[2017-12-14 15:51:19] Learning rate decayed by 0.5000
[2017-12-14 15:51:19] Checkpointing model...
[2017-12-14 15:51:19] Model Checkpointing finished.
[2017-12-14 15:52:18] Epoch 0016 mean train/dev loss: 192.6820 / 195.4419
[2017-12-14 15:53:22] Epoch 0017 mean train/dev loss: 156.2320 / 175.5530
[2017-12-14 15:54:26] Epoch 0018 mean train/dev loss: 166.5698 / 170.3027
[2017-12-14 15:55:29] Epoch 0019 mean train/dev loss: 157.6973 / 223.7461
[2017-12-14 15:56:30] Epoch 0020 mean train/dev loss: 156.2713 / 173.8717
[2017-12-14 15:56:30] Checkpointing model...
[2017-12-14 15:56:31] Model Checkpointing finished.
[2017-12-14 15:57:33] Epoch 0021 mean train/dev loss: 150.3276 / 156.9440
[2017-12-14 15:58:37] Epoch 0022 mean train/dev loss: 136.9565 / 146.7083
[2017-12-14 15:59:38] Epoch 0023 mean train/dev loss: 153.9661 / 161.8894
[2017-12-14 16:00:38] Epoch 0024 mean train/dev loss: 134.3686 / 158.6033
[2017-12-14 16:01:41] Epoch 0025 mean train/dev loss: 195.1118 / 232.9888
[2017-12-14 16:01:41] Checkpointing model...
[2017-12-14 16:01:41] Model Checkpointing finished.
[2017-12-14 16:02:43] Epoch 0026 mean train/dev loss: 265.7751 / 175.3581
[2017-12-14 16:03:47] Epoch 0027 mean train/dev loss: 159.8508 / 151.6564
[2017-12-14 16:04:50] Epoch 0028 mean train/dev loss: 162.8497 / 161.9915
[2017-12-14 16:05:51] Epoch 0029 mean train/dev loss: 152.0416 / 137.8502
[2017-12-14 16:06:53] Epoch 0030 mean train/dev loss: 143.4829 / 178.2221
[2017-12-14 16:06:53] Learning rate decayed by 0.5000
[2017-12-14 16:06:53] Checkpointing model...
[2017-12-14 16:06:53] Model Checkpointing finished.
[2017-12-14 16:07:55] Epoch 0031 mean train/dev loss: 131.3885 / 140.5386
[2017-12-14 16:08:56] Epoch 0032 mean train/dev loss: 132.6525 / 129.5392
[2017-12-14 16:09:57] Epoch 0033 mean train/dev loss: 120.7517 / 127.4185
[2017-12-14 16:11:00] Epoch 0034 mean train/dev loss: 129.8065 / 124.7378
[2017-12-14 16:12:02] Epoch 0035 mean train/dev loss: 126.5867 / 119.8582
[2017-12-14 16:12:02] Checkpointing model...
[2017-12-14 16:12:03] Model Checkpointing finished.
[2017-12-14 16:13:04] Epoch 0036 mean train/dev loss: 121.5729 / 142.0095
[2017-12-14 16:14:05] Epoch 0037 mean train/dev loss: 116.0413 / 134.5116
[2017-12-14 16:15:05] Epoch 0038 mean train/dev loss: 116.8062 / 112.7423
[2017-12-14 16:16:07] Epoch 0039 mean train/dev loss: 115.1600 / 113.0029
[2017-12-14 16:17:06] Epoch 0040 mean train/dev loss: 119.1789 / 116.6367
[2017-12-14 16:17:06] Checkpointing model...
[2017-12-14 16:17:06] Model Checkpointing finished.
[2017-12-14 16:18:08] Epoch 0041 mean train/dev loss: 107.5516 / 125.6730
[2017-12-14 16:19:08] Epoch 0042 mean train/dev loss: 122.9725 / 106.3193
[2017-12-14 16:20:10] Epoch 0043 mean train/dev loss: 111.4839 / 120.1808
[2017-12-14 16:21:13] Epoch 0044 mean train/dev loss: 102.8747 / 130.1438
[2017-12-14 16:22:15] Epoch 0045 mean train/dev loss: 97.7832 / 116.7710
[2017-12-14 16:22:15] Learning rate decayed by 0.5000
[2017-12-14 16:22:15] Checkpointing model...
[2017-12-14 16:22:16] Model Checkpointing finished.
[2017-12-14 16:23:19] Epoch 0046 mean train/dev loss: 97.4292 / 107.6535
[2017-12-14 16:24:21] Epoch 0047 mean train/dev loss: 95.4129 / 116.6768
[2017-12-14 16:25:21] Epoch 0048 mean train/dev loss: 97.3441 / 101.3744
[2017-12-14 16:26:18] Epoch 0049 mean train/dev loss: 96.3616 / 105.4130
[2017-12-14 16:27:20] Epoch 0050 mean train/dev loss: 91.4268 / 104.7138
[2017-12-14 16:27:20] Checkpointing model...
[2017-12-14 16:27:20] Model Checkpointing finished.
[2017-12-14 16:28:19] Epoch 0051 mean train/dev loss: 94.1487 / 109.3217
[2017-12-14 16:29:24] Epoch 0052 mean train/dev loss: 93.8770 / 117.9184
[2017-12-14 16:30:26] Epoch 0053 mean train/dev loss: 90.5938 / 97.3028
[2017-12-14 16:31:27] Epoch 0054 mean train/dev loss: 89.7304 / 111.2007
[2017-12-14 16:32:29] Epoch 0055 mean train/dev loss: 93.9904 / 112.4051
[2017-12-14 16:32:29] Checkpointing model...
[2017-12-14 16:32:29] Model Checkpointing finished.
[2017-12-14 16:33:30] Epoch 0056 mean train/dev loss: 93.8869 / 113.8701
[2017-12-14 16:34:32] Epoch 0057 mean train/dev loss: 101.6024 / 101.6015
[2017-12-14 16:35:33] Epoch 0058 mean train/dev loss: 88.8627 / 112.1279
[2017-12-14 16:36:35] Epoch 0059 mean train/dev loss: 94.9806 / 100.0524
[2017-12-14 16:37:39] Epoch 0060 mean train/dev loss: 92.3935 / 110.7495
[2017-12-14 16:37:39] Learning rate decayed by 0.5000
[2017-12-14 16:37:39] Checkpointing model...
[2017-12-14 16:37:39] Model Checkpointing finished.
[2017-12-14 16:38:40] Epoch 0061 mean train/dev loss: 83.5305 / 92.6123
[2017-12-14 16:39:44] Epoch 0062 mean train/dev loss: 82.9533 / 97.5056
[2017-12-14 16:40:43] Epoch 0063 mean train/dev loss: 84.5471 / 109.7697
[2017-12-14 16:41:45] Epoch 0064 mean train/dev loss: 83.0442 / 95.8807
[2017-12-14 16:42:48] Epoch 0065 mean train/dev loss: 81.8030 / 96.8932
[2017-12-14 16:42:48] Checkpointing model...
[2017-12-14 16:42:49] Model Checkpointing finished.
[2017-12-14 16:43:50] Epoch 0066 mean train/dev loss: 88.6774 / 105.4329
[2017-12-14 16:44:48] Epoch 0067 mean train/dev loss: 84.1757 / 95.8465
[2017-12-14 16:45:49] Epoch 0068 mean train/dev loss: 86.6093 / 102.3347
[2017-12-14 16:46:56] Epoch 0069 mean train/dev loss: 84.0814 / 102.4263
[2017-12-14 16:48:01] Epoch 0070 mean train/dev loss: 80.3520 / 98.6050
[2017-12-14 16:48:01] Checkpointing model...
[2017-12-14 16:48:01] Model Checkpointing finished.
[2017-12-14 16:49:01] Epoch 0071 mean train/dev loss: 84.7773 / 98.9952
[2017-12-14 16:50:02] Epoch 0072 mean train/dev loss: 85.4105 / 104.1060
[2017-12-14 16:51:04] Epoch 0073 mean train/dev loss: 80.7394 / 93.2574
[2017-12-14 16:52:04] Epoch 0074 mean train/dev loss: 80.9497 / 99.5238
[2017-12-14 16:53:02] Epoch 0075 mean train/dev loss: 87.2566 / 105.0076
[2017-12-14 16:53:02] Learning rate decayed by 0.5000
[2017-12-14 16:53:02] Checkpointing model...
[2017-12-14 16:53:02] Model Checkpointing finished.
[2017-12-14 16:54:02] Epoch 0076 mean train/dev loss: 78.3806 / 91.9523
[2017-12-14 16:55:06] Epoch 0077 mean train/dev loss: 76.4452 / 92.0853
[2017-12-14 16:56:08] Epoch 0078 mean train/dev loss: 80.4329 / 95.8461
[2017-12-14 16:57:10] Epoch 0079 mean train/dev loss: 79.0614 / 95.7497
[2017-12-14 16:58:12] Epoch 0080 mean train/dev loss: 76.8344 / 96.4468
[2017-12-14 16:58:12] Checkpointing model...
[2017-12-14 16:58:12] Model Checkpointing finished.
[2017-12-14 16:59:15] Epoch 0081 mean train/dev loss: 77.6185 / 92.4354
[2017-12-14 17:00:20] Epoch 0082 mean train/dev loss: 77.4650 / 97.1910
[2017-12-14 17:01:22] Epoch 0083 mean train/dev loss: 78.1996 / 91.8215
[2017-12-14 17:02:23] Epoch 0084 mean train/dev loss: 78.0883 / 95.2659
[2017-12-14 17:03:24] Epoch 0085 mean train/dev loss: 77.8218 / 105.1845
[2017-12-14 17:03:24] Checkpointing model...
[2017-12-14 17:03:25] Model Checkpointing finished.
[2017-12-14 17:04:26] Epoch 0086 mean train/dev loss: 78.1549 / 94.1388
[2017-12-14 17:05:28] Epoch 0087 mean train/dev loss: 77.2928 / 92.5921
[2017-12-14 17:06:30] Epoch 0088 mean train/dev loss: 75.7312 / 96.1742
[2017-12-14 17:07:31] Epoch 0089 mean train/dev loss: 81.8252 / 90.7847
[2017-12-14 17:08:30] Epoch 0090 mean train/dev loss: 75.5068 / 93.4721
[2017-12-14 17:08:30] Learning rate decayed by 0.5000
[2017-12-14 17:08:30] Checkpointing model...
[2017-12-14 17:08:30] Model Checkpointing finished.
[2017-12-14 17:09:31] Epoch 0091 mean train/dev loss: 75.2835 / 92.4461
[2017-12-14 17:10:32] Epoch 0092 mean train/dev loss: 73.8328 / 94.7829
[2017-12-14 17:11:33] Epoch 0093 mean train/dev loss: 75.5742 / 95.9000
[2017-12-14 17:12:35] Epoch 0094 mean train/dev loss: 74.4051 / 94.9615
[2017-12-14 17:13:37] Epoch 0095 mean train/dev loss: 74.0513 / 100.5798
[2017-12-14 17:13:37] Checkpointing model...
[2017-12-14 17:13:37] Model Checkpointing finished.
[2017-12-14 17:14:41] Epoch 0096 mean train/dev loss: 74.9388 / 93.4299
[2017-12-14 17:15:45] Epoch 0097 mean train/dev loss: 73.7593 / 91.6233
[2017-12-14 17:16:46] Epoch 0098 mean train/dev loss: 73.8390 / 92.3210
[2017-12-14 17:17:48] Epoch 0099 mean train/dev loss: 73.8017 / 91.9013
[2017-12-14 17:18:51] Epoch 0100 mean train/dev loss: 73.5699 / 98.3331
[2017-12-14 17:18:51] Checkpointing model...
[2017-12-14 17:18:51] Model Checkpointing finished.
[2017-12-14 17:19:51] Epoch 0101 mean train/dev loss: 73.7937 / 92.0836
[2017-12-14 17:20:53] Epoch 0102 mean train/dev loss: 72.7607 / 91.8456
[2017-12-14 17:21:55] Epoch 0103 mean train/dev loss: 72.7521 / 91.7881
[2017-12-14 17:22:56] Epoch 0104 mean train/dev loss: 73.6045 / 93.1076
[2017-12-14 17:23:56] Epoch 0105 mean train/dev loss: 72.6316 / 93.1442
[2017-12-14 17:23:56] Learning rate decayed by 0.5000
[2017-12-14 17:23:56] Checkpointing model...
[2017-12-14 17:23:56] Model Checkpointing finished.
[2017-12-14 17:24:59] Epoch 0106 mean train/dev loss: 72.7602 / 91.0874
[2017-12-14 17:26:00] Epoch 0107 mean train/dev loss: 72.5827 / 92.7889
[2017-12-14 17:27:02] Epoch 0108 mean train/dev loss: 72.0071 / 92.7307
[2017-12-14 17:28:05] Epoch 0109 mean train/dev loss: 72.0807 / 91.0269
[2017-12-14 17:29:07] Epoch 0110 mean train/dev loss: 71.6772 / 94.1028
[2017-12-14 17:29:07] Checkpointing model...
[2017-12-14 17:29:07] Model Checkpointing finished.
[2017-12-14 17:30:09] Epoch 0111 mean train/dev loss: 72.2747 / 92.2209
[2017-12-14 17:31:08] Epoch 0112 mean train/dev loss: 71.7444 / 91.4023
[2017-12-14 17:32:12] Epoch 0113 mean train/dev loss: 71.6898 / 90.5389
[2017-12-14 17:33:18] Epoch 0114 mean train/dev loss: 71.7848 / 93.8752
[2017-12-14 17:34:17] Epoch 0115 mean train/dev loss: 72.3788 / 91.4162
[2017-12-14 17:34:17] Checkpointing model...
[2017-12-14 17:34:17] Model Checkpointing finished.
[2017-12-14 17:35:18] Epoch 0116 mean train/dev loss: 72.2250 / 90.7533
[2017-12-14 17:36:19] Epoch 0117 mean train/dev loss: 71.3177 / 90.6268
[2017-12-14 17:37:23] Epoch 0118 mean train/dev loss: 71.5521 / 90.4900
[2017-12-14 17:38:24] Epoch 0119 mean train/dev loss: 71.5986 / 92.9546
[2017-12-14 17:39:28] Epoch 0120 mean train/dev loss: 71.7908 / 92.5427
[2017-12-14 17:39:28] Learning rate decayed by 0.5000
[2017-12-14 17:39:28] Checkpointing model...
[2017-12-14 17:39:28] Model Checkpointing finished.
[2017-12-14 17:40:28] Epoch 0121 mean train/dev loss: 71.1239 / 90.6016
[2017-12-14 17:41:32] Epoch 0122 mean train/dev loss: 70.5927 / 91.0459
[2017-12-14 17:42:35] Epoch 0123 mean train/dev loss: 70.7979 / 91.4630
[2017-12-14 17:43:33] Epoch 0124 mean train/dev loss: 70.6978 / 90.9805
[2017-12-14 17:44:35] Epoch 0125 mean train/dev loss: 70.7044 / 91.3216
[2017-12-14 17:44:35] Checkpointing model...
[2017-12-14 17:44:35] Model Checkpointing finished.
[2017-12-14 17:45:36] Epoch 0126 mean train/dev loss: 70.7255 / 91.3850
[2017-12-14 17:46:38] Epoch 0127 mean train/dev loss: 70.4869 / 90.8298
[2017-12-14 17:47:39] Epoch 0128 mean train/dev loss: 70.0731 / 90.9599
[2017-12-14 17:48:42] Epoch 0129 mean train/dev loss: 70.6762 / 90.8918
[2017-12-14 17:49:41] Epoch 0130 mean train/dev loss: 70.8872 / 92.6870
[2017-12-14 17:49:41] Checkpointing model...
[2017-12-14 17:49:42] Model Checkpointing finished.
[2017-12-14 17:50:40] Epoch 0131 mean train/dev loss: 70.6840 / 90.8552
[2017-12-14 17:51:42] Epoch 0132 mean train/dev loss: 70.8387 / 90.6677
[2017-12-14 17:52:40] Epoch 0133 mean train/dev loss: 70.8449 / 90.4981
[2017-12-14 17:53:40] Epoch 0134 mean train/dev loss: 70.6138 / 90.4830
[2017-12-14 17:54:41] Epoch 0135 mean train/dev loss: 70.5174 / 90.5380
[2017-12-14 17:54:41] Learning rate decayed by 0.5000
[2017-12-14 17:54:41] Checkpointing model...
[2017-12-14 17:54:41] Model Checkpointing finished.
[2017-12-14 17:55:40] Epoch 0136 mean train/dev loss: 69.9734 / 91.4614
[2017-12-14 17:56:41] Epoch 0137 mean train/dev loss: 69.9072 / 89.5399
[2017-12-14 17:57:41] Epoch 0138 mean train/dev loss: 70.0760 / 90.8100
[2017-12-14 17:58:39] Epoch 0139 mean train/dev loss: 69.8942 / 90.6592
[2017-12-14 17:59:39] Epoch 0140 mean train/dev loss: 69.8908 / 92.1043
[2017-12-14 17:59:39] Checkpointing model...
[2017-12-14 17:59:39] Model Checkpointing finished.
[2017-12-14 18:00:40] Epoch 0141 mean train/dev loss: 70.4119 / 91.9557
[2017-12-14 18:01:43] Epoch 0142 mean train/dev loss: 70.2034 / 90.4753
[2017-12-14 18:02:43] Epoch 0143 mean train/dev loss: 69.8991 / 91.0088
[2017-12-14 18:03:43] Epoch 0144 mean train/dev loss: 69.8005 / 90.3142
[2017-12-14 18:04:44] Epoch 0145 mean train/dev loss: 69.9045 / 89.9071
[2017-12-14 18:04:44] Checkpointing model...
[2017-12-14 18:04:45] Model Checkpointing finished.
[2017-12-14 18:05:46] Epoch 0146 mean train/dev loss: 70.2377 / 90.5674
[2017-12-14 18:06:45] Epoch 0147 mean train/dev loss: 69.6284 / 90.8149
[2017-12-14 18:07:46] Epoch 0148 mean train/dev loss: 69.7926 / 91.1328
[2017-12-14 18:08:46] Epoch 0149 mean train/dev loss: 69.9451 / 90.1618
[2017-12-14 18:09:49] Epoch 0150 mean train/dev loss: 70.0878 / 90.7239
[2017-12-14 18:09:49] Learning rate decayed by 0.5000
[2017-12-14 18:09:49] Checkpointing model...
[2017-12-14 18:09:49] Model Checkpointing finished.
[2017-12-14 18:10:52] Epoch 0151 mean train/dev loss: 69.7193 / 90.8223
[2017-12-14 18:11:53] Epoch 0152 mean train/dev loss: 69.5038 / 90.2557
[2017-12-14 18:12:54] Epoch 0153 mean train/dev loss: 69.5944 / 90.8606
[2017-12-14 18:13:55] Epoch 0154 mean train/dev loss: 69.5396 / 90.3710
[2017-12-14 18:14:59] Epoch 0155 mean train/dev loss: 69.4938 / 90.7240
[2017-12-14 18:14:59] Checkpointing model...
[2017-12-14 18:14:59] Model Checkpointing finished.
[2017-12-14 18:16:00] Epoch 0156 mean train/dev loss: 69.5962 / 90.8691
[2017-12-14 18:17:02] Epoch 0157 mean train/dev loss: 69.9230 / 90.2492
[2017-12-14 18:18:05] Epoch 0158 mean train/dev loss: 69.4093 / 90.6431
[2017-12-14 18:19:07] Epoch 0159 mean train/dev loss: 69.5262 / 90.8477
[2017-12-14 18:20:08] Epoch 0160 mean train/dev loss: 69.3996 / 90.6225
[2017-12-14 18:20:08] Checkpointing model...
[2017-12-14 18:20:09] Model Checkpointing finished.
[2017-12-14 18:21:14] Epoch 0161 mean train/dev loss: 69.3727 / 90.2226
[2017-12-14 18:22:18] Epoch 0162 mean train/dev loss: 69.5418 / 90.0745
[2017-12-14 18:23:20] Epoch 0163 mean train/dev loss: 69.3568 / 90.4197
[2017-12-14 18:24:19] Epoch 0164 mean train/dev loss: 69.4483 / 90.4061
[2017-12-14 18:25:22] Epoch 0165 mean train/dev loss: 69.2577 / 90.8120
[2017-12-14 18:25:22] Learning rate decayed by 0.5000
[2017-12-14 18:25:22] Checkpointing model...
[2017-12-14 18:25:23] Model Checkpointing finished.
[2017-12-14 18:26:23] Epoch 0166 mean train/dev loss: 69.2853 / 90.3594
[2017-12-14 18:27:27] Epoch 0167 mean train/dev loss: 69.4107 / 90.3733
[2017-12-14 18:28:29] Epoch 0168 mean train/dev loss: 69.1545 / 90.3248
[2017-12-14 18:29:31] Epoch 0169 mean train/dev loss: 69.4000 / 90.5010
[2017-12-14 18:30:34] Epoch 0170 mean train/dev loss: 69.2230 / 90.2102
[2017-12-14 18:30:34] Checkpointing model...
[2017-12-14 18:30:34] Model Checkpointing finished.
[2017-12-14 18:31:39] Epoch 0171 mean train/dev loss: 69.3584 / 90.1509
[2017-12-14 18:32:39] Epoch 0172 mean train/dev loss: 69.1932 / 90.3559
[2017-12-14 18:33:43] Epoch 0173 mean train/dev loss: 69.3534 / 90.0725
[2017-12-14 18:34:44] Epoch 0174 mean train/dev loss: 69.2186 / 90.4199
[2017-12-14 18:35:45] Epoch 0175 mean train/dev loss: 69.2025 / 90.1302
[2017-12-14 18:35:45] Checkpointing model...
[2017-12-14 18:35:45] Model Checkpointing finished.
[2017-12-14 18:36:47] Epoch 0176 mean train/dev loss: 69.2441 / 90.3333
[2017-12-14 18:37:48] Epoch 0177 mean train/dev loss: 69.2181 / 90.6386
[2017-12-14 18:38:52] Epoch 0178 mean train/dev loss: 69.0779 / 90.2873
[2017-12-14 18:38:52] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-14 18:38:52] 
                       *** Training finished *** 
[2017-12-14 18:38:57] Dev MSE: 90.2873
[2017-12-14 18:39:48] Training MSE: 69.0732
[2017-12-14 18:39:51] Experiment lstm.hs_20.nl_1.lr_0.1.wd_0.001.rl_40_40 logging ended.
