[2017-12-14 17:41:17] Experiment lstm.hs_50.nl_1.lr_0.01.wd_0.001.rl_linear logging started.
[2017-12-14 17:41:17] 
                       *** Starting Experiment lstm.hs_50.nl_1.lr_0.01.wd_0.001.rl_linear ***
                      
[2017-12-14 17:41:17] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 50  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.01  
                      [               num_epochs] 300  
                      [               num_layers] 1  
                      [        regression_layers] None  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-14 17:41:17] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 50, batch_first=True)
                        (final): Linear (50 -> 1)
                      )
[2017-12-14 17:41:17]  *** Training on GPU ***
[2017-12-14 17:42:20] Epoch 0001 mean train/dev loss: 318535.8986 / 307316.9062
[2017-12-14 17:42:20] Checkpointing model...
[2017-12-14 17:42:20] Model Checkpointing finished.
[2017-12-14 17:43:24] Epoch 0002 mean train/dev loss: 293015.5376 / 283594.7500
[2017-12-14 17:43:24] Checkpointing model...
[2017-12-14 17:43:24] Model Checkpointing finished.
[2017-12-14 17:44:27] Epoch 0003 mean train/dev loss: 269724.3434 / 261539.8594
[2017-12-14 17:44:27] Checkpointing model...
[2017-12-14 17:44:28] Model Checkpointing finished.
[2017-12-14 17:45:31] Epoch 0004 mean train/dev loss: 248979.4936 / 241693.5000
[2017-12-14 17:45:31] Checkpointing model...
[2017-12-14 17:45:31] Model Checkpointing finished.
[2017-12-14 17:46:34] Epoch 0005 mean train/dev loss: 230100.9783 / 223583.0156
[2017-12-14 17:46:34] Checkpointing model...
[2017-12-14 17:46:34] Model Checkpointing finished.
[2017-12-14 17:47:38] Epoch 0006 mean train/dev loss: 213332.1805 / 206984.4375
[2017-12-14 17:48:40] Epoch 0007 mean train/dev loss: 196933.2034 / 191715.6875
[2017-12-14 17:49:45] Epoch 0008 mean train/dev loss: 181575.2779 / 178832.8438
[2017-12-14 17:50:45] Epoch 0009 mean train/dev loss: 168820.0293 / 165099.0156
[2017-12-14 17:51:46] Epoch 0010 mean train/dev loss: 155927.0022 / 152964.4531
[2017-12-14 17:51:46] Checkpointing model...
[2017-12-14 17:51:46] Model Checkpointing finished.
[2017-12-14 17:52:49] Epoch 0011 mean train/dev loss: 144799.2746 / 141960.8438
[2017-12-14 17:53:50] Epoch 0012 mean train/dev loss: 134323.1744 / 132649.4062
[2017-12-14 17:54:51] Epoch 0013 mean train/dev loss: 125328.0928 / 122994.0781
[2017-12-14 17:55:52] Epoch 0014 mean train/dev loss: 115834.7977 / 114369.9297
[2017-12-14 17:56:54] Epoch 0015 mean train/dev loss: 107789.7468 / 106695.1094
[2017-12-14 17:56:54] Learning rate decayed by 0.5000
[2017-12-14 17:56:54] Checkpointing model...
[2017-12-14 17:56:54] Model Checkpointing finished.
[2017-12-14 17:57:56] Epoch 0016 mean train/dev loss: 102276.6896 / 102835.4297
[2017-12-14 17:58:54] Epoch 0017 mean train/dev loss: 98247.6030 / 98815.2812
[2017-12-14 17:59:57] Epoch 0018 mean train/dev loss: 95225.6614 / 96212.9688
[2017-12-14 18:00:57] Epoch 0019 mean train/dev loss: 91933.2038 / 92439.0234
[2017-12-14 18:01:58] Epoch 0020 mean train/dev loss: 87997.2787 / 88726.1484
[2017-12-14 18:01:58] Checkpointing model...
[2017-12-14 18:01:59] Model Checkpointing finished.
[2017-12-14 18:02:59] Epoch 0021 mean train/dev loss: 84395.6081 / 84533.4453
[2017-12-14 18:04:00] Epoch 0022 mean train/dev loss: 80022.7647 / 80783.0156
[2017-12-14 18:05:01] Epoch 0023 mean train/dev loss: 76671.3445 / 77420.3047
[2017-12-14 18:06:04] Epoch 0024 mean train/dev loss: 73459.4254 / 74247.3203
[2017-12-14 18:07:06] Epoch 0025 mean train/dev loss: 70399.1214 / 71233.6484
[2017-12-14 18:07:06] Checkpointing model...
[2017-12-14 18:07:07] Model Checkpointing finished.
[2017-12-14 18:08:07] Epoch 0026 mean train/dev loss: 67462.9801 / 68305.4766
[2017-12-14 18:09:09] Epoch 0027 mean train/dev loss: 64669.9338 / 65532.4492
[2017-12-14 18:10:12] Epoch 0028 mean train/dev loss: 62217.6724 / 62910.8203
[2017-12-14 18:11:14] Epoch 0029 mean train/dev loss: 59365.8096 / 60316.0039
[2017-12-14 18:12:14] Epoch 0030 mean train/dev loss: 57057.3724 / 57704.8594
[2017-12-14 18:12:14] Learning rate decayed by 0.5000
[2017-12-14 18:12:14] Checkpointing model...
[2017-12-14 18:12:14] Model Checkpointing finished.
[2017-12-14 18:13:15] Epoch 0031 mean train/dev loss: 54901.3386 / 56451.8750
[2017-12-14 18:14:18] Epoch 0032 mean train/dev loss: 53862.4316 / 55230.4961
[2017-12-14 18:15:21] Epoch 0033 mean train/dev loss: 52620.7328 / 54016.2930
[2017-12-14 18:16:24] Epoch 0034 mean train/dev loss: 51656.4035 / 52807.8477
[2017-12-14 18:17:29] Epoch 0035 mean train/dev loss: 50270.0231 / 51627.3828
[2017-12-14 18:17:29] Checkpointing model...
[2017-12-14 18:17:29] Model Checkpointing finished.
[2017-12-14 18:18:32] Epoch 0036 mean train/dev loss: 49097.6031 / 50470.0898
[2017-12-14 18:19:28] Epoch 0037 mean train/dev loss: 48088.6216 / 49310.8281
[2017-12-14 18:20:29] Epoch 0038 mean train/dev loss: 46945.5924 / 48171.8945
[2017-12-14 18:21:30] Epoch 0039 mean train/dev loss: 45791.6849 / 47049.7695
[2017-12-14 18:22:30] Epoch 0040 mean train/dev loss: 44801.3160 / 45955.6367
[2017-12-14 18:22:30] Checkpointing model...
[2017-12-14 18:22:30] Model Checkpointing finished.
[2017-12-14 18:23:33] Epoch 0041 mean train/dev loss: 43748.3512 / 44859.8906
[2017-12-14 18:24:37] Epoch 0042 mean train/dev loss: 42558.8444 / 43789.1367
[2017-12-14 18:25:38] Epoch 0043 mean train/dev loss: 41519.5312 / 42741.4766
[2017-12-14 18:26:41] Epoch 0044 mean train/dev loss: 40648.8905 / 41694.7812
[2017-12-14 18:27:43] Epoch 0045 mean train/dev loss: 39577.0492 / 40688.8281
[2017-12-14 18:27:43] Learning rate decayed by 0.5000
[2017-12-14 18:27:43] Checkpointing model...
[2017-12-14 18:27:44] Model Checkpointing finished.
[2017-12-14 18:28:49] Epoch 0046 mean train/dev loss: 38791.8292 / 40172.8203
[2017-12-14 18:29:53] Epoch 0047 mean train/dev loss: 38261.1749 / 39706.7656
[2017-12-14 18:30:57] Epoch 0048 mean train/dev loss: 37865.3356 / 39164.7578
[2017-12-14 18:31:59] Epoch 0049 mean train/dev loss: 37337.6719 / 38672.0352
[2017-12-14 18:33:03] Epoch 0050 mean train/dev loss: 36929.7869 / 38172.0859
[2017-12-14 18:33:03] Checkpointing model...
[2017-12-14 18:33:03] Model Checkpointing finished.
[2017-12-14 18:34:07] Epoch 0051 mean train/dev loss: 36445.9534 / 37659.4844
[2017-12-14 18:35:08] Epoch 0052 mean train/dev loss: 35857.8906 / 37184.9883
[2017-12-14 18:36:11] Epoch 0053 mean train/dev loss: 35410.0727 / 36686.0508
[2017-12-14 18:37:16] Epoch 0054 mean train/dev loss: 34899.3906 / 36188.8789
[2017-12-14 18:38:18] Epoch 0055 mean train/dev loss: 34466.6093 / 35693.6367
[2017-12-14 18:38:18] Checkpointing model...
[2017-12-14 18:38:18] Model Checkpointing finished.
[2017-12-14 18:39:22] Epoch 0056 mean train/dev loss: 33958.8332 / 35202.1719
[2017-12-14 18:40:24] Epoch 0057 mean train/dev loss: 33479.6366 / 34724.4414
[2017-12-14 18:41:25] Epoch 0058 mean train/dev loss: 33048.5675 / 34247.6289
[2017-12-14 18:42:29] Epoch 0059 mean train/dev loss: 32709.8115 / 33754.4922
[2017-12-14 18:43:30] Epoch 0060 mean train/dev loss: 32190.3449 / 33287.5977
[2017-12-14 18:43:30] Learning rate decayed by 0.5000
[2017-12-14 18:43:30] Checkpointing model...
[2017-12-14 18:43:31] Model Checkpointing finished.
[2017-12-14 18:44:33] Epoch 0061 mean train/dev loss: 31822.2875 / 33047.0742
[2017-12-14 18:45:36] Epoch 0062 mean train/dev loss: 31490.7048 / 32799.9805
[2017-12-14 18:46:38] Epoch 0063 mean train/dev loss: 31239.2272 / 32562.1953
[2017-12-14 18:47:42] Epoch 0064 mean train/dev loss: 31072.0961 / 32323.5332
[2017-12-14 18:48:45] Epoch 0065 mean train/dev loss: 30861.2327 / 32079.5039
[2017-12-14 18:48:45] Checkpointing model...
[2017-12-14 18:48:45] Model Checkpointing finished.
[2017-12-14 18:49:45] Epoch 0066 mean train/dev loss: 30683.7796 / 31842.2539
[2017-12-14 18:50:46] Epoch 0067 mean train/dev loss: 30328.6978 / 31604.9199
[2017-12-14 18:51:46] Epoch 0068 mean train/dev loss: 30241.1309 / 31353.4395
[2017-12-14 18:52:45] Epoch 0069 mean train/dev loss: 29739.0615 / 31111.6895
[2017-12-14 18:53:49] Epoch 0070 mean train/dev loss: 29745.1103 / 30878.3438
[2017-12-14 18:53:49] Checkpointing model...
[2017-12-14 18:53:50] Model Checkpointing finished.
[2017-12-14 18:54:51] Epoch 0071 mean train/dev loss: 29499.4822 / 30628.7344
[2017-12-14 18:55:51] Epoch 0072 mean train/dev loss: 29312.9337 / 30504.5098
[2017-12-14 18:56:54] Epoch 0073 mean train/dev loss: 29010.3938 / 30162.1914
[2017-12-14 18:57:53] Epoch 0074 mean train/dev loss: 28743.3672 / 29914.5820
[2017-12-14 18:58:56] Epoch 0075 mean train/dev loss: 28639.7679 / 29669.2461
[2017-12-14 18:58:56] Learning rate decayed by 0.5000
[2017-12-14 18:58:56] Checkpointing model...
[2017-12-14 18:58:56] Model Checkpointing finished.
[2017-12-14 18:59:54] Epoch 0076 mean train/dev loss: 28305.6555 / 29541.5469
[2017-12-14 19:00:55] Epoch 0077 mean train/dev loss: 28218.0089 / 29420.0078
[2017-12-14 19:01:59] Epoch 0078 mean train/dev loss: 28127.1508 / 29292.0898
[2017-12-14 19:03:01] Epoch 0079 mean train/dev loss: 27991.5417 / 29172.9590
[2017-12-14 19:04:02] Epoch 0080 mean train/dev loss: 27857.8302 / 29051.1895
[2017-12-14 19:04:02] Checkpointing model...
[2017-12-14 19:04:03] Model Checkpointing finished.
[2017-12-14 19:05:03] Epoch 0081 mean train/dev loss: 27745.3884 / 28923.0547
[2017-12-14 19:06:04] Epoch 0082 mean train/dev loss: 27594.9551 / 28799.8379
[2017-12-14 19:07:04] Epoch 0083 mean train/dev loss: 27560.9123 / 28676.5176
[2017-12-14 19:08:07] Epoch 0084 mean train/dev loss: 27395.6240 / 28549.4707
[2017-12-14 19:09:07] Epoch 0085 mean train/dev loss: 27226.4062 / 28424.6523
[2017-12-14 19:09:07] Checkpointing model...
[2017-12-14 19:09:07] Model Checkpointing finished.
[2017-12-14 19:10:11] Epoch 0086 mean train/dev loss: 27055.1888 / 28301.8418
[2017-12-14 19:11:11] Epoch 0087 mean train/dev loss: 26969.4998 / 28181.2305
[2017-12-14 19:12:13] Epoch 0088 mean train/dev loss: 26867.1662 / 28053.9395
[2017-12-14 19:13:16] Epoch 0089 mean train/dev loss: 26777.5356 / 27927.7383
[2017-12-14 19:14:20] Epoch 0090 mean train/dev loss: 26720.4935 / 27798.8496
[2017-12-14 19:14:20] Learning rate decayed by 0.5000
[2017-12-14 19:14:20] Checkpointing model...
[2017-12-14 19:14:20] Model Checkpointing finished.
[2017-12-14 19:15:21] Epoch 0091 mean train/dev loss: 26602.5367 / 27736.4414
[2017-12-14 19:16:25] Epoch 0092 mean train/dev loss: 26526.2862 / 27673.6309
[2017-12-14 19:17:32] Epoch 0093 mean train/dev loss: 26363.5686 / 27606.3828
[2017-12-14 19:18:37] Epoch 0094 mean train/dev loss: 26374.7699 / 27543.2539
[2017-12-14 19:19:43] Epoch 0095 mean train/dev loss: 26284.1534 / 27481.3730
[2017-12-14 19:19:43] Checkpointing model...
[2017-12-14 19:19:43] Model Checkpointing finished.
[2017-12-14 19:20:50] Epoch 0096 mean train/dev loss: 26138.0928 / 27418.3516
[2017-12-14 19:22:00] Epoch 0097 mean train/dev loss: 26116.4969 / 27352.1230
[2017-12-14 19:23:07] Epoch 0098 mean train/dev loss: 26195.8578 / 27288.9258
[2017-12-14 19:24:19] Epoch 0099 mean train/dev loss: 26001.7479 / 27219.5059
[2017-12-14 19:25:28] Epoch 0100 mean train/dev loss: 25958.4864 / 27159.5820
[2017-12-14 19:25:28] Checkpointing model...
[2017-12-14 19:25:29] Model Checkpointing finished.
[2017-12-14 19:26:37] Epoch 0101 mean train/dev loss: 25938.0965 / 27095.3301
[2017-12-14 19:27:42] Epoch 0102 mean train/dev loss: 25868.4393 / 27028.0293
[2017-12-14 19:28:52] Epoch 0103 mean train/dev loss: 25783.0922 / 26963.1367
[2017-12-14 19:30:01] Epoch 0104 mean train/dev loss: 25679.5692 / 26895.6152
[2017-12-14 19:31:05] Epoch 0105 mean train/dev loss: 25628.4591 / 26830.0059
[2017-12-14 19:31:05] Learning rate decayed by 0.5000
[2017-12-14 19:31:05] Checkpointing model...
[2017-12-14 19:31:05] Model Checkpointing finished.
[2017-12-14 19:32:11] Epoch 0106 mean train/dev loss: 25648.0637 / 26797.5703
[2017-12-14 19:33:17] Epoch 0107 mean train/dev loss: 25577.9323 / 26764.6152
[2017-12-14 19:34:22] Epoch 0108 mean train/dev loss: 25524.3725 / 26731.8926
[2017-12-14 19:35:27] Epoch 0109 mean train/dev loss: 25564.0387 / 26699.4023
[2017-12-14 19:36:32] Epoch 0110 mean train/dev loss: 25536.6772 / 26665.7500
[2017-12-14 19:36:32] Checkpointing model...
[2017-12-14 19:36:33] Model Checkpointing finished.
[2017-12-14 19:37:40] Epoch 0111 mean train/dev loss: 25479.7191 / 26631.8672
[2017-12-14 19:38:41] Epoch 0112 mean train/dev loss: 25510.2973 / 26599.1035
[2017-12-14 19:39:42] Epoch 0113 mean train/dev loss: 25468.2559 / 26563.0566
[2017-12-14 19:40:44] Epoch 0114 mean train/dev loss: 25381.5965 / 26533.0977
[2017-12-14 19:41:48] Epoch 0115 mean train/dev loss: 25425.6817 / 26498.8047
[2017-12-14 19:41:48] Checkpointing model...
[2017-12-14 19:41:48] Model Checkpointing finished.
[2017-12-14 19:42:50] Epoch 0116 mean train/dev loss: 25300.1205 / 26465.5898
[2017-12-14 19:43:53] Epoch 0117 mean train/dev loss: 25289.3159 / 26431.8301
[2017-12-14 19:44:58] Epoch 0118 mean train/dev loss: 25232.2323 / 26396.6465
[2017-12-14 19:46:00] Epoch 0119 mean train/dev loss: 25211.4542 / 26364.6621
[2017-12-14 19:47:03] Epoch 0120 mean train/dev loss: 25125.6205 / 26328.9785
[2017-12-14 19:47:03] Learning rate decayed by 0.5000
[2017-12-14 19:47:03] Checkpointing model...
[2017-12-14 19:47:04] Model Checkpointing finished.
[2017-12-14 19:48:07] Epoch 0121 mean train/dev loss: 25186.7596 / 26311.2500
[2017-12-14 19:49:12] Epoch 0122 mean train/dev loss: 25175.5535 / 26295.0410
[2017-12-14 19:50:13] Epoch 0123 mean train/dev loss: 25177.2683 / 26277.6523
[2017-12-14 19:51:19] Epoch 0124 mean train/dev loss: 25090.1737 / 26259.5977
[2017-12-14 19:52:18] Epoch 0125 mean train/dev loss: 25025.1075 / 26242.8848
[2017-12-14 19:52:18] Checkpointing model...
[2017-12-14 19:52:18] Model Checkpointing finished.
[2017-12-14 19:53:21] Epoch 0126 mean train/dev loss: 25086.3522 / 26225.8340
[2017-12-14 19:54:24] Epoch 0127 mean train/dev loss: 24974.2472 / 26214.3008
[2017-12-14 19:55:23] Epoch 0128 mean train/dev loss: 24997.8600 / 26193.2988
[2017-12-14 19:56:22] Epoch 0129 mean train/dev loss: 24961.7153 / 26175.7480
[2017-12-14 19:57:22] Epoch 0130 mean train/dev loss: 25034.8658 / 26158.9375
[2017-12-14 19:57:22] Checkpointing model...
[2017-12-14 19:57:22] Model Checkpointing finished.
[2017-12-14 19:58:25] Epoch 0131 mean train/dev loss: 25030.2130 / 26141.4570
[2017-12-14 19:59:26] Epoch 0132 mean train/dev loss: 24967.1764 / 26123.3398
[2017-12-14 20:00:30] Epoch 0133 mean train/dev loss: 25008.5135 / 26105.3379
[2017-12-14 20:01:30] Epoch 0134 mean train/dev loss: 24966.0695 / 26088.6992
[2017-12-14 20:02:32] Epoch 0135 mean train/dev loss: 24968.7349 / 26071.9512
[2017-12-14 20:02:32] Learning rate decayed by 0.5000
[2017-12-14 20:02:32] Checkpointing model...
[2017-12-14 20:02:32] Model Checkpointing finished.
[2017-12-14 20:03:33] Epoch 0136 mean train/dev loss: 24864.0577 / 26061.7598
[2017-12-14 20:04:34] Epoch 0137 mean train/dev loss: 24988.5931 / 26053.6504
[2017-12-14 20:05:36] Epoch 0138 mean train/dev loss: 24850.7573 / 26045.1348
[2017-12-14 20:06:38] Epoch 0139 mean train/dev loss: 24911.7079 / 26036.2227
[2017-12-14 20:07:41] Epoch 0140 mean train/dev loss: 24930.0696 / 26027.4941
[2017-12-14 20:07:41] Checkpointing model...
[2017-12-14 20:07:41] Model Checkpointing finished.
[2017-12-14 20:08:44] Epoch 0141 mean train/dev loss: 24896.8516 / 26018.8730
[2017-12-14 20:09:47] Epoch 0142 mean train/dev loss: 24870.7451 / 26010.0781
[2017-12-14 20:10:51] Epoch 0143 mean train/dev loss: 24846.9685 / 26001.3945
[2017-12-14 20:11:51] Epoch 0144 mean train/dev loss: 24782.2595 / 25992.5840
[2017-12-14 20:12:54] Epoch 0145 mean train/dev loss: 24857.4828 / 25984.0527
[2017-12-14 20:12:54] Checkpointing model...
[2017-12-14 20:12:55] Model Checkpointing finished.
[2017-12-14 20:13:57] Epoch 0146 mean train/dev loss: 24837.4045 / 25974.6914
[2017-12-14 20:14:59] Epoch 0147 mean train/dev loss: 24830.3500 / 25966.7266
[2017-12-14 20:16:02] Epoch 0148 mean train/dev loss: 24776.5647 / 25957.9238
[2017-12-14 20:17:07] Epoch 0149 mean train/dev loss: 24763.0706 / 25948.8945
[2017-12-14 20:18:10] Epoch 0150 mean train/dev loss: 24804.4037 / 25940.3281
[2017-12-14 20:18:10] Learning rate decayed by 0.5000
[2017-12-14 20:18:10] Checkpointing model...
[2017-12-14 20:18:11] Model Checkpointing finished.
[2017-12-14 20:19:12] Epoch 0151 mean train/dev loss: 24768.3302 / 25935.6367
[2017-12-14 20:20:14] Epoch 0152 mean train/dev loss: 24766.4771 / 25931.0488
[2017-12-14 20:21:14] Epoch 0153 mean train/dev loss: 24727.6702 / 25926.7930
[2017-12-14 20:22:18] Epoch 0154 mean train/dev loss: 24884.4084 / 25922.2852
[2017-12-14 20:23:21] Epoch 0155 mean train/dev loss: 24727.3928 / 25917.9727
[2017-12-14 20:23:21] Checkpointing model...
[2017-12-14 20:23:21] Model Checkpointing finished.
[2017-12-14 20:24:24] Epoch 0156 mean train/dev loss: 24753.9867 / 25913.5156
[2017-12-14 20:25:25] Epoch 0157 mean train/dev loss: 24705.1418 / 25908.9863
[2017-12-14 20:26:29] Epoch 0158 mean train/dev loss: 24819.8776 / 25904.5645
[2017-12-14 20:27:35] Epoch 0159 mean train/dev loss: 24754.7515 / 25900.4121
[2017-12-14 20:28:39] Epoch 0160 mean train/dev loss: 24859.9021 / 25895.8477
[2017-12-14 20:28:39] Checkpointing model...
[2017-12-14 20:28:39] Model Checkpointing finished.
[2017-12-14 20:29:43] Epoch 0161 mean train/dev loss: 24742.8762 / 25891.2070
[2017-12-14 20:30:46] Epoch 0162 mean train/dev loss: 24717.5054 / 25887.6953
[2017-12-14 20:31:47] Epoch 0163 mean train/dev loss: 24745.7141 / 25882.8047
[2017-12-14 20:32:51] Epoch 0164 mean train/dev loss: 24812.2563 / 25878.3945
[2017-12-14 20:33:52] Epoch 0165 mean train/dev loss: 24684.1844 / 25873.7207
[2017-12-14 20:33:52] Learning rate decayed by 0.5000
[2017-12-14 20:33:52] Checkpointing model...
[2017-12-14 20:33:52] Model Checkpointing finished.
[2017-12-14 20:34:54] Epoch 0166 mean train/dev loss: 24777.4915 / 25871.7461
[2017-12-14 20:35:54] Epoch 0167 mean train/dev loss: 24665.8102 / 25869.4902
[2017-12-14 20:36:56] Epoch 0168 mean train/dev loss: 24728.6936 / 25867.4316
[2017-12-14 20:37:58] Epoch 0169 mean train/dev loss: 24776.0525 / 25865.0957
[2017-12-14 20:39:01] Epoch 0170 mean train/dev loss: 24658.1879 / 25862.9688
[2017-12-14 20:39:01] Checkpointing model...
[2017-12-14 20:39:01] Model Checkpointing finished.
[2017-12-14 20:40:05] Epoch 0171 mean train/dev loss: 24725.5180 / 25860.7324
[2017-12-14 20:41:11] Epoch 0172 mean train/dev loss: 24729.7639 / 25858.5117
[2017-12-14 20:42:12] Epoch 0173 mean train/dev loss: 24602.6043 / 25856.2344
[2017-12-14 20:43:15] Epoch 0174 mean train/dev loss: 24752.0368 / 25854.1758
[2017-12-14 20:44:16] Epoch 0175 mean train/dev loss: 24648.7667 / 25851.8301
[2017-12-14 20:44:16] Checkpointing model...
[2017-12-14 20:44:17] Model Checkpointing finished.
[2017-12-14 20:45:19] Epoch 0176 mean train/dev loss: 24671.1006 / 25849.6777
[2017-12-14 20:46:24] Epoch 0177 mean train/dev loss: 24698.1035 / 25847.4648
[2017-12-14 20:47:25] Epoch 0178 mean train/dev loss: 24690.7162 / 25845.3711
[2017-12-14 20:48:29] Epoch 0179 mean train/dev loss: 24650.9312 / 25843.1719
[2017-12-14 20:49:34] Epoch 0180 mean train/dev loss: 24706.3858 / 25840.7109
[2017-12-14 20:49:34] Learning rate decayed by 0.5000
[2017-12-14 20:49:34] Checkpointing model...
[2017-12-14 20:49:34] Model Checkpointing finished.
[2017-12-14 20:50:38] Epoch 0181 mean train/dev loss: 24750.8562 / 25839.5918
[2017-12-14 20:51:41] Epoch 0182 mean train/dev loss: 24709.1009 / 25838.6016
[2017-12-14 20:52:41] Epoch 0183 mean train/dev loss: 24642.9454 / 25837.3281
[2017-12-14 20:53:44] Epoch 0184 mean train/dev loss: 24631.6468 / 25836.3809
[2017-12-14 20:54:49] Epoch 0185 mean train/dev loss: 24713.9636 / 25835.2344
[2017-12-14 20:54:49] Checkpointing model...
[2017-12-14 20:54:49] Model Checkpointing finished.
[2017-12-14 20:55:52] Epoch 0186 mean train/dev loss: 24668.5639 / 25834.0664
[2017-12-14 20:56:52] Epoch 0187 mean train/dev loss: 24728.5710 / 25832.8730
[2017-12-14 20:57:58] Epoch 0188 mean train/dev loss: 24743.7294 / 25831.6816
[2017-12-14 20:59:02] Epoch 0189 mean train/dev loss: 24641.4192 / 25830.4141
[2017-12-14 21:00:05] Epoch 0190 mean train/dev loss: 24720.2599 / 25829.4062
[2017-12-14 21:00:05] Checkpointing model...
[2017-12-14 21:00:05] Model Checkpointing finished.
[2017-12-14 21:01:08] Epoch 0191 mean train/dev loss: 24680.0671 / 25828.2695
[2017-12-14 21:02:11] Epoch 0192 mean train/dev loss: 24612.8239 / 25826.9766
[2017-12-14 21:03:12] Epoch 0193 mean train/dev loss: 24644.2838 / 25825.9766
[2017-12-14 21:04:14] Epoch 0194 mean train/dev loss: 24654.3683 / 25824.9082
[2017-12-14 21:05:15] Epoch 0195 mean train/dev loss: 24771.1475 / 25823.6875
[2017-12-14 21:05:15] Learning rate decayed by 0.5000
[2017-12-14 21:05:15] Checkpointing model...
[2017-12-14 21:05:15] Model Checkpointing finished.
[2017-12-14 21:06:13] Epoch 0196 mean train/dev loss: 24766.9235 / 25823.3027
[2017-12-14 21:07:18] Epoch 0197 mean train/dev loss: 24653.7385 / 25822.8613
[2017-12-14 21:08:19] Epoch 0198 mean train/dev loss: 24650.1999 / 25822.3711
[2017-12-14 21:09:22] Epoch 0199 mean train/dev loss: 24638.2274 / 25821.9551
[2017-12-14 21:10:24] Epoch 0200 mean train/dev loss: 24615.7985 / 25821.5273
[2017-12-14 21:10:24] Checkpointing model...
[2017-12-14 21:10:24] Model Checkpointing finished.
[2017-12-14 21:11:26] Epoch 0201 mean train/dev loss: 24668.3807 / 25821.1504
[2017-12-14 21:12:26] Epoch 0202 mean train/dev loss: 24690.2603 / 25820.6328
[2017-12-14 21:13:29] Epoch 0203 mean train/dev loss: 24680.6938 / 25820.1465
[2017-12-14 21:14:31] Epoch 0204 mean train/dev loss: 24661.9190 / 25819.7168
[2017-12-14 21:15:38] Epoch 0205 mean train/dev loss: 24621.2549 / 25819.2637
[2017-12-14 21:15:38] Checkpointing model...
[2017-12-14 21:15:38] Model Checkpointing finished.
[2017-12-14 21:16:40] Epoch 0206 mean train/dev loss: 24692.0823 / 25818.8730
[2017-12-14 21:17:44] Epoch 0207 mean train/dev loss: 24715.6608 / 25818.4160
[2017-12-14 21:18:45] Epoch 0208 mean train/dev loss: 24685.3740 / 25818.0000
[2017-12-14 21:19:48] Epoch 0209 mean train/dev loss: 24683.5294 / 25817.4727
[2017-12-14 21:20:49] Epoch 0210 mean train/dev loss: 24600.0873 / 25817.0684
[2017-12-14 21:20:49] Learning rate decayed by 0.5000
[2017-12-14 21:20:49] Checkpointing model...
[2017-12-14 21:20:49] Model Checkpointing finished.
[2017-12-14 21:21:50] Epoch 0211 mean train/dev loss: 24667.7319 / 25816.6152
[2017-12-14 21:22:51] Epoch 0212 mean train/dev loss: 24613.3496 / 25816.1738
[2017-12-14 21:23:52] Epoch 0213 mean train/dev loss: 24694.0130 / 25815.7578
[2017-12-14 21:24:55] Epoch 0214 mean train/dev loss: 24719.7233 / 25815.3086
[2017-12-14 21:25:55] Epoch 0215 mean train/dev loss: 24651.2923 / 25814.8945
[2017-12-14 21:25:55] Checkpointing model...
[2017-12-14 21:25:56] Model Checkpointing finished.
[2017-12-14 21:26:56] Epoch 0216 mean train/dev loss: 24667.7203 / 25814.4180
[2017-12-14 21:27:55] Epoch 0217 mean train/dev loss: 24656.4800 / 25813.9824
[2017-12-14 21:28:56] Epoch 0218 mean train/dev loss: 24624.5655 / 25813.5703
[2017-12-14 21:29:59] Epoch 0219 mean train/dev loss: 24751.3183 / 25813.1250
[2017-12-14 21:31:02] Epoch 0220 mean train/dev loss: 24616.6401 / 25812.6543
[2017-12-14 21:31:02] Checkpointing model...
[2017-12-14 21:31:02] Model Checkpointing finished.
[2017-12-14 21:32:04] Epoch 0221 mean train/dev loss: 24660.5505 / 25812.2305
[2017-12-14 21:33:07] Epoch 0222 mean train/dev loss: 24673.1127 / 25811.7793
[2017-12-14 21:34:10] Epoch 0223 mean train/dev loss: 24756.0542 / 25811.3398
[2017-12-14 21:35:13] Epoch 0224 mean train/dev loss: 24636.7434 / 25810.9316
[2017-12-14 21:36:13] Epoch 0225 mean train/dev loss: 24716.0525 / 25810.4863
[2017-12-14 21:36:13] Learning rate decayed by 0.5000
[2017-12-14 21:36:13] Checkpointing model...
[2017-12-14 21:36:14] Model Checkpointing finished.
[2017-12-14 21:37:16] Epoch 0226 mean train/dev loss: 24573.2847 / 25810.4980
[2017-12-14 21:38:19] Epoch 0227 mean train/dev loss: 24610.1562 / 25810.4863
[2017-12-14 21:39:20] Epoch 0228 mean train/dev loss: 24750.9586 / 25810.4727
[2017-12-14 21:40:21] Epoch 0229 mean train/dev loss: 24685.4712 / 25810.4805
[2017-12-14 21:41:23] Epoch 0230 mean train/dev loss: 24667.7560 / 25810.4707
[2017-12-14 21:41:23] Checkpointing model...
[2017-12-14 21:41:24] Model Checkpointing finished.
[2017-12-14 21:42:28] Epoch 0231 mean train/dev loss: 24627.5413 / 25810.4648
[2017-12-14 21:43:30] Epoch 0232 mean train/dev loss: 24603.0338 / 25810.4805
[2017-12-14 21:44:35] Epoch 0233 mean train/dev loss: 24712.1594 / 25810.4688
[2017-12-14 21:45:33] Epoch 0234 mean train/dev loss: 24658.1181 / 25810.4785
[2017-12-14 21:46:36] Epoch 0235 mean train/dev loss: 24643.2795 / 25810.4609
[2017-12-14 21:46:36] Checkpointing model...
[2017-12-14 21:46:37] Model Checkpointing finished.
[2017-12-14 21:47:39] Epoch 0236 mean train/dev loss: 24628.8720 / 25810.4727
[2017-12-14 21:48:42] Epoch 0237 mean train/dev loss: 24624.2092 / 25810.4688
[2017-12-14 21:49:43] Epoch 0238 mean train/dev loss: 24624.5156 / 25810.4766
[2017-12-14 21:50:47] Epoch 0239 mean train/dev loss: 24570.3052 / 25810.4766
[2017-12-14 21:51:51] Epoch 0240 mean train/dev loss: 24697.2588 / 25810.4570
[2017-12-14 21:51:51] Learning rate decayed by 0.5000
[2017-12-14 21:51:51] Checkpointing model...
[2017-12-14 21:51:51] Model Checkpointing finished.
[2017-12-14 21:52:52] Epoch 0241 mean train/dev loss: 24676.9425 / 25810.4590
[2017-12-14 21:53:57] Epoch 0242 mean train/dev loss: 24672.9961 / 25810.4668
[2017-12-14 21:54:58] Epoch 0243 mean train/dev loss: 24675.8281 / 25810.4648
[2017-12-14 21:56:01] Epoch 0244 mean train/dev loss: 24582.6925 / 25810.4590
[2017-12-14 21:57:02] Epoch 0245 mean train/dev loss: 24616.9859 / 25810.4629
[2017-12-14 21:57:02] Checkpointing model...
[2017-12-14 21:57:03] Model Checkpointing finished.
[2017-12-14 21:58:06] Epoch 0246 mean train/dev loss: 24655.1698 / 25810.4668
[2017-12-14 21:59:09] Epoch 0247 mean train/dev loss: 24712.1458 / 25810.4629
[2017-12-14 22:00:12] Epoch 0248 mean train/dev loss: 24683.9663 / 25810.4570
[2017-12-14 22:01:10] Epoch 0249 mean train/dev loss: 24612.0092 / 25810.4648
[2017-12-14 22:02:13] Epoch 0250 mean train/dev loss: 24659.0462 / 25810.4570
[2017-12-14 22:02:13] Checkpointing model...
[2017-12-14 22:02:13] Model Checkpointing finished.
[2017-12-14 22:03:15] Epoch 0251 mean train/dev loss: 24607.6517 / 25810.4668
[2017-12-14 22:04:17] Epoch 0252 mean train/dev loss: 24676.4285 / 25810.4570
[2017-12-14 22:05:18] Epoch 0253 mean train/dev loss: 24650.4250 / 25810.4648
[2017-12-14 22:06:20] Epoch 0254 mean train/dev loss: 24636.3168 / 25810.4570
[2017-12-14 22:07:21] Epoch 0255 mean train/dev loss: 24609.5293 / 25810.4629
[2017-12-14 22:07:21] Learning rate decayed by 0.5000
[2017-12-14 22:07:21] Checkpointing model...
[2017-12-14 22:07:22] Model Checkpointing finished.
[2017-12-14 22:08:24] Epoch 0256 mean train/dev loss: 24632.8569 / 25810.4590
[2017-12-14 22:09:21] Epoch 0257 mean train/dev loss: 24665.8009 / 25810.4570
[2017-12-14 22:10:26] Epoch 0258 mean train/dev loss: 24692.5904 / 25810.4629
[2017-12-14 22:11:21] Epoch 0259 mean train/dev loss: 24741.5699 / 25810.4629
[2017-12-14 22:12:21] Epoch 0260 mean train/dev loss: 24621.6582 / 25810.4648
[2017-12-14 22:12:21] Checkpointing model...
[2017-12-14 22:12:21] Model Checkpointing finished.
[2017-12-14 22:13:26] Epoch 0261 mean train/dev loss: 24634.4509 / 25810.4570
[2017-12-14 22:14:29] Epoch 0262 mean train/dev loss: 24614.5702 / 25810.4609
[2017-12-14 22:15:30] Epoch 0263 mean train/dev loss: 24661.1131 / 25810.4590
[2017-12-14 22:16:34] Epoch 0264 mean train/dev loss: 24671.5191 / 25810.4629
[2017-12-14 22:17:40] Epoch 0265 mean train/dev loss: 24715.5615 / 25810.4707
[2017-12-14 22:17:40] Checkpointing model...
[2017-12-14 22:17:41] Model Checkpointing finished.
[2017-12-14 22:18:45] Epoch 0266 mean train/dev loss: 24740.0960 / 25810.4668
[2017-12-14 22:19:46] Epoch 0267 mean train/dev loss: 24640.7675 / 25810.4688
[2017-12-14 22:20:50] Epoch 0268 mean train/dev loss: 24688.4455 / 25810.4648
[2017-12-14 22:21:52] Epoch 0269 mean train/dev loss: 24576.4495 / 25810.4648
[2017-12-14 22:22:55] Epoch 0270 mean train/dev loss: 24694.9447 / 25810.4590
[2017-12-14 22:22:55] Learning rate decayed by 0.5000
[2017-12-14 22:22:55] Checkpointing model...
[2017-12-14 22:22:55] Model Checkpointing finished.
[2017-12-14 22:23:58] Epoch 0271 mean train/dev loss: 24629.8705 / 25810.4590
[2017-12-14 22:25:00] Epoch 0272 mean train/dev loss: 24666.8913 / 25810.4609
[2017-12-14 22:26:03] Epoch 0273 mean train/dev loss: 24645.3774 / 25810.4609
[2017-12-14 22:27:02] Epoch 0274 mean train/dev loss: 24692.2639 / 25810.4648
[2017-12-14 22:27:57] Epoch 0275 mean train/dev loss: 24678.7344 / 25810.4609
[2017-12-14 22:27:57] Checkpointing model...
[2017-12-14 22:27:57] Model Checkpointing finished.
[2017-12-14 22:28:47] Epoch 0276 mean train/dev loss: 24632.8923 / 25810.4609
[2017-12-14 22:29:37] Epoch 0277 mean train/dev loss: 24733.6827 / 25810.4629
[2017-12-14 22:30:31] Epoch 0278 mean train/dev loss: 24632.0970 / 25810.4609
[2017-12-14 22:31:22] Epoch 0279 mean train/dev loss: 24612.1881 / 25810.4590
[2017-12-14 22:32:14] Epoch 0280 mean train/dev loss: 24706.6089 / 25810.4609
[2017-12-14 22:32:14] Checkpointing model...
[2017-12-14 22:32:14] Model Checkpointing finished.
[2017-12-14 22:33:04] Epoch 0281 mean train/dev loss: 24644.0136 / 25810.4609
[2017-12-14 22:33:04] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-14 22:33:04] 
                       *** Training finished *** 
[2017-12-14 22:33:08] Dev MSE: 25810.4609
[2017-12-14 22:33:49] Training MSE: 24663.0859
[2017-12-14 22:33:51] Experiment lstm.hs_50.nl_1.lr_0.01.wd_0.001.rl_linear logging ended.
