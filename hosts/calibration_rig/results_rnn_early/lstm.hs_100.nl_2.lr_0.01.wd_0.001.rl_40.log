[2017-12-15 07:56:37] Experiment lstm.hs_100.nl_2.lr_0.01.wd_0.001.rl_40 logging started.
[2017-12-15 07:56:37] 
                       *** Starting Experiment lstm.hs_100.nl_2.lr_0.01.wd_0.001.rl_40 ***
                      
[2017-12-15 07:56:37] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 100  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.01  
                      [               num_epochs] 300  
                      [               num_layers] 2  
                      [        regression_layers] [40]  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-15 07:56:40] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 100, num_layers=2, batch_first=True)
                        (linear1): Linear (100 -> 40)
                        (final): Linear (40 -> 1)
                      )
[2017-12-15 07:56:40]  *** Training on GPU ***
[2017-12-15 07:57:19] Epoch 0001 mean train/dev loss: 217434.6311 / 75517.3516
[2017-12-15 07:57:19] Checkpointing model...
[2017-12-15 07:57:19] Model Checkpointing finished.
[2017-12-15 07:57:59] Epoch 0002 mean train/dev loss: 63889.1917 / 62203.7148
[2017-12-15 07:57:59] Checkpointing model...
[2017-12-15 07:57:59] Model Checkpointing finished.
[2017-12-15 07:58:39] Epoch 0003 mean train/dev loss: 60636.6138 / 60319.7383
[2017-12-15 07:58:39] Checkpointing model...
[2017-12-15 07:58:39] Model Checkpointing finished.
[2017-12-15 07:59:18] Epoch 0004 mean train/dev loss: 59297.1884 / 50101.2500
[2017-12-15 07:59:18] Checkpointing model...
[2017-12-15 07:59:18] Model Checkpointing finished.
[2017-12-15 07:59:58] Epoch 0005 mean train/dev loss: 44440.7327 / 12823.7266
[2017-12-15 07:59:58] Checkpointing model...
[2017-12-15 07:59:58] Model Checkpointing finished.
[2017-12-15 08:00:38] Epoch 0006 mean train/dev loss: 6782.6296 / 5931.3071
[2017-12-15 08:01:18] Epoch 0007 mean train/dev loss: 2634.4743 / 1335.6368
[2017-12-15 08:01:57] Epoch 0008 mean train/dev loss: 966.4771 / 1155.2404
[2017-12-15 08:02:37] Epoch 0009 mean train/dev loss: 1199.0382 / 18775.6602
[2017-12-15 08:03:17] Epoch 0010 mean train/dev loss: 4507.4626 / 1122.6221
[2017-12-15 08:03:17] Checkpointing model...
[2017-12-15 08:03:17] Model Checkpointing finished.
[2017-12-15 08:03:57] Epoch 0011 mean train/dev loss: 791.5687 / 676.8298
[2017-12-15 08:04:37] Epoch 0012 mean train/dev loss: 628.4029 / 980.5690
[2017-12-15 08:05:16] Epoch 0013 mean train/dev loss: 470.6409 / 436.5771
[2017-12-15 08:05:56] Epoch 0014 mean train/dev loss: 327.9919 / 390.2445
[2017-12-15 08:06:36] Epoch 0015 mean train/dev loss: 340.5475 / 297.8054
[2017-12-15 08:06:36] Learning rate decayed by 0.5000
[2017-12-15 08:06:36] Checkpointing model...
[2017-12-15 08:06:36] Model Checkpointing finished.
[2017-12-15 08:07:16] Epoch 0016 mean train/dev loss: 236.9930 / 532.2816
[2017-12-15 08:07:55] Epoch 0017 mean train/dev loss: 410.0134 / 358.3594
[2017-12-15 08:08:35] Epoch 0018 mean train/dev loss: 221.2124 / 232.3881
[2017-12-15 08:09:14] Epoch 0019 mean train/dev loss: 189.2512 / 234.9579
[2017-12-15 08:09:54] Epoch 0020 mean train/dev loss: 164.4931 / 192.9850
[2017-12-15 08:09:54] Checkpointing model...
[2017-12-15 08:09:54] Model Checkpointing finished.
[2017-12-15 08:10:34] Epoch 0021 mean train/dev loss: 152.6872 / 198.3377
[2017-12-15 08:11:13] Epoch 0022 mean train/dev loss: 150.4787 / 179.4436
[2017-12-15 08:11:53] Epoch 0023 mean train/dev loss: 143.2490 / 189.4497
[2017-12-15 08:12:33] Epoch 0024 mean train/dev loss: 154.1162 / 200.5255
[2017-12-15 08:13:12] Epoch 0025 mean train/dev loss: 145.1244 / 198.2242
[2017-12-15 08:13:12] Checkpointing model...
[2017-12-15 08:13:12] Model Checkpointing finished.
[2017-12-15 08:13:52] Epoch 0026 mean train/dev loss: 241.7344 / 221.4048
[2017-12-15 08:14:31] Epoch 0027 mean train/dev loss: 164.9211 / 199.2737
[2017-12-15 08:15:11] Epoch 0028 mean train/dev loss: 140.9638 / 192.2885
[2017-12-15 08:15:51] Epoch 0029 mean train/dev loss: 148.4865 / 168.4890
[2017-12-15 08:16:31] Epoch 0030 mean train/dev loss: 118.2106 / 165.2279
[2017-12-15 08:16:31] Learning rate decayed by 0.5000
[2017-12-15 08:16:31] Checkpointing model...
[2017-12-15 08:16:31] Model Checkpointing finished.
[2017-12-15 08:17:11] Epoch 0031 mean train/dev loss: 111.4316 / 159.0281
[2017-12-15 08:17:50] Epoch 0032 mean train/dev loss: 104.7028 / 162.5211
[2017-12-15 08:18:30] Epoch 0033 mean train/dev loss: 100.3183 / 145.5527
[2017-12-15 08:19:10] Epoch 0034 mean train/dev loss: 97.9506 / 144.5025
[2017-12-15 08:19:49] Epoch 0035 mean train/dev loss: 95.7726 / 138.3376
[2017-12-15 08:19:49] Checkpointing model...
[2017-12-15 08:19:50] Model Checkpointing finished.
[2017-12-15 08:20:29] Epoch 0036 mean train/dev loss: 93.5808 / 146.3521
[2017-12-15 08:21:10] Epoch 0037 mean train/dev loss: 94.8809 / 137.4332
[2017-12-15 08:21:49] Epoch 0038 mean train/dev loss: 97.5183 / 136.9908
[2017-12-15 08:22:28] Epoch 0039 mean train/dev loss: 92.8311 / 132.9114
[2017-12-15 08:23:08] Epoch 0040 mean train/dev loss: 88.5265 / 145.8089
[2017-12-15 08:23:08] Checkpointing model...
[2017-12-15 08:23:08] Model Checkpointing finished.
[2017-12-15 08:23:47] Epoch 0041 mean train/dev loss: 92.8828 / 131.7592
[2017-12-15 08:24:27] Epoch 0042 mean train/dev loss: 96.5868 / 126.2562
[2017-12-15 08:25:07] Epoch 0043 mean train/dev loss: 92.5051 / 117.5990
[2017-12-15 08:25:47] Epoch 0044 mean train/dev loss: 89.2668 / 109.3082
[2017-12-15 08:26:27] Epoch 0045 mean train/dev loss: 85.6860 / 115.1932
[2017-12-15 08:26:27] Learning rate decayed by 0.5000
[2017-12-15 08:26:27] Checkpointing model...
[2017-12-15 08:26:27] Model Checkpointing finished.
[2017-12-15 08:27:07] Epoch 0046 mean train/dev loss: 81.6164 / 109.3238
[2017-12-15 08:27:46] Epoch 0047 mean train/dev loss: 79.0841 / 126.2435
[2017-12-15 08:28:25] Epoch 0048 mean train/dev loss: 75.3684 / 106.1769
[2017-12-15 08:29:05] Epoch 0049 mean train/dev loss: 75.4350 / 109.0049
[2017-12-15 08:29:44] Epoch 0050 mean train/dev loss: 75.8412 / 106.5866
[2017-12-15 08:29:44] Checkpointing model...
[2017-12-15 08:29:44] Model Checkpointing finished.
[2017-12-15 08:30:24] Epoch 0051 mean train/dev loss: 75.1799 / 106.6481
[2017-12-15 08:31:03] Epoch 0052 mean train/dev loss: 73.6108 / 105.9199
[2017-12-15 08:31:43] Epoch 0053 mean train/dev loss: 73.7534 / 109.9074
[2017-12-15 08:32:22] Epoch 0054 mean train/dev loss: 72.3970 / 108.0668
[2017-12-15 08:33:01] Epoch 0055 mean train/dev loss: 75.5916 / 115.4179
[2017-12-15 08:33:01] Checkpointing model...
[2017-12-15 08:33:01] Model Checkpointing finished.
[2017-12-15 08:33:41] Epoch 0056 mean train/dev loss: 77.1197 / 126.0134
[2017-12-15 08:34:20] Epoch 0057 mean train/dev loss: 73.7541 / 105.0456
[2017-12-15 08:35:00] Epoch 0058 mean train/dev loss: 72.8535 / 111.4987
[2017-12-15 08:35:40] Epoch 0059 mean train/dev loss: 71.8311 / 123.7630
[2017-12-15 08:36:20] Epoch 0060 mean train/dev loss: 72.4161 / 107.7943
[2017-12-15 08:36:20] Learning rate decayed by 0.5000
[2017-12-15 08:36:20] Checkpointing model...
[2017-12-15 08:36:20] Model Checkpointing finished.
[2017-12-15 08:36:59] Epoch 0061 mean train/dev loss: 70.6359 / 123.8645
[2017-12-15 08:37:39] Epoch 0062 mean train/dev loss: 90.0220 / 117.8076
[2017-12-15 08:38:18] Epoch 0063 mean train/dev loss: 74.6755 / 108.5776
[2017-12-15 08:38:57] Epoch 0064 mean train/dev loss: 71.0664 / 111.7067
[2017-12-15 08:39:37] Epoch 0065 mean train/dev loss: 68.7391 / 110.3281
[2017-12-15 08:39:37] Checkpointing model...
[2017-12-15 08:39:37] Model Checkpointing finished.
[2017-12-15 08:40:17] Epoch 0066 mean train/dev loss: 68.3650 / 107.9229
[2017-12-15 08:40:56] Epoch 0067 mean train/dev loss: 66.3617 / 109.8589
[2017-12-15 08:41:36] Epoch 0068 mean train/dev loss: 68.0064 / 108.8188
[2017-12-15 08:42:15] Epoch 0069 mean train/dev loss: 65.7955 / 111.1000
[2017-12-15 08:42:54] Epoch 0070 mean train/dev loss: 66.3477 / 106.9149
[2017-12-15 08:42:54] Checkpointing model...
[2017-12-15 08:42:54] Model Checkpointing finished.
[2017-12-15 08:43:34] Epoch 0071 mean train/dev loss: 64.6708 / 105.4411
[2017-12-15 08:44:14] Epoch 0072 mean train/dev loss: 67.0797 / 103.9017
[2017-12-15 08:44:54] Epoch 0073 mean train/dev loss: 65.4446 / 104.6020
[2017-12-15 08:45:35] Epoch 0074 mean train/dev loss: 63.5006 / 111.0166
[2017-12-15 08:46:15] Epoch 0075 mean train/dev loss: 70.2654 / 115.1166
[2017-12-15 08:46:15] Learning rate decayed by 0.5000
[2017-12-15 08:46:15] Checkpointing model...
[2017-12-15 08:46:15] Model Checkpointing finished.
[2017-12-15 08:46:55] Epoch 0076 mean train/dev loss: 67.8456 / 103.6406
[2017-12-15 08:47:35] Epoch 0077 mean train/dev loss: 65.3755 / 101.2671
[2017-12-15 08:48:16] Epoch 0078 mean train/dev loss: 79.3896 / 159.1298
[2017-12-15 08:48:56] Epoch 0079 mean train/dev loss: 74.1941 / 104.1555
[2017-12-15 08:49:35] Epoch 0080 mean train/dev loss: 65.5280 / 106.7277
[2017-12-15 08:49:35] Checkpointing model...
[2017-12-15 08:49:36] Model Checkpointing finished.
[2017-12-15 08:50:16] Epoch 0081 mean train/dev loss: 65.4923 / 102.4987
[2017-12-15 08:50:56] Epoch 0082 mean train/dev loss: 63.1233 / 100.6900
[2017-12-15 08:51:36] Epoch 0083 mean train/dev loss: 61.8131 / 102.5113
[2017-12-15 08:52:16] Epoch 0084 mean train/dev loss: 60.5436 / 98.6689
[2017-12-15 08:52:56] Epoch 0085 mean train/dev loss: 61.0139 / 96.2655
[2017-12-15 08:52:56] Checkpointing model...
[2017-12-15 08:52:56] Model Checkpointing finished.
[2017-12-15 08:53:36] Epoch 0086 mean train/dev loss: 59.8331 / 99.4832
[2017-12-15 08:54:16] Epoch 0087 mean train/dev loss: 59.8313 / 99.1984
[2017-12-15 08:54:55] Epoch 0088 mean train/dev loss: 59.7165 / 97.0423
[2017-12-15 08:55:36] Epoch 0089 mean train/dev loss: 59.7914 / 100.9954
[2017-12-15 08:56:16] Epoch 0090 mean train/dev loss: 59.0971 / 98.3241
[2017-12-15 08:56:16] Learning rate decayed by 0.5000
[2017-12-15 08:56:16] Checkpointing model...
[2017-12-15 08:56:16] Model Checkpointing finished.
[2017-12-15 08:56:57] Epoch 0091 mean train/dev loss: 57.8418 / 94.3433
[2017-12-15 08:57:37] Epoch 0092 mean train/dev loss: 57.4768 / 96.7975
[2017-12-15 08:58:17] Epoch 0093 mean train/dev loss: 57.2084 / 97.4075
[2017-12-15 08:58:57] Epoch 0094 mean train/dev loss: 56.7388 / 95.2214
[2017-12-15 08:59:37] Epoch 0095 mean train/dev loss: 56.1418 / 95.3357
[2017-12-15 08:59:37] Checkpointing model...
[2017-12-15 08:59:37] Model Checkpointing finished.
[2017-12-15 09:00:17] Epoch 0096 mean train/dev loss: 56.4799 / 93.8263
[2017-12-15 09:00:57] Epoch 0097 mean train/dev loss: 56.2302 / 98.1567
[2017-12-15 09:01:37] Epoch 0098 mean train/dev loss: 56.3162 / 95.6134
[2017-12-15 09:02:17] Epoch 0099 mean train/dev loss: 56.0388 / 94.3629
[2017-12-15 09:02:57] Epoch 0100 mean train/dev loss: 55.8205 / 95.1712
[2017-12-15 09:02:57] Checkpointing model...
[2017-12-15 09:02:57] Model Checkpointing finished.
[2017-12-15 09:03:37] Epoch 0101 mean train/dev loss: 55.6833 / 93.3174
[2017-12-15 09:04:17] Epoch 0102 mean train/dev loss: 55.5448 / 92.6696
[2017-12-15 09:04:57] Epoch 0103 mean train/dev loss: 56.6544 / 93.9434
[2017-12-15 09:05:37] Epoch 0104 mean train/dev loss: 55.5512 / 95.4313
[2017-12-15 09:06:17] Epoch 0105 mean train/dev loss: 56.0491 / 93.1784
[2017-12-15 09:06:17] Learning rate decayed by 0.5000
[2017-12-15 09:06:17] Checkpointing model...
[2017-12-15 09:06:18] Model Checkpointing finished.
[2017-12-15 09:06:57] Epoch 0106 mean train/dev loss: 54.6865 / 93.3356
[2017-12-15 09:07:37] Epoch 0107 mean train/dev loss: 54.7055 / 91.5445
[2017-12-15 09:08:16] Epoch 0108 mean train/dev loss: 54.4020 / 93.3324
[2017-12-15 09:08:57] Epoch 0109 mean train/dev loss: 54.3807 / 91.3736
[2017-12-15 09:09:36] Epoch 0110 mean train/dev loss: 54.6180 / 91.5344
[2017-12-15 09:09:36] Checkpointing model...
[2017-12-15 09:09:36] Model Checkpointing finished.
[2017-12-15 09:10:16] Epoch 0111 mean train/dev loss: 54.6229 / 93.9200
[2017-12-15 09:10:56] Epoch 0112 mean train/dev loss: 54.0809 / 92.8073
[2017-12-15 09:11:36] Epoch 0113 mean train/dev loss: 53.9495 / 92.2815
[2017-12-15 09:12:16] Epoch 0114 mean train/dev loss: 54.4180 / 94.5523
[2017-12-15 09:12:55] Epoch 0115 mean train/dev loss: 54.0558 / 91.5633
[2017-12-15 09:12:55] Checkpointing model...
[2017-12-15 09:12:55] Model Checkpointing finished.
[2017-12-15 09:13:35] Epoch 0116 mean train/dev loss: 53.5385 / 94.2754
[2017-12-15 09:14:15] Epoch 0117 mean train/dev loss: 53.5473 / 91.9048
[2017-12-15 09:14:55] Epoch 0118 mean train/dev loss: 53.5577 / 92.7442
[2017-12-15 09:15:35] Epoch 0119 mean train/dev loss: 53.8313 / 94.6665
[2017-12-15 09:16:15] Epoch 0120 mean train/dev loss: 53.9563 / 94.3788
[2017-12-15 09:16:15] Learning rate decayed by 0.5000
[2017-12-15 09:16:15] Checkpointing model...
[2017-12-15 09:16:15] Model Checkpointing finished.
[2017-12-15 09:16:55] Epoch 0121 mean train/dev loss: 52.7094 / 91.3394
[2017-12-15 09:17:35] Epoch 0122 mean train/dev loss: 52.8213 / 91.5263
[2017-12-15 09:18:15] Epoch 0123 mean train/dev loss: 52.7999 / 92.8868
[2017-12-15 09:18:54] Epoch 0124 mean train/dev loss: 52.6632 / 92.2721
[2017-12-15 09:19:34] Epoch 0125 mean train/dev loss: 52.4084 / 90.3502
[2017-12-15 09:19:34] Checkpointing model...
[2017-12-15 09:19:34] Model Checkpointing finished.
[2017-12-15 09:20:14] Epoch 0126 mean train/dev loss: 52.3051 / 91.3895
[2017-12-15 09:20:54] Epoch 0127 mean train/dev loss: 52.4842 / 91.9206
[2017-12-15 09:21:33] Epoch 0128 mean train/dev loss: 52.5851 / 91.4825
[2017-12-15 09:22:13] Epoch 0129 mean train/dev loss: 52.3211 / 91.3015
[2017-12-15 09:22:53] Epoch 0130 mean train/dev loss: 52.3526 / 90.9380
[2017-12-15 09:22:53] Checkpointing model...
[2017-12-15 09:22:53] Model Checkpointing finished.
[2017-12-15 09:23:33] Epoch 0131 mean train/dev loss: 52.2713 / 90.7339
[2017-12-15 09:24:12] Epoch 0132 mean train/dev loss: 51.9320 / 91.7593
[2017-12-15 09:24:53] Epoch 0133 mean train/dev loss: 52.1698 / 91.0414
[2017-12-15 09:25:33] Epoch 0134 mean train/dev loss: 51.9876 / 91.3636
[2017-12-15 09:26:14] Epoch 0135 mean train/dev loss: 52.1561 / 90.5063
[2017-12-15 09:26:14] Learning rate decayed by 0.5000
[2017-12-15 09:26:14] Checkpointing model...
[2017-12-15 09:26:14] Model Checkpointing finished.
[2017-12-15 09:26:54] Epoch 0136 mean train/dev loss: 51.8016 / 91.2295
[2017-12-15 09:27:35] Epoch 0137 mean train/dev loss: 52.1323 / 90.6368
[2017-12-15 09:28:15] Epoch 0138 mean train/dev loss: 51.6235 / 90.0845
[2017-12-15 09:28:55] Epoch 0139 mean train/dev loss: 51.5323 / 90.2678
[2017-12-15 09:29:36] Epoch 0140 mean train/dev loss: 51.4068 / 91.6306
[2017-12-15 09:29:36] Checkpointing model...
[2017-12-15 09:29:36] Model Checkpointing finished.
[2017-12-15 09:30:17] Epoch 0141 mean train/dev loss: 51.5267 / 90.8061
[2017-12-15 09:30:57] Epoch 0142 mean train/dev loss: 51.2811 / 90.6321
[2017-12-15 09:31:37] Epoch 0143 mean train/dev loss: 51.3584 / 90.3119
[2017-12-15 09:32:17] Epoch 0144 mean train/dev loss: 51.3570 / 90.3470
[2017-12-15 09:32:57] Epoch 0145 mean train/dev loss: 51.3513 / 91.4138
[2017-12-15 09:32:57] Checkpointing model...
[2017-12-15 09:32:58] Model Checkpointing finished.
[2017-12-15 09:33:38] Epoch 0146 mean train/dev loss: 51.4587 / 89.1407
[2017-12-15 09:34:19] Epoch 0147 mean train/dev loss: 51.3619 / 89.2652
[2017-12-15 09:34:59] Epoch 0148 mean train/dev loss: 51.2704 / 90.6249
[2017-12-15 09:35:40] Epoch 0149 mean train/dev loss: 51.2288 / 91.3822
[2017-12-15 09:36:20] Epoch 0150 mean train/dev loss: 51.1369 / 90.0735
[2017-12-15 09:36:20] Learning rate decayed by 0.5000
[2017-12-15 09:36:20] Checkpointing model...
[2017-12-15 09:36:21] Model Checkpointing finished.
[2017-12-15 09:37:01] Epoch 0151 mean train/dev loss: 51.0401 / 90.3271
[2017-12-15 09:37:42] Epoch 0152 mean train/dev loss: 50.9568 / 90.3542
[2017-12-15 09:38:22] Epoch 0153 mean train/dev loss: 50.9354 / 90.1705
[2017-12-15 09:39:03] Epoch 0154 mean train/dev loss: 50.9372 / 89.9131
[2017-12-15 09:39:43] Epoch 0155 mean train/dev loss: 51.0174 / 90.3512
[2017-12-15 09:39:43] Checkpointing model...
[2017-12-15 09:39:43] Model Checkpointing finished.
[2017-12-15 09:40:24] Epoch 0156 mean train/dev loss: 51.0939 / 90.2926
[2017-12-15 09:41:05] Epoch 0157 mean train/dev loss: 50.9980 / 90.1785
[2017-12-15 09:41:45] Epoch 0158 mean train/dev loss: 50.8842 / 91.0909
[2017-12-15 09:42:25] Epoch 0159 mean train/dev loss: 50.8352 / 90.4039
[2017-12-15 09:43:06] Epoch 0160 mean train/dev loss: 50.6953 / 89.7366
[2017-12-15 09:43:06] Checkpointing model...
[2017-12-15 09:43:06] Model Checkpointing finished.
[2017-12-15 09:43:47] Epoch 0161 mean train/dev loss: 50.9424 / 89.8549
[2017-12-15 09:44:27] Epoch 0162 mean train/dev loss: 50.7586 / 90.3027
[2017-12-15 09:45:08] Epoch 0163 mean train/dev loss: 50.6879 / 89.8268
[2017-12-15 09:45:48] Epoch 0164 mean train/dev loss: 50.7442 / 89.9670
[2017-12-15 09:46:29] Epoch 0165 mean train/dev loss: 50.6955 / 89.4861
[2017-12-15 09:46:29] Learning rate decayed by 0.5000
[2017-12-15 09:46:29] Checkpointing model...
[2017-12-15 09:46:29] Model Checkpointing finished.
[2017-12-15 09:47:09] Epoch 0166 mean train/dev loss: 50.6229 / 90.0198
[2017-12-15 09:47:49] Epoch 0167 mean train/dev loss: 50.6867 / 89.8460
[2017-12-15 09:48:30] Epoch 0168 mean train/dev loss: 50.8121 / 89.8526
[2017-12-15 09:49:10] Epoch 0169 mean train/dev loss: 50.5912 / 89.7754
[2017-12-15 09:49:51] Epoch 0170 mean train/dev loss: 50.4126 / 89.8640
[2017-12-15 09:49:51] Checkpointing model...
[2017-12-15 09:49:51] Model Checkpointing finished.
[2017-12-15 09:50:31] Epoch 0171 mean train/dev loss: 50.6126 / 89.7521
[2017-12-15 09:51:11] Epoch 0172 mean train/dev loss: 50.4945 / 89.8318
[2017-12-15 09:51:51] Epoch 0173 mean train/dev loss: 50.7888 / 89.9195
[2017-12-15 09:52:31] Epoch 0174 mean train/dev loss: 50.4569 / 89.8970
[2017-12-15 09:53:11] Epoch 0175 mean train/dev loss: 50.4788 / 89.9142
[2017-12-15 09:53:11] Checkpointing model...
[2017-12-15 09:53:11] Model Checkpointing finished.
[2017-12-15 09:53:51] Epoch 0176 mean train/dev loss: 50.5526 / 90.0060
[2017-12-15 09:54:32] Epoch 0177 mean train/dev loss: 50.5376 / 89.7389
[2017-12-15 09:55:12] Epoch 0178 mean train/dev loss: 50.5736 / 90.2865
[2017-12-15 09:55:53] Epoch 0179 mean train/dev loss: 50.3939 / 89.9825
[2017-12-15 09:56:33] Epoch 0180 mean train/dev loss: 50.2875 / 89.9228
[2017-12-15 09:56:33] Learning rate decayed by 0.5000
[2017-12-15 09:56:33] Checkpointing model...
[2017-12-15 09:56:33] Model Checkpointing finished.
[2017-12-15 09:57:13] Epoch 0181 mean train/dev loss: 50.4147 / 89.8095
[2017-12-15 09:57:54] Epoch 0182 mean train/dev loss: 50.2524 / 89.8040
[2017-12-15 09:58:34] Epoch 0183 mean train/dev loss: 50.3085 / 89.8091
[2017-12-15 09:59:14] Epoch 0184 mean train/dev loss: 50.3330 / 89.7530
[2017-12-15 09:59:54] Epoch 0185 mean train/dev loss: 50.3881 / 89.6555
[2017-12-15 09:59:54] Checkpointing model...
[2017-12-15 09:59:54] Model Checkpointing finished.
[2017-12-15 10:00:35] Epoch 0186 mean train/dev loss: 50.3554 / 89.7705
[2017-12-15 10:01:15] Epoch 0187 mean train/dev loss: 50.4799 / 89.5877
[2017-12-15 10:01:15] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-15 10:01:15] 
                       *** Training finished *** 
[2017-12-15 10:01:19] Dev MSE: 89.5877
[2017-12-15 10:01:52] Training MSE: 50.2827
[2017-12-15 10:01:54] Experiment lstm.hs_100.nl_2.lr_0.01.wd_0.001.rl_40 logging ended.
