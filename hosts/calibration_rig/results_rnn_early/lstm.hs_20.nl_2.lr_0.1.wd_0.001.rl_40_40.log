[2017-12-14 06:08:43] Experiment lstm.hs_20.nl_2.lr_0.1.wd_0.001.rl_40_40 logging started.
[2017-12-14 06:08:43] 
                       *** Starting Experiment lstm.hs_20.nl_2.lr_0.1.wd_0.001.rl_40_40 ***
                      
[2017-12-14 06:08:43] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 20  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.1  
                      [               num_epochs] 300  
                      [               num_layers] 2  
                      [        regression_layers] [40, 40]  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-14 06:08:43] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 20, num_layers=2, batch_first=True)
                        (linear1): Linear (20 -> 40)
                        (linear2): Linear (40 -> 40)
                        (final): Linear (40 -> 1)
                      )
[2017-12-14 06:08:43]  *** Training on GPU ***
[2017-12-14 06:09:54] Epoch 0001 mean train/dev loss: 72433.7416 / 25740.4961
[2017-12-14 06:09:54] Checkpointing model...
[2017-12-14 06:09:55] Model Checkpointing finished.
[2017-12-14 06:11:05] Epoch 0002 mean train/dev loss: 17212.1094 / 7521.8169
[2017-12-14 06:11:05] Checkpointing model...
[2017-12-14 06:11:06] Model Checkpointing finished.
[2017-12-14 06:12:17] Epoch 0003 mean train/dev loss: 7161.1225 / 3363.5691
[2017-12-14 06:12:17] Checkpointing model...
[2017-12-14 06:12:18] Model Checkpointing finished.
[2017-12-14 06:13:28] Epoch 0004 mean train/dev loss: 1687.1040 / 1328.9287
[2017-12-14 06:13:28] Checkpointing model...
[2017-12-14 06:13:29] Model Checkpointing finished.
[2017-12-14 06:14:40] Epoch 0005 mean train/dev loss: 992.3847 / 867.5159
[2017-12-14 06:14:40] Checkpointing model...
[2017-12-14 06:14:40] Model Checkpointing finished.
[2017-12-14 06:15:51] Epoch 0006 mean train/dev loss: 842.2288 / 1678.1506
[2017-12-14 06:17:02] Epoch 0007 mean train/dev loss: 638.2241 / 711.5969
[2017-12-14 06:18:13] Epoch 0008 mean train/dev loss: 515.4690 / 1058.6553
[2017-12-14 06:19:24] Epoch 0009 mean train/dev loss: 643.5327 / 610.0574
[2017-12-14 06:20:34] Epoch 0010 mean train/dev loss: 578.2753 / 671.8138
[2017-12-14 06:20:34] Checkpointing model...
[2017-12-14 06:20:34] Model Checkpointing finished.
[2017-12-14 06:21:45] Epoch 0011 mean train/dev loss: 5529.0051 / 4309.5020
[2017-12-14 06:22:57] Epoch 0012 mean train/dev loss: 2674.0115 / 1831.0406
[2017-12-14 06:24:09] Epoch 0013 mean train/dev loss: 1168.3501 / 1205.7426
[2017-12-14 06:25:20] Epoch 0014 mean train/dev loss: 2077.5445 / 1274.3922
[2017-12-14 06:26:32] Epoch 0015 mean train/dev loss: 1098.7183 / 1036.5782
[2017-12-14 06:26:32] Learning rate decayed by 0.5000
[2017-12-14 06:26:32] Checkpointing model...
[2017-12-14 06:26:33] Model Checkpointing finished.
[2017-12-14 06:27:44] Epoch 0016 mean train/dev loss: 800.4411 / 767.2727
[2017-12-14 06:28:56] Epoch 0017 mean train/dev loss: 578.3463 / 739.3792
[2017-12-14 06:30:07] Epoch 0018 mean train/dev loss: 593.5281 / 584.4770
[2017-12-14 06:31:19] Epoch 0019 mean train/dev loss: 580.6116 / 528.2158
[2017-12-14 06:32:30] Epoch 0020 mean train/dev loss: 579.3729 / 1155.8831
[2017-12-14 06:32:30] Checkpointing model...
[2017-12-14 06:32:31] Model Checkpointing finished.
[2017-12-14 06:33:42] Epoch 0021 mean train/dev loss: 775.9235 / 773.4767
[2017-12-14 06:34:54] Epoch 0022 mean train/dev loss: 737.0023 / 1238.1654
[2017-12-14 06:36:06] Epoch 0023 mean train/dev loss: 848.3698 / 659.3792
[2017-12-14 06:37:17] Epoch 0024 mean train/dev loss: 591.4355 / 521.3954
[2017-12-14 06:38:27] Epoch 0025 mean train/dev loss: 581.1893 / 446.9472
[2017-12-14 06:38:27] Checkpointing model...
[2017-12-14 06:38:27] Model Checkpointing finished.
[2017-12-14 06:39:36] Epoch 0026 mean train/dev loss: 452.8783 / 416.6292
[2017-12-14 06:40:47] Epoch 0027 mean train/dev loss: 411.1393 / 482.9831
[2017-12-14 06:41:56] Epoch 0028 mean train/dev loss: 445.0988 / 573.6323
[2017-12-14 06:43:05] Epoch 0029 mean train/dev loss: 553.3917 / 722.2029
[2017-12-14 06:44:14] Epoch 0030 mean train/dev loss: 590.6735 / 600.6449
[2017-12-14 06:44:14] Learning rate decayed by 0.5000
[2017-12-14 06:44:14] Checkpointing model...
[2017-12-14 06:44:14] Model Checkpointing finished.
[2017-12-14 06:45:23] Epoch 0031 mean train/dev loss: 411.1765 / 604.2832
[2017-12-14 06:46:31] Epoch 0032 mean train/dev loss: 358.7349 / 537.3466
[2017-12-14 06:47:44] Epoch 0033 mean train/dev loss: 343.4704 / 610.6263
[2017-12-14 06:48:53] Epoch 0034 mean train/dev loss: 285.3401 / 568.7626
[2017-12-14 06:50:00] Epoch 0035 mean train/dev loss: 243.7878 / 420.9906
[2017-12-14 06:50:00] Checkpointing model...
[2017-12-14 06:50:00] Model Checkpointing finished.
[2017-12-14 06:51:09] Epoch 0036 mean train/dev loss: 219.0860 / 439.3543
[2017-12-14 06:52:17] Epoch 0037 mean train/dev loss: 210.6755 / 359.9747
[2017-12-14 06:53:26] Epoch 0038 mean train/dev loss: 201.6954 / 403.5799
[2017-12-14 06:54:35] Epoch 0039 mean train/dev loss: 176.3137 / 377.9133
[2017-12-14 06:55:42] Epoch 0040 mean train/dev loss: 194.9394 / 579.2659
[2017-12-14 06:55:42] Checkpointing model...
[2017-12-14 06:55:42] Model Checkpointing finished.
[2017-12-14 06:56:50] Epoch 0041 mean train/dev loss: 212.9879 / 429.7353
[2017-12-14 06:57:59] Epoch 0042 mean train/dev loss: 187.5604 / 378.8431
[2017-12-14 06:59:08] Epoch 0043 mean train/dev loss: 176.6447 / 380.7376
[2017-12-14 07:00:19] Epoch 0044 mean train/dev loss: 180.5099 / 331.6306
[2017-12-14 07:01:30] Epoch 0045 mean train/dev loss: 174.4525 / 365.7355
[2017-12-14 07:01:30] Learning rate decayed by 0.5000
[2017-12-14 07:01:30] Checkpointing model...
[2017-12-14 07:01:30] Model Checkpointing finished.
[2017-12-14 07:02:39] Epoch 0046 mean train/dev loss: 149.0582 / 323.0102
[2017-12-14 07:03:49] Epoch 0047 mean train/dev loss: 147.5390 / 338.2900
[2017-12-14 07:04:58] Epoch 0048 mean train/dev loss: 142.5888 / 327.9836
[2017-12-14 07:06:07] Epoch 0049 mean train/dev loss: 132.7481 / 307.8698
[2017-12-14 07:07:17] Epoch 0050 mean train/dev loss: 133.9231 / 361.9880
[2017-12-14 07:07:17] Checkpointing model...
[2017-12-14 07:07:17] Model Checkpointing finished.
[2017-12-14 07:08:25] Epoch 0051 mean train/dev loss: 140.1708 / 331.3454
[2017-12-14 07:09:35] Epoch 0052 mean train/dev loss: 135.6734 / 312.0783
[2017-12-14 07:10:43] Epoch 0053 mean train/dev loss: 134.6991 / 300.6531
[2017-12-14 07:11:51] Epoch 0054 mean train/dev loss: 127.2480 / 305.4640
[2017-12-14 07:13:00] Epoch 0055 mean train/dev loss: 126.3439 / 285.5167
[2017-12-14 07:13:00] Checkpointing model...
[2017-12-14 07:13:00] Model Checkpointing finished.
[2017-12-14 07:14:08] Epoch 0056 mean train/dev loss: 136.5427 / 357.3622
[2017-12-14 07:15:16] Epoch 0057 mean train/dev loss: 135.8988 / 308.9699
[2017-12-14 07:16:24] Epoch 0058 mean train/dev loss: 126.3200 / 260.8637
[2017-12-14 07:17:33] Epoch 0059 mean train/dev loss: 132.6876 / 314.8768
[2017-12-14 07:18:42] Epoch 0060 mean train/dev loss: 145.7768 / 333.9051
[2017-12-14 07:18:42] Learning rate decayed by 0.5000
[2017-12-14 07:18:42] Checkpointing model...
[2017-12-14 07:18:42] Model Checkpointing finished.
[2017-12-14 07:19:49] Epoch 0061 mean train/dev loss: 126.0827 / 265.9334
[2017-12-14 07:20:56] Epoch 0062 mean train/dev loss: 118.5283 / 266.3943
[2017-12-14 07:22:03] Epoch 0063 mean train/dev loss: 115.7709 / 264.0924
[2017-12-14 07:23:09] Epoch 0064 mean train/dev loss: 115.2153 / 248.7638
[2017-12-14 07:24:16] Epoch 0065 mean train/dev loss: 117.0715 / 293.7699
[2017-12-14 07:24:16] Checkpointing model...
[2017-12-14 07:24:17] Model Checkpointing finished.
[2017-12-14 07:25:23] Epoch 0066 mean train/dev loss: 117.7567 / 246.1646
[2017-12-14 07:26:30] Epoch 0067 mean train/dev loss: 113.7174 / 238.3028
[2017-12-14 07:27:37] Epoch 0068 mean train/dev loss: 115.2417 / 254.9877
[2017-12-14 07:28:45] Epoch 0069 mean train/dev loss: 113.7593 / 247.3351
[2017-12-14 07:29:54] Epoch 0070 mean train/dev loss: 112.7520 / 263.1879
[2017-12-14 07:29:54] Checkpointing model...
[2017-12-14 07:29:54] Model Checkpointing finished.
[2017-12-14 07:31:01] Epoch 0071 mean train/dev loss: 111.2749 / 237.7578
[2017-12-14 07:32:09] Epoch 0072 mean train/dev loss: 109.3125 / 245.8624
[2017-12-14 07:33:16] Epoch 0073 mean train/dev loss: 114.0829 / 241.9397
[2017-12-14 07:34:23] Epoch 0074 mean train/dev loss: 111.3282 / 230.4919
[2017-12-14 07:35:33] Epoch 0075 mean train/dev loss: 110.8548 / 249.3211
[2017-12-14 07:35:33] Learning rate decayed by 0.5000
[2017-12-14 07:35:33] Checkpointing model...
[2017-12-14 07:35:34] Model Checkpointing finished.
[2017-12-14 07:36:41] Epoch 0076 mean train/dev loss: 107.9710 / 237.0091
[2017-12-14 07:37:48] Epoch 0077 mean train/dev loss: 106.9748 / 225.6972
[2017-12-14 07:38:56] Epoch 0078 mean train/dev loss: 105.1305 / 229.7186
[2017-12-14 07:40:06] Epoch 0079 mean train/dev loss: 104.1065 / 221.1240
[2017-12-14 07:41:18] Epoch 0080 mean train/dev loss: 103.6516 / 224.9345
[2017-12-14 07:41:18] Checkpointing model...
[2017-12-14 07:41:18] Model Checkpointing finished.
[2017-12-14 07:42:30] Epoch 0081 mean train/dev loss: 104.3515 / 226.7906
[2017-12-14 07:43:39] Epoch 0082 mean train/dev loss: 102.6879 / 220.8682
[2017-12-14 07:44:49] Epoch 0083 mean train/dev loss: 103.1675 / 227.6633
[2017-12-14 07:45:59] Epoch 0084 mean train/dev loss: 103.6891 / 223.4528
[2017-12-14 07:47:10] Epoch 0085 mean train/dev loss: 102.5524 / 217.5312
[2017-12-14 07:47:10] Checkpointing model...
[2017-12-14 07:47:10] Model Checkpointing finished.
[2017-12-14 07:48:21] Epoch 0086 mean train/dev loss: 103.2809 / 220.0565
[2017-12-14 07:49:32] Epoch 0087 mean train/dev loss: 102.8166 / 210.6069
[2017-12-14 07:50:42] Epoch 0088 mean train/dev loss: 103.2375 / 227.8746
[2017-12-14 07:51:52] Epoch 0089 mean train/dev loss: 102.0163 / 213.5142
[2017-12-14 07:53:03] Epoch 0090 mean train/dev loss: 101.3917 / 221.4066
[2017-12-14 07:53:03] Learning rate decayed by 0.5000
[2017-12-14 07:53:03] Checkpointing model...
[2017-12-14 07:53:03] Model Checkpointing finished.
[2017-12-14 07:54:14] Epoch 0091 mean train/dev loss: 100.4049 / 209.1125
[2017-12-14 07:55:25] Epoch 0092 mean train/dev loss: 98.9904 / 207.2606
[2017-12-14 07:56:36] Epoch 0093 mean train/dev loss: 98.6218 / 213.9294
[2017-12-14 07:57:46] Epoch 0094 mean train/dev loss: 98.1706 / 206.3455
[2017-12-14 07:58:57] Epoch 0095 mean train/dev loss: 97.4555 / 213.2168
[2017-12-14 07:58:57] Checkpointing model...
[2017-12-14 07:58:57] Model Checkpointing finished.
[2017-12-14 08:00:08] Epoch 0096 mean train/dev loss: 97.2704 / 209.7674
[2017-12-14 08:01:19] Epoch 0097 mean train/dev loss: 98.3949 / 207.9722
[2017-12-14 08:02:29] Epoch 0098 mean train/dev loss: 97.1905 / 211.8880
[2017-12-14 08:03:40] Epoch 0099 mean train/dev loss: 98.2136 / 201.9054
[2017-12-14 08:04:50] Epoch 0100 mean train/dev loss: 97.1647 / 206.0292
[2017-12-14 08:04:50] Checkpointing model...
[2017-12-14 08:04:51] Model Checkpointing finished.
[2017-12-14 08:06:02] Epoch 0101 mean train/dev loss: 97.4302 / 212.9961
[2017-12-14 08:07:12] Epoch 0102 mean train/dev loss: 96.6262 / 198.6529
[2017-12-14 08:08:23] Epoch 0103 mean train/dev loss: 97.6653 / 201.5175
[2017-12-14 08:09:34] Epoch 0104 mean train/dev loss: 98.5776 / 193.2726
[2017-12-14 08:10:45] Epoch 0105 mean train/dev loss: 96.4597 / 195.6587
[2017-12-14 08:10:45] Learning rate decayed by 0.5000
[2017-12-14 08:10:45] Checkpointing model...
[2017-12-14 08:10:45] Model Checkpointing finished.
[2017-12-14 08:11:56] Epoch 0106 mean train/dev loss: 94.1265 / 202.3904
[2017-12-14 08:13:07] Epoch 0107 mean train/dev loss: 93.8465 / 196.2971
[2017-12-14 08:14:18] Epoch 0108 mean train/dev loss: 93.4828 / 198.1037
[2017-12-14 08:15:29] Epoch 0109 mean train/dev loss: 95.1933 / 202.0786
[2017-12-14 08:16:40] Epoch 0110 mean train/dev loss: 93.8793 / 200.2476
[2017-12-14 08:16:40] Checkpointing model...
[2017-12-14 08:16:40] Model Checkpointing finished.
[2017-12-14 08:17:51] Epoch 0111 mean train/dev loss: 94.4354 / 199.1754
[2017-12-14 08:19:03] Epoch 0112 mean train/dev loss: 93.9033 / 193.8041
[2017-12-14 08:20:14] Epoch 0113 mean train/dev loss: 93.2263 / 196.9144
[2017-12-14 08:21:26] Epoch 0114 mean train/dev loss: 92.3685 / 201.0320
[2017-12-14 08:22:37] Epoch 0115 mean train/dev loss: 93.2673 / 202.2293
[2017-12-14 08:22:37] Checkpointing model...
[2017-12-14 08:22:37] Model Checkpointing finished.
[2017-12-14 08:23:48] Epoch 0116 mean train/dev loss: 93.3500 / 193.5092
[2017-12-14 08:24:58] Epoch 0117 mean train/dev loss: 93.3050 / 196.8609
[2017-12-14 08:26:09] Epoch 0118 mean train/dev loss: 92.4814 / 192.1268
[2017-12-14 08:27:20] Epoch 0119 mean train/dev loss: 93.4686 / 197.6956
[2017-12-14 08:28:31] Epoch 0120 mean train/dev loss: 92.5435 / 187.3218
[2017-12-14 08:28:31] Learning rate decayed by 0.5000
[2017-12-14 08:28:31] Checkpointing model...
[2017-12-14 08:28:32] Model Checkpointing finished.
[2017-12-14 08:29:43] Epoch 0121 mean train/dev loss: 91.9339 / 191.5955
[2017-12-14 08:30:54] Epoch 0122 mean train/dev loss: 91.6943 / 192.2471
[2017-12-14 08:32:04] Epoch 0123 mean train/dev loss: 90.9772 / 189.4269
[2017-12-14 08:33:15] Epoch 0124 mean train/dev loss: 90.9846 / 196.4373
[2017-12-14 08:34:26] Epoch 0125 mean train/dev loss: 90.9577 / 191.8417
[2017-12-14 08:34:26] Checkpointing model...
[2017-12-14 08:34:27] Model Checkpointing finished.
[2017-12-14 08:35:38] Epoch 0126 mean train/dev loss: 91.8813 / 190.7012
[2017-12-14 08:36:49] Epoch 0127 mean train/dev loss: 91.7357 / 200.4682
[2017-12-14 08:38:00] Epoch 0128 mean train/dev loss: 91.2449 / 187.8908
[2017-12-14 08:39:11] Epoch 0129 mean train/dev loss: 91.1793 / 189.1259
[2017-12-14 08:40:22] Epoch 0130 mean train/dev loss: 90.4822 / 184.7905
[2017-12-14 08:40:22] Checkpointing model...
[2017-12-14 08:40:22] Model Checkpointing finished.
[2017-12-14 08:41:33] Epoch 0131 mean train/dev loss: 90.6825 / 195.6694
[2017-12-14 08:42:44] Epoch 0132 mean train/dev loss: 91.0253 / 194.5352
[2017-12-14 08:43:55] Epoch 0133 mean train/dev loss: 91.6181 / 186.4346
[2017-12-14 08:45:06] Epoch 0134 mean train/dev loss: 90.3686 / 188.0122
[2017-12-14 08:46:17] Epoch 0135 mean train/dev loss: 90.5015 / 185.6252
[2017-12-14 08:46:17] Learning rate decayed by 0.5000
[2017-12-14 08:46:17] Checkpointing model...
[2017-12-14 08:46:18] Model Checkpointing finished.
[2017-12-14 08:47:29] Epoch 0136 mean train/dev loss: 89.9167 / 187.7696
[2017-12-14 08:48:41] Epoch 0137 mean train/dev loss: 89.9301 / 185.5937
[2017-12-14 08:49:52] Epoch 0138 mean train/dev loss: 89.8284 / 190.5566
[2017-12-14 08:51:03] Epoch 0139 mean train/dev loss: 89.6310 / 189.9213
[2017-12-14 08:52:14] Epoch 0140 mean train/dev loss: 89.7450 / 184.8543
[2017-12-14 08:52:14] Checkpointing model...
[2017-12-14 08:52:15] Model Checkpointing finished.
[2017-12-14 08:53:27] Epoch 0141 mean train/dev loss: 89.6209 / 185.0876
[2017-12-14 08:54:37] Epoch 0142 mean train/dev loss: 89.9577 / 185.9615
[2017-12-14 08:55:48] Epoch 0143 mean train/dev loss: 89.4513 / 187.0519
[2017-12-14 08:56:59] Epoch 0144 mean train/dev loss: 89.2982 / 184.7232
[2017-12-14 08:58:10] Epoch 0145 mean train/dev loss: 90.2577 / 190.4826
[2017-12-14 08:58:10] Checkpointing model...
[2017-12-14 08:58:11] Model Checkpointing finished.
[2017-12-14 08:59:22] Epoch 0146 mean train/dev loss: 92.4650 / 184.5769
[2017-12-14 09:00:33] Epoch 0147 mean train/dev loss: 89.4278 / 188.4210
[2017-12-14 09:01:44] Epoch 0148 mean train/dev loss: 89.3262 / 184.0504
[2017-12-14 09:02:55] Epoch 0149 mean train/dev loss: 89.1209 / 186.8790
[2017-12-14 09:04:06] Epoch 0150 mean train/dev loss: 89.3955 / 189.5773
[2017-12-14 09:04:06] Learning rate decayed by 0.5000
[2017-12-14 09:04:06] Checkpointing model...
[2017-12-14 09:04:06] Model Checkpointing finished.
[2017-12-14 09:05:17] Epoch 0151 mean train/dev loss: 89.1145 / 185.5979
[2017-12-14 09:06:29] Epoch 0152 mean train/dev loss: 88.9121 / 187.5877
[2017-12-14 09:07:41] Epoch 0153 mean train/dev loss: 89.0386 / 187.2847
[2017-12-14 09:08:52] Epoch 0154 mean train/dev loss: 88.9579 / 186.3113
[2017-12-14 09:10:03] Epoch 0155 mean train/dev loss: 88.9291 / 188.4268
[2017-12-14 09:10:03] Checkpointing model...
[2017-12-14 09:10:04] Model Checkpointing finished.
[2017-12-14 09:11:15] Epoch 0156 mean train/dev loss: 88.7544 / 186.6009
[2017-12-14 09:12:25] Epoch 0157 mean train/dev loss: 88.6885 / 185.9828
[2017-12-14 09:13:36] Epoch 0158 mean train/dev loss: 88.9377 / 187.2241
[2017-12-14 09:14:47] Epoch 0159 mean train/dev loss: 88.6922 / 186.6588
[2017-12-14 09:15:59] Epoch 0160 mean train/dev loss: 88.8306 / 189.1415
[2017-12-14 09:15:59] Checkpointing model...
[2017-12-14 09:15:59] Model Checkpointing finished.
[2017-12-14 09:17:11] Epoch 0161 mean train/dev loss: 88.6049 / 185.5582
[2017-12-14 09:18:21] Epoch 0162 mean train/dev loss: 88.9144 / 184.5203
[2017-12-14 09:19:33] Epoch 0163 mean train/dev loss: 88.7472 / 186.0905
[2017-12-14 09:20:44] Epoch 0164 mean train/dev loss: 88.5656 / 186.7066
[2017-12-14 09:21:55] Epoch 0165 mean train/dev loss: 88.7925 / 186.9221
[2017-12-14 09:21:55] Learning rate decayed by 0.5000
[2017-12-14 09:21:55] Checkpointing model...
[2017-12-14 09:21:55] Model Checkpointing finished.
[2017-12-14 09:23:06] Epoch 0166 mean train/dev loss: 88.7449 / 186.5634
[2017-12-14 09:24:18] Epoch 0167 mean train/dev loss: 88.5196 / 184.0782
[2017-12-14 09:25:28] Epoch 0168 mean train/dev loss: 88.3119 / 185.7800
[2017-12-14 09:26:39] Epoch 0169 mean train/dev loss: 88.3614 / 185.7842
[2017-12-14 09:27:51] Epoch 0170 mean train/dev loss: 88.3871 / 187.1539
[2017-12-14 09:27:51] Checkpointing model...
[2017-12-14 09:27:52] Model Checkpointing finished.
[2017-12-14 09:29:03] Epoch 0171 mean train/dev loss: 88.4761 / 185.2536
[2017-12-14 09:30:14] Epoch 0172 mean train/dev loss: 88.3754 / 186.9954
[2017-12-14 09:31:25] Epoch 0173 mean train/dev loss: 88.4363 / 184.6947
[2017-12-14 09:32:36] Epoch 0174 mean train/dev loss: 88.4239 / 184.9126
[2017-12-14 09:33:48] Epoch 0175 mean train/dev loss: 88.2608 / 186.5476
[2017-12-14 09:33:48] Checkpointing model...
[2017-12-14 09:33:48] Model Checkpointing finished.
[2017-12-14 09:34:58] Epoch 0176 mean train/dev loss: 88.5394 / 185.8120
[2017-12-14 09:36:09] Epoch 0177 mean train/dev loss: 88.2195 / 186.6962
[2017-12-14 09:37:20] Epoch 0178 mean train/dev loss: 88.1893 / 186.1686
[2017-12-14 09:38:31] Epoch 0179 mean train/dev loss: 88.1048 / 187.6874
[2017-12-14 09:39:42] Epoch 0180 mean train/dev loss: 88.2304 / 186.4024
[2017-12-14 09:39:42] Learning rate decayed by 0.5000
[2017-12-14 09:39:42] Checkpointing model...
[2017-12-14 09:39:42] Model Checkpointing finished.
[2017-12-14 09:40:53] Epoch 0181 mean train/dev loss: 88.2719 / 185.6659
[2017-12-14 09:42:04] Epoch 0182 mean train/dev loss: 88.1611 / 187.2409
[2017-12-14 09:43:15] Epoch 0183 mean train/dev loss: 88.0809 / 184.8843
[2017-12-14 09:44:27] Epoch 0184 mean train/dev loss: 88.0034 / 186.3916
[2017-12-14 09:45:40] Epoch 0185 mean train/dev loss: 87.7740 / 185.4121
[2017-12-14 09:45:40] Checkpointing model...
[2017-12-14 09:45:40] Model Checkpointing finished.
[2017-12-14 09:46:52] Epoch 0186 mean train/dev loss: 88.7028 / 185.4605
[2017-12-14 09:48:04] Epoch 0187 mean train/dev loss: 88.0162 / 184.9001
[2017-12-14 09:49:16] Epoch 0188 mean train/dev loss: 87.9932 / 185.7208
[2017-12-14 09:50:28] Epoch 0189 mean train/dev loss: 87.8424 / 185.4874
[2017-12-14 09:50:28] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-14 09:50:28] 
                       *** Training finished *** 
[2017-12-14 09:50:35] Dev MSE: 185.4874
[2017-12-14 09:51:37] Training MSE: 87.9940
[2017-12-14 09:51:39] Experiment lstm.hs_20.nl_2.lr_0.1.wd_0.001.rl_40_40 logging ended.
