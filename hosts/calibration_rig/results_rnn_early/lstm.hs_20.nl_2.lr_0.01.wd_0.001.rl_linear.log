[2017-12-15 02:50:30] Experiment lstm.hs_20.nl_2.lr_0.01.wd_0.001.rl_linear logging started.
[2017-12-15 02:50:30] 
                       *** Starting Experiment lstm.hs_20.nl_2.lr_0.01.wd_0.001.rl_linear ***
                      
[2017-12-15 02:50:30] Hyper parameters
                      [               batch_size] 64  
                      [           dataset_prefix] 20171209.1220  
                      [                 dump_dir] results_rnn_early  
                      [               early_stop] 40  
                      [              hidden_size] 20  
                      [                input_dim] 12  
                      [                  loss_fn] MSELoss ()  
                      [                 lr_decay] 0.5  
                      [            lr_decay_freq] 15  
                      [                  lr_init] 0.01  
                      [               num_epochs] 300  
                      [               num_layers] 2  
                      [        regression_layers] None  
                      [                 use_cuda] True  
                      [             weight_decay] 0.001  
[2017-12-15 02:50:32] Model architecture
                      SequentialRegression (
                        (lstm): LSTM(12, 20, num_layers=2, batch_first=True)
                        (final): Linear (20 -> 1)
                      )
[2017-12-15 02:50:32]  *** Training on GPU ***
[2017-12-15 02:51:35] Epoch 0001 mean train/dev loss: 326814.1266 / 323828.2812
[2017-12-15 02:51:35] Checkpointing model...
[2017-12-15 02:51:36] Model Checkpointing finished.
[2017-12-15 02:52:37] Epoch 0002 mean train/dev loss: 315357.5383 / 313200.1562
[2017-12-15 02:52:37] Checkpointing model...
[2017-12-15 02:52:37] Model Checkpointing finished.
[2017-12-15 02:53:38] Epoch 0003 mean train/dev loss: 305443.1869 / 303182.7812
[2017-12-15 02:53:38] Checkpointing model...
[2017-12-15 02:53:38] Model Checkpointing finished.
[2017-12-15 02:54:42] Epoch 0004 mean train/dev loss: 295594.6429 / 293623.2188
[2017-12-15 02:54:42] Checkpointing model...
[2017-12-15 02:54:42] Model Checkpointing finished.
[2017-12-15 02:55:46] Epoch 0005 mean train/dev loss: 286430.3597 / 284459.7500
[2017-12-15 02:55:46] Checkpointing model...
[2017-12-15 02:55:46] Model Checkpointing finished.
[2017-12-15 02:56:47] Epoch 0006 mean train/dev loss: 277528.7041 / 275588.3125
[2017-12-15 02:57:52] Epoch 0007 mean train/dev loss: 268891.2771 / 267011.0000
[2017-12-15 02:58:54] Epoch 0008 mean train/dev loss: 260033.6834 / 258729.6406
[2017-12-15 02:59:56] Epoch 0009 mean train/dev loss: 251699.9011 / 250732.5312
[2017-12-15 03:00:58] Epoch 0010 mean train/dev loss: 244069.7152 / 242910.2344
[2017-12-15 03:00:58] Checkpointing model...
[2017-12-15 03:00:58] Model Checkpointing finished.
[2017-12-15 03:01:57] Epoch 0011 mean train/dev loss: 236097.0246 / 235415.0000
[2017-12-15 03:02:59] Epoch 0012 mean train/dev loss: 228930.3396 / 228113.3906
[2017-12-15 03:04:01] Epoch 0013 mean train/dev loss: 221259.7812 / 221087.5938
[2017-12-15 03:05:02] Epoch 0014 mean train/dev loss: 214894.5067 / 214300.2500
[2017-12-15 03:06:01] Epoch 0015 mean train/dev loss: 208216.8151 / 207712.0469
[2017-12-15 03:06:01] Learning rate decayed by 0.5000
[2017-12-15 03:06:01] Checkpointing model...
[2017-12-15 03:06:02] Model Checkpointing finished.
[2017-12-15 03:07:04] Epoch 0016 mean train/dev loss: 203136.7605 / 204482.7344
[2017-12-15 03:08:09] Epoch 0017 mean train/dev loss: 200407.8492 / 201336.3750
[2017-12-15 03:09:13] Epoch 0018 mean train/dev loss: 196923.6154 / 198172.5938
[2017-12-15 03:10:15] Epoch 0019 mean train/dev loss: 193406.8364 / 194991.2188
[2017-12-15 03:11:16] Epoch 0020 mean train/dev loss: 190346.2758 / 191894.7188
[2017-12-15 03:11:16] Checkpointing model...
[2017-12-15 03:11:16] Model Checkpointing finished.
[2017-12-15 03:12:17] Epoch 0021 mean train/dev loss: 187824.2841 / 188842.8906
[2017-12-15 03:13:19] Epoch 0022 mean train/dev loss: 184323.5944 / 185830.9219
[2017-12-15 03:14:18] Epoch 0023 mean train/dev loss: 181550.1572 / 182854.1875
[2017-12-15 03:15:20] Epoch 0024 mean train/dev loss: 179084.1738 / 179921.7500
[2017-12-15 03:16:21] Epoch 0025 mean train/dev loss: 175745.0096 / 177028.8281
[2017-12-15 03:16:21] Checkpointing model...
[2017-12-15 03:16:22] Model Checkpointing finished.
[2017-12-15 03:17:25] Epoch 0026 mean train/dev loss: 172902.8973 / 174082.9062
[2017-12-15 03:18:28] Epoch 0027 mean train/dev loss: 170175.7991 / 171256.7031
[2017-12-15 03:19:32] Epoch 0028 mean train/dev loss: 167262.9896 / 168584.8438
[2017-12-15 03:20:37] Epoch 0029 mean train/dev loss: 164547.8136 / 165926.5000
[2017-12-15 03:21:35] Epoch 0030 mean train/dev loss: 161736.5375 / 163169.7969
[2017-12-15 03:21:35] Learning rate decayed by 0.5000
[2017-12-15 03:21:35] Checkpointing model...
[2017-12-15 03:21:35] Model Checkpointing finished.
[2017-12-15 03:22:39] Epoch 0031 mean train/dev loss: 160015.3764 / 161835.4219
[2017-12-15 03:23:43] Epoch 0032 mean train/dev loss: 158493.1996 / 160503.9219
[2017-12-15 03:24:43] Epoch 0033 mean train/dev loss: 157482.9807 / 159186.1406
[2017-12-15 03:25:47] Epoch 0034 mean train/dev loss: 155907.1722 / 157867.2344
[2017-12-15 03:26:48] Epoch 0035 mean train/dev loss: 154304.1073 / 156432.7812
[2017-12-15 03:26:48] Checkpointing model...
[2017-12-15 03:26:48] Model Checkpointing finished.
[2017-12-15 03:27:46] Epoch 0036 mean train/dev loss: 153036.8798 / 155033.9375
[2017-12-15 03:28:47] Epoch 0037 mean train/dev loss: 151429.1872 / 153700.6719
[2017-12-15 03:29:47] Epoch 0038 mean train/dev loss: 150572.8385 / 152387.0156
[2017-12-15 03:30:48] Epoch 0039 mean train/dev loss: 148958.7299 / 151084.3594
[2017-12-15 03:31:51] Epoch 0040 mean train/dev loss: 147768.8130 / 149789.3125
[2017-12-15 03:31:51] Checkpointing model...
[2017-12-15 03:31:51] Model Checkpointing finished.
[2017-12-15 03:32:54] Epoch 0041 mean train/dev loss: 146371.0904 / 148497.7031
[2017-12-15 03:33:55] Epoch 0042 mean train/dev loss: 145102.2352 / 147217.1719
[2017-12-15 03:34:57] Epoch 0043 mean train/dev loss: 143729.1110 / 145952.1094
[2017-12-15 03:35:59] Epoch 0044 mean train/dev loss: 142598.2636 / 144679.2344
[2017-12-15 03:36:58] Epoch 0045 mean train/dev loss: 141372.9614 / 143415.0938
[2017-12-15 03:36:58] Learning rate decayed by 0.5000
[2017-12-15 03:36:58] Checkpointing model...
[2017-12-15 03:36:59] Model Checkpointing finished.
[2017-12-15 03:38:00] Epoch 0046 mean train/dev loss: 140612.1405 / 142778.5781
[2017-12-15 03:39:03] Epoch 0047 mean train/dev loss: 139755.3348 / 142042.1562
[2017-12-15 03:40:01] Epoch 0048 mean train/dev loss: 139206.3198 / 141282.2812
[2017-12-15 03:41:01] Epoch 0049 mean train/dev loss: 138139.1105 / 140618.2188
[2017-12-15 03:42:03] Epoch 0050 mean train/dev loss: 137562.5320 / 139991.0156
[2017-12-15 03:42:03] Checkpointing model...
[2017-12-15 03:42:04] Model Checkpointing finished.
[2017-12-15 03:43:05] Epoch 0051 mean train/dev loss: 136908.1739 / 139324.7656
[2017-12-15 03:44:05] Epoch 0052 mean train/dev loss: 136467.6912 / 138676.3125
[2017-12-15 03:45:08] Epoch 0053 mean train/dev loss: 135832.2647 / 138018.3125
[2017-12-15 03:46:09] Epoch 0054 mean train/dev loss: 134933.2390 / 137369.2656
[2017-12-15 03:47:10] Epoch 0055 mean train/dev loss: 134590.0340 / 136730.8906
[2017-12-15 03:47:10] Checkpointing model...
[2017-12-15 03:47:10] Model Checkpointing finished.
[2017-12-15 03:48:11] Epoch 0056 mean train/dev loss: 133585.4195 / 136092.5625
[2017-12-15 03:49:11] Epoch 0057 mean train/dev loss: 133278.9688 / 135462.3281
[2017-12-15 03:50:09] Epoch 0058 mean train/dev loss: 132705.7298 / 134823.4219
[2017-12-15 03:51:05] Epoch 0059 mean train/dev loss: 132018.7883 / 134190.8281
[2017-12-15 03:52:05] Epoch 0060 mean train/dev loss: 131185.9649 / 133557.5781
[2017-12-15 03:52:05] Learning rate decayed by 0.5000
[2017-12-15 03:52:05] Checkpointing model...
[2017-12-15 03:52:06] Model Checkpointing finished.
[2017-12-15 03:53:07] Epoch 0061 mean train/dev loss: 130874.4011 / 133240.5469
[2017-12-15 03:54:08] Epoch 0062 mean train/dev loss: 130486.1912 / 132923.1094
[2017-12-15 03:55:08] Epoch 0063 mean train/dev loss: 130248.9750 / 132608.7188
[2017-12-15 03:56:08] Epoch 0064 mean train/dev loss: 129888.0378 / 132287.1562
[2017-12-15 03:57:10] Epoch 0065 mean train/dev loss: 129452.8359 / 131970.9062
[2017-12-15 03:57:10] Checkpointing model...
[2017-12-15 03:57:10] Model Checkpointing finished.
[2017-12-15 03:58:10] Epoch 0066 mean train/dev loss: 129433.9689 / 131652.7969
[2017-12-15 03:59:12] Epoch 0067 mean train/dev loss: 128863.6507 / 131331.7500
[2017-12-15 04:00:13] Epoch 0068 mean train/dev loss: 128204.5655 / 131014.7188
[2017-12-15 04:01:14] Epoch 0069 mean train/dev loss: 128648.4595 / 130809.7578
[2017-12-15 04:02:12] Epoch 0070 mean train/dev loss: 128106.6789 / 130450.4219
[2017-12-15 04:02:12] Checkpointing model...
[2017-12-15 04:02:12] Model Checkpointing finished.
[2017-12-15 04:03:13] Epoch 0071 mean train/dev loss: 127669.6751 / 130115.2188
[2017-12-15 04:04:16] Epoch 0072 mean train/dev loss: 127415.3761 / 129788.6172
[2017-12-15 04:05:17] Epoch 0073 mean train/dev loss: 127051.7607 / 129462.5781
[2017-12-15 04:06:21] Epoch 0074 mean train/dev loss: 126832.7974 / 129139.3047
[2017-12-15 04:07:23] Epoch 0075 mean train/dev loss: 126393.9923 / 128815.3906
[2017-12-15 04:07:23] Learning rate decayed by 0.5000
[2017-12-15 04:07:23] Checkpointing model...
[2017-12-15 04:07:24] Model Checkpointing finished.
[2017-12-15 04:08:25] Epoch 0076 mean train/dev loss: 125986.8101 / 128654.5859
[2017-12-15 04:09:25] Epoch 0077 mean train/dev loss: 125911.2323 / 128493.8203
[2017-12-15 04:10:25] Epoch 0078 mean train/dev loss: 125731.3627 / 128331.5703
[2017-12-15 04:11:27] Epoch 0079 mean train/dev loss: 125579.2645 / 128172.6875
[2017-12-15 04:12:26] Epoch 0080 mean train/dev loss: 125602.2999 / 128012.0859
[2017-12-15 04:12:26] Checkpointing model...
[2017-12-15 04:12:26] Model Checkpointing finished.
[2017-12-15 04:13:28] Epoch 0081 mean train/dev loss: 125495.6916 / 127850.7891
[2017-12-15 04:14:25] Epoch 0082 mean train/dev loss: 124877.7704 / 127689.7188
[2017-12-15 04:15:29] Epoch 0083 mean train/dev loss: 124833.6590 / 127529.0703
[2017-12-15 04:16:31] Epoch 0084 mean train/dev loss: 124844.2846 / 127369.3984
[2017-12-15 04:17:34] Epoch 0085 mean train/dev loss: 124848.1405 / 127206.4531
[2017-12-15 04:17:34] Checkpointing model...
[2017-12-15 04:17:35] Model Checkpointing finished.
[2017-12-15 04:18:37] Epoch 0086 mean train/dev loss: 124417.8852 / 127043.8516
[2017-12-15 04:19:38] Epoch 0087 mean train/dev loss: 124332.8428 / 126881.9531
[2017-12-15 04:20:39] Epoch 0088 mean train/dev loss: 123954.3557 / 126719.0078
[2017-12-15 04:21:41] Epoch 0089 mean train/dev loss: 124126.5140 / 126557.0703
[2017-12-15 04:22:41] Epoch 0090 mean train/dev loss: 123872.1172 / 126395.8359
[2017-12-15 04:22:41] Learning rate decayed by 0.5000
[2017-12-15 04:22:41] Checkpointing model...
[2017-12-15 04:22:42] Model Checkpointing finished.
[2017-12-15 04:23:43] Epoch 0091 mean train/dev loss: 123512.2444 / 126315.4766
[2017-12-15 04:24:45] Epoch 0092 mean train/dev loss: 123402.5633 / 126234.3047
[2017-12-15 04:25:47] Epoch 0093 mean train/dev loss: 123113.5026 / 126152.8984
[2017-12-15 04:26:47] Epoch 0094 mean train/dev loss: 123077.4322 / 126072.2188
[2017-12-15 04:27:47] Epoch 0095 mean train/dev loss: 123539.9680 / 125991.8750
[2017-12-15 04:27:47] Checkpointing model...
[2017-12-15 04:27:47] Model Checkpointing finished.
[2017-12-15 04:28:47] Epoch 0096 mean train/dev loss: 123233.3799 / 125910.2578
[2017-12-15 04:29:46] Epoch 0097 mean train/dev loss: 123203.9813 / 125829.7344
[2017-12-15 04:30:47] Epoch 0098 mean train/dev loss: 123198.3264 / 125748.2109
[2017-12-15 04:31:45] Epoch 0099 mean train/dev loss: 123257.7089 / 125666.5703
[2017-12-15 04:32:42] Epoch 0100 mean train/dev loss: 122871.8597 / 125585.1953
[2017-12-15 04:32:42] Checkpointing model...
[2017-12-15 04:32:43] Model Checkpointing finished.
[2017-12-15 04:33:45] Epoch 0101 mean train/dev loss: 122953.0764 / 125501.2266
[2017-12-15 04:34:46] Epoch 0102 mean train/dev loss: 123284.6172 / 125420.8594
[2017-12-15 04:35:46] Epoch 0103 mean train/dev loss: 122798.0143 / 125339.0625
[2017-12-15 04:36:46] Epoch 0104 mean train/dev loss: 122719.7125 / 125257.9688
[2017-12-15 04:37:48] Epoch 0105 mean train/dev loss: 122709.7165 / 125175.8125
[2017-12-15 04:37:48] Learning rate decayed by 0.5000
[2017-12-15 04:37:48] Checkpointing model...
[2017-12-15 04:37:48] Model Checkpointing finished.
[2017-12-15 04:38:50] Epoch 0106 mean train/dev loss: 122166.3876 / 125135.0547
[2017-12-15 04:39:53] Epoch 0107 mean train/dev loss: 122457.2816 / 125094.5078
[2017-12-15 04:40:55] Epoch 0108 mean train/dev loss: 122163.5496 / 125053.8672
[2017-12-15 04:41:54] Epoch 0109 mean train/dev loss: 122545.2527 / 125013.0859
[2017-12-15 04:42:54] Epoch 0110 mean train/dev loss: 122267.7573 / 124972.0703
[2017-12-15 04:42:54] Checkpointing model...
[2017-12-15 04:42:55] Model Checkpointing finished.
[2017-12-15 04:43:53] Epoch 0111 mean train/dev loss: 122128.8230 / 124931.6172
[2017-12-15 04:44:56] Epoch 0112 mean train/dev loss: 122564.0871 / 124891.0469
[2017-12-15 04:45:58] Epoch 0113 mean train/dev loss: 122156.8643 / 124849.7344
[2017-12-15 04:46:58] Epoch 0114 mean train/dev loss: 122196.6783 / 124809.1094
[2017-12-15 04:47:57] Epoch 0115 mean train/dev loss: 122030.3447 / 124767.8906
[2017-12-15 04:47:57] Checkpointing model...
[2017-12-15 04:47:57] Model Checkpointing finished.
[2017-12-15 04:48:55] Epoch 0116 mean train/dev loss: 122265.9791 / 124727.1641
[2017-12-15 04:49:53] Epoch 0117 mean train/dev loss: 122189.7380 / 124686.5703
[2017-12-15 04:50:55] Epoch 0118 mean train/dev loss: 121982.9394 / 124644.9766
[2017-12-15 04:51:54] Epoch 0119 mean train/dev loss: 121996.0461 / 124604.1797
[2017-12-15 04:52:53] Epoch 0120 mean train/dev loss: 122054.2862 / 124563.1953
[2017-12-15 04:52:53] Learning rate decayed by 0.5000
[2017-12-15 04:52:53] Checkpointing model...
[2017-12-15 04:52:53] Model Checkpointing finished.
[2017-12-15 04:53:51] Epoch 0121 mean train/dev loss: 121936.2897 / 124542.5859
[2017-12-15 04:54:51] Epoch 0122 mean train/dev loss: 121940.7100 / 124522.1094
[2017-12-15 04:55:50] Epoch 0123 mean train/dev loss: 122297.2540 / 124501.7656
[2017-12-15 04:56:49] Epoch 0124 mean train/dev loss: 121794.4979 / 124480.9688
[2017-12-15 04:57:47] Epoch 0125 mean train/dev loss: 121915.9279 / 124460.3672
[2017-12-15 04:57:47] Checkpointing model...
[2017-12-15 04:57:48] Model Checkpointing finished.
[2017-12-15 04:58:49] Epoch 0126 mean train/dev loss: 121781.7309 / 124440.2969
[2017-12-15 04:59:47] Epoch 0127 mean train/dev loss: 121964.8850 / 124419.5156
[2017-12-15 05:00:47] Epoch 0128 mean train/dev loss: 121570.4190 / 124398.8672
[2017-12-15 05:01:46] Epoch 0129 mean train/dev loss: 121831.9431 / 124378.3047
[2017-12-15 05:02:47] Epoch 0130 mean train/dev loss: 121756.6937 / 124357.5547
[2017-12-15 05:02:47] Checkpointing model...
[2017-12-15 05:02:47] Model Checkpointing finished.
[2017-12-15 05:03:46] Epoch 0131 mean train/dev loss: 121491.6264 / 124337.2266
[2017-12-15 05:04:46] Epoch 0132 mean train/dev loss: 121484.7937 / 124316.6172
[2017-12-15 05:05:44] Epoch 0133 mean train/dev loss: 121535.9332 / 124295.9453
[2017-12-15 05:06:44] Epoch 0134 mean train/dev loss: 121850.9114 / 124275.2891
[2017-12-15 05:07:45] Epoch 0135 mean train/dev loss: 121635.1421 / 124254.7422
[2017-12-15 05:07:45] Learning rate decayed by 0.5000
[2017-12-15 05:07:45] Checkpointing model...
[2017-12-15 05:07:46] Model Checkpointing finished.
[2017-12-15 05:08:47] Epoch 0136 mean train/dev loss: 121782.0051 / 124244.4766
[2017-12-15 05:09:45] Epoch 0137 mean train/dev loss: 121425.9330 / 124234.2344
[2017-12-15 05:10:45] Epoch 0138 mean train/dev loss: 121490.9530 / 124223.9219
[2017-12-15 05:11:46] Epoch 0139 mean train/dev loss: 121657.7060 / 124213.6719
[2017-12-15 05:12:48] Epoch 0140 mean train/dev loss: 121827.7572 / 124203.3516
[2017-12-15 05:12:48] Checkpointing model...
[2017-12-15 05:12:48] Model Checkpointing finished.
[2017-12-15 05:13:48] Epoch 0141 mean train/dev loss: 121664.2932 / 124193.0234
[2017-12-15 05:14:45] Epoch 0142 mean train/dev loss: 121621.0113 / 124182.6641
[2017-12-15 05:15:45] Epoch 0143 mean train/dev loss: 121713.4185 / 124172.4531
[2017-12-15 05:16:47] Epoch 0144 mean train/dev loss: 121748.8048 / 124162.1016
[2017-12-15 05:17:46] Epoch 0145 mean train/dev loss: 121340.1165 / 124151.6562
[2017-12-15 05:17:46] Checkpointing model...
[2017-12-15 05:17:46] Model Checkpointing finished.
[2017-12-15 05:18:44] Epoch 0146 mean train/dev loss: 121687.0552 / 124141.4297
[2017-12-15 05:19:45] Epoch 0147 mean train/dev loss: 121308.1773 / 124131.1094
[2017-12-15 05:20:44] Epoch 0148 mean train/dev loss: 121254.8034 / 124120.7969
[2017-12-15 05:21:43] Epoch 0149 mean train/dev loss: 121575.9641 / 124110.5859
[2017-12-15 05:22:38] Epoch 0150 mean train/dev loss: 121332.9841 / 124100.3750
[2017-12-15 05:22:38] Learning rate decayed by 0.5000
[2017-12-15 05:22:38] Checkpointing model...
[2017-12-15 05:22:39] Model Checkpointing finished.
[2017-12-15 05:23:38] Epoch 0151 mean train/dev loss: 121763.9716 / 124095.1250
[2017-12-15 05:24:34] Epoch 0152 mean train/dev loss: 121508.6870 / 124090.0625
[2017-12-15 05:25:33] Epoch 0153 mean train/dev loss: 121329.4067 / 124084.9688
[2017-12-15 05:26:31] Epoch 0154 mean train/dev loss: 121349.4094 / 124079.8750
[2017-12-15 05:27:30] Epoch 0155 mean train/dev loss: 121144.5405 / 124074.7656
[2017-12-15 05:27:30] Checkpointing model...
[2017-12-15 05:27:31] Model Checkpointing finished.
[2017-12-15 05:28:29] Epoch 0156 mean train/dev loss: 121677.1264 / 124069.6953
[2017-12-15 05:29:28] Epoch 0157 mean train/dev loss: 121580.2812 / 124064.5547
[2017-12-15 05:30:26] Epoch 0158 mean train/dev loss: 121503.2669 / 124059.4531
[2017-12-15 05:31:25] Epoch 0159 mean train/dev loss: 121212.3076 / 124054.2734
[2017-12-15 05:32:25] Epoch 0160 mean train/dev loss: 121390.3874 / 124049.2812
[2017-12-15 05:32:25] Checkpointing model...
[2017-12-15 05:32:25] Model Checkpointing finished.
[2017-12-15 05:33:23] Epoch 0161 mean train/dev loss: 121893.8021 / 124044.1406
[2017-12-15 05:34:23] Epoch 0162 mean train/dev loss: 121446.7310 / 124039.0547
[2017-12-15 05:35:21] Epoch 0163 mean train/dev loss: 121537.1038 / 124034.0625
[2017-12-15 05:36:19] Epoch 0164 mean train/dev loss: 121325.9042 / 124028.9062
[2017-12-15 05:37:14] Epoch 0165 mean train/dev loss: 121292.8890 / 124023.8203
[2017-12-15 05:37:14] Learning rate decayed by 0.5000
[2017-12-15 05:37:14] Checkpointing model...
[2017-12-15 05:37:15] Model Checkpointing finished.
[2017-12-15 05:38:13] Epoch 0166 mean train/dev loss: 121280.6330 / 124021.2422
[2017-12-15 05:39:11] Epoch 0167 mean train/dev loss: 121247.2133 / 124018.7266
[2017-12-15 05:40:12] Epoch 0168 mean train/dev loss: 121495.3428 / 124016.1328
[2017-12-15 05:41:11] Epoch 0169 mean train/dev loss: 121434.5990 / 124013.6250
[2017-12-15 05:42:11] Epoch 0170 mean train/dev loss: 121098.6999 / 124011.0859
[2017-12-15 05:42:11] Checkpointing model...
[2017-12-15 05:42:11] Model Checkpointing finished.
[2017-12-15 05:43:10] Epoch 0171 mean train/dev loss: 121464.9471 / 124008.5234
[2017-12-15 05:44:08] Epoch 0172 mean train/dev loss: 121571.3551 / 124006.0312
[2017-12-15 05:45:08] Epoch 0173 mean train/dev loss: 121741.7835 / 124003.4219
[2017-12-15 05:46:05] Epoch 0174 mean train/dev loss: 121396.2982 / 124000.9141
[2017-12-15 05:47:02] Epoch 0175 mean train/dev loss: 121139.9254 / 123998.3906
[2017-12-15 05:47:02] Checkpointing model...
[2017-12-15 05:47:02] Model Checkpointing finished.
[2017-12-15 05:48:02] Epoch 0176 mean train/dev loss: 121438.7439 / 123995.7734
[2017-12-15 05:48:58] Epoch 0177 mean train/dev loss: 121464.6389 / 123993.2656
[2017-12-15 05:49:55] Epoch 0178 mean train/dev loss: 121373.1940 / 123990.7734
[2017-12-15 05:50:55] Epoch 0179 mean train/dev loss: 121774.1237 / 123988.1484
[2017-12-15 05:51:52] Epoch 0180 mean train/dev loss: 121279.0553 / 123985.6406
[2017-12-15 05:51:52] Learning rate decayed by 0.5000
[2017-12-15 05:51:52] Checkpointing model...
[2017-12-15 05:51:52] Model Checkpointing finished.
[2017-12-15 05:52:50] Epoch 0181 mean train/dev loss: 121674.0767 / 123984.2500
[2017-12-15 05:53:48] Epoch 0182 mean train/dev loss: 121286.7610 / 123982.7656
[2017-12-15 05:54:47] Epoch 0183 mean train/dev loss: 121269.8173 / 123981.2969
[2017-12-15 05:55:45] Epoch 0184 mean train/dev loss: 121513.5753 / 123979.8047
[2017-12-15 05:56:43] Epoch 0185 mean train/dev loss: 121413.7041 / 123978.3594
[2017-12-15 05:56:43] Checkpointing model...
[2017-12-15 05:56:43] Model Checkpointing finished.
[2017-12-15 05:57:43] Epoch 0186 mean train/dev loss: 121224.3632 / 123976.8906
[2017-12-15 05:58:40] Epoch 0187 mean train/dev loss: 121385.8766 / 123975.4609
[2017-12-15 05:59:39] Epoch 0188 mean train/dev loss: 121498.3296 / 123973.9609
[2017-12-15 06:00:36] Epoch 0189 mean train/dev loss: 121281.7650 / 123972.4688
[2017-12-15 06:01:37] Epoch 0190 mean train/dev loss: 121172.9201 / 123971.0703
[2017-12-15 06:01:37] Checkpointing model...
[2017-12-15 06:01:37] Model Checkpointing finished.
[2017-12-15 06:02:35] Epoch 0191 mean train/dev loss: 121255.2436 / 123969.6484
[2017-12-15 06:03:36] Epoch 0192 mean train/dev loss: 121546.2400 / 123968.1875
[2017-12-15 06:04:35] Epoch 0193 mean train/dev loss: 121513.5722 / 123966.7812
[2017-12-15 06:05:35] Epoch 0194 mean train/dev loss: 121439.7318 / 123965.3125
[2017-12-15 06:06:36] Epoch 0195 mean train/dev loss: 121289.5985 / 123963.9219
[2017-12-15 06:06:36] Learning rate decayed by 0.5000
[2017-12-15 06:06:36] Checkpointing model...
[2017-12-15 06:06:36] Model Checkpointing finished.
[2017-12-15 06:07:37] Epoch 0196 mean train/dev loss: 121397.9160 / 123963.4062
[2017-12-15 06:08:40] Epoch 0197 mean train/dev loss: 121083.6134 / 123962.8828
[2017-12-15 06:09:41] Epoch 0198 mean train/dev loss: 121353.9365 / 123962.3828
[2017-12-15 06:10:40] Epoch 0199 mean train/dev loss: 121495.7750 / 123961.8594
[2017-12-15 06:11:43] Epoch 0200 mean train/dev loss: 121311.4659 / 123961.3438
[2017-12-15 06:11:43] Checkpointing model...
[2017-12-15 06:11:43] Model Checkpointing finished.
[2017-12-15 06:12:43] Epoch 0201 mean train/dev loss: 121277.2577 / 123960.8438
[2017-12-15 06:13:45] Epoch 0202 mean train/dev loss: 121296.9695 / 123960.3203
[2017-12-15 06:14:46] Epoch 0203 mean train/dev loss: 120833.0343 / 123959.8438
[2017-12-15 06:15:46] Epoch 0204 mean train/dev loss: 121365.8988 / 123959.2969
[2017-12-15 06:16:48] Epoch 0205 mean train/dev loss: 121214.7325 / 123958.8047
[2017-12-15 06:16:48] Checkpointing model...
[2017-12-15 06:16:49] Model Checkpointing finished.
[2017-12-15 06:17:52] Epoch 0206 mean train/dev loss: 121223.6875 / 123958.2891
[2017-12-15 06:18:53] Epoch 0207 mean train/dev loss: 121094.5003 / 123957.8125
[2017-12-15 06:19:53] Epoch 0208 mean train/dev loss: 121528.6607 / 123957.2812
[2017-12-15 06:20:54] Epoch 0209 mean train/dev loss: 121189.6287 / 123956.7734
[2017-12-15 06:21:56] Epoch 0210 mean train/dev loss: 121375.6169 / 123956.2578
[2017-12-15 06:21:56] Learning rate decayed by 0.5000
[2017-12-15 06:21:56] Checkpointing model...
[2017-12-15 06:21:57] Model Checkpointing finished.
[2017-12-15 06:22:59] Epoch 0211 mean train/dev loss: 121371.3943 / 123955.7578
[2017-12-15 06:24:01] Epoch 0212 mean train/dev loss: 121337.1500 / 123955.2500
[2017-12-15 06:25:06] Epoch 0213 mean train/dev loss: 121337.1877 / 123954.7344
[2017-12-15 06:26:10] Epoch 0214 mean train/dev loss: 121344.5705 / 123954.2266
[2017-12-15 06:27:14] Epoch 0215 mean train/dev loss: 121297.4941 / 123953.7188
[2017-12-15 06:27:14] Checkpointing model...
[2017-12-15 06:27:14] Model Checkpointing finished.
[2017-12-15 06:28:16] Epoch 0216 mean train/dev loss: 121271.2688 / 123953.2188
[2017-12-15 06:29:18] Epoch 0217 mean train/dev loss: 121509.5820 / 123952.6875
[2017-12-15 06:30:19] Epoch 0218 mean train/dev loss: 121123.6413 / 123952.2109
[2017-12-15 06:31:22] Epoch 0219 mean train/dev loss: 121163.0529 / 123951.6875
[2017-12-15 06:32:21] Epoch 0220 mean train/dev loss: 121269.0960 / 123951.2031
[2017-12-15 06:32:21] Checkpointing model...
[2017-12-15 06:32:21] Model Checkpointing finished.
[2017-12-15 06:33:23] Epoch 0221 mean train/dev loss: 121669.8036 / 123950.6641
[2017-12-15 06:34:26] Epoch 0222 mean train/dev loss: 121322.8724 / 123950.1797
[2017-12-15 06:35:26] Epoch 0223 mean train/dev loss: 121215.0234 / 123949.6484
[2017-12-15 06:36:27] Epoch 0224 mean train/dev loss: 121211.8994 / 123949.1562
[2017-12-15 06:37:27] Epoch 0225 mean train/dev loss: 121313.8584 / 123948.6328
[2017-12-15 06:37:27] Learning rate decayed by 0.5000
[2017-12-15 06:37:27] Checkpointing model...
[2017-12-15 06:37:27] Model Checkpointing finished.
[2017-12-15 06:38:25] Epoch 0226 mean train/dev loss: 121277.0489 / 123948.6328
[2017-12-15 06:39:24] Epoch 0227 mean train/dev loss: 121418.5277 / 123948.6328
[2017-12-15 06:40:20] Epoch 0228 mean train/dev loss: 121592.1221 / 123948.6328
[2017-12-15 06:41:20] Epoch 0229 mean train/dev loss: 121192.3296 / 123948.6328
[2017-12-15 06:42:19] Epoch 0230 mean train/dev loss: 121473.9055 / 123948.6328
[2017-12-15 06:42:19] Checkpointing model...
[2017-12-15 06:42:19] Model Checkpointing finished.
[2017-12-15 06:43:21] Epoch 0231 mean train/dev loss: 121166.1489 / 123948.6328
[2017-12-15 06:44:19] Epoch 0232 mean train/dev loss: 121420.1070 / 123948.6328
[2017-12-15 06:45:19] Epoch 0233 mean train/dev loss: 121311.2830 / 123948.6328
[2017-12-15 06:46:20] Epoch 0234 mean train/dev loss: 121181.5029 / 123948.6328
[2017-12-15 06:47:20] Epoch 0235 mean train/dev loss: 121141.2608 / 123948.6328
[2017-12-15 06:47:20] Checkpointing model...
[2017-12-15 06:47:20] Model Checkpointing finished.
[2017-12-15 06:48:19] Epoch 0236 mean train/dev loss: 121086.5191 / 123948.6328
[2017-12-15 06:49:20] Epoch 0237 mean train/dev loss: 121508.6513 / 123948.6328
[2017-12-15 06:50:23] Epoch 0238 mean train/dev loss: 121066.6468 / 123948.6328
[2017-12-15 06:51:20] Epoch 0239 mean train/dev loss: 121118.2159 / 123948.6328
[2017-12-15 06:52:17] Epoch 0240 mean train/dev loss: 121387.2054 / 123948.6328
[2017-12-15 06:52:17] Learning rate decayed by 0.5000
[2017-12-15 06:52:17] Checkpointing model...
[2017-12-15 06:52:17] Model Checkpointing finished.
[2017-12-15 06:53:19] Epoch 0241 mean train/dev loss: 121125.7031 / 123948.6328
[2017-12-15 06:54:16] Epoch 0242 mean train/dev loss: 121446.4573 / 123948.6328
[2017-12-15 06:55:17] Epoch 0243 mean train/dev loss: 121254.9638 / 123948.6328
[2017-12-15 06:56:18] Epoch 0244 mean train/dev loss: 121370.6086 / 123948.6328
[2017-12-15 06:57:16] Epoch 0245 mean train/dev loss: 121310.1703 / 123948.6328
[2017-12-15 06:57:16] Checkpointing model...
[2017-12-15 06:57:17] Model Checkpointing finished.
[2017-12-15 06:58:16] Epoch 0246 mean train/dev loss: 121391.1497 / 123948.6328
[2017-12-15 06:59:15] Epoch 0247 mean train/dev loss: 121558.9531 / 123948.6328
[2017-12-15 07:00:17] Epoch 0248 mean train/dev loss: 121298.1440 / 123948.6328
[2017-12-15 07:01:17] Epoch 0249 mean train/dev loss: 121660.4279 / 123948.6328
[2017-12-15 07:02:17] Epoch 0250 mean train/dev loss: 121219.2712 / 123948.6328
[2017-12-15 07:02:17] Checkpointing model...
[2017-12-15 07:02:17] Model Checkpointing finished.
[2017-12-15 07:03:15] Epoch 0251 mean train/dev loss: 121121.6615 / 123948.6250
[2017-12-15 07:04:15] Epoch 0252 mean train/dev loss: 121381.0604 / 123948.6328
[2017-12-15 07:05:13] Epoch 0253 mean train/dev loss: 121217.7589 / 123948.6250
[2017-12-15 07:06:11] Epoch 0254 mean train/dev loss: 121481.6696 / 123948.6328
[2017-12-15 07:07:08] Epoch 0255 mean train/dev loss: 121165.1920 / 123948.6250
[2017-12-15 07:07:08] Learning rate decayed by 0.5000
[2017-12-15 07:07:08] Checkpointing model...
[2017-12-15 07:07:09] Model Checkpointing finished.
[2017-12-15 07:08:11] Epoch 0256 mean train/dev loss: 121051.6773 / 123948.6250
[2017-12-15 07:09:11] Epoch 0257 mean train/dev loss: 121090.3737 / 123948.6250
[2017-12-15 07:10:10] Epoch 0258 mean train/dev loss: 121366.2093 / 123948.6250
[2017-12-15 07:11:08] Epoch 0259 mean train/dev loss: 121407.5888 / 123948.6328
[2017-12-15 07:12:06] Epoch 0260 mean train/dev loss: 121146.7178 / 123948.6328
[2017-12-15 07:12:06] Checkpointing model...
[2017-12-15 07:12:06] Model Checkpointing finished.
[2017-12-15 07:13:05] Epoch 0261 mean train/dev loss: 121316.6433 / 123948.6250
[2017-12-15 07:14:05] Epoch 0262 mean train/dev loss: 121270.3927 / 123948.6250
[2017-12-15 07:15:02] Epoch 0263 mean train/dev loss: 121230.5434 / 123948.6250
[2017-12-15 07:16:02] Epoch 0264 mean train/dev loss: 121243.1087 / 123948.6250
[2017-12-15 07:17:00] Epoch 0265 mean train/dev loss: 121066.4976 / 123948.6250
[2017-12-15 07:17:00] Checkpointing model...
[2017-12-15 07:17:00] Model Checkpointing finished.
[2017-12-15 07:17:58] Epoch 0266 mean train/dev loss: 121377.2682 / 123948.6328
[2017-12-15 07:18:56] Epoch 0267 mean train/dev loss: 121126.6016 / 123948.6328
[2017-12-15 07:19:59] Epoch 0268 mean train/dev loss: 121243.7030 / 123948.6250
[2017-12-15 07:20:55] Epoch 0269 mean train/dev loss: 121398.0778 / 123948.6328
[2017-12-15 07:21:55] Epoch 0270 mean train/dev loss: 121259.3860 / 123948.6328
[2017-12-15 07:21:55] Learning rate decayed by 0.5000
[2017-12-15 07:21:55] Checkpointing model...
[2017-12-15 07:21:55] Model Checkpointing finished.
[2017-12-15 07:22:54] Epoch 0271 mean train/dev loss: 121058.0129 / 123948.6328
[2017-12-15 07:23:50] Epoch 0272 mean train/dev loss: 121393.5987 / 123948.6250
[2017-12-15 07:24:51] Epoch 0273 mean train/dev loss: 121450.1567 / 123948.6250
[2017-12-15 07:25:52] Epoch 0274 mean train/dev loss: 121286.1488 / 123948.6328
[2017-12-15 07:26:50] Epoch 0275 mean train/dev loss: 121198.6724 / 123948.6328
[2017-12-15 07:26:50] Checkpointing model...
[2017-12-15 07:26:51] Model Checkpointing finished.
[2017-12-15 07:27:52] Epoch 0276 mean train/dev loss: 121196.0666 / 123948.6328
[2017-12-15 07:28:52] Epoch 0277 mean train/dev loss: 121536.6169 / 123948.6328
[2017-12-15 07:29:51] Epoch 0278 mean train/dev loss: 121609.0654 / 123948.6328
[2017-12-15 07:30:52] Epoch 0279 mean train/dev loss: 121265.7438 / 123948.6250
[2017-12-15 07:31:52] Epoch 0280 mean train/dev loss: 121298.9609 / 123948.6250
[2017-12-15 07:31:52] Checkpointing model...
[2017-12-15 07:31:52] Model Checkpointing finished.
[2017-12-15 07:32:53] Epoch 0281 mean train/dev loss: 121450.9479 / 123948.6328
[2017-12-15 07:33:54] Epoch 0282 mean train/dev loss: 121552.4796 / 123948.6250
[2017-12-15 07:34:52] Epoch 0283 mean train/dev loss: 121393.9415 / 123948.6250
[2017-12-15 07:35:50] Epoch 0284 mean train/dev loss: 121243.8968 / 123948.6250
[2017-12-15 07:36:49] Epoch 0285 mean train/dev loss: 121168.4305 / 123948.6328
[2017-12-15 07:36:49] Learning rate decayed by 0.5000
[2017-12-15 07:36:49] Checkpointing model...
[2017-12-15 07:36:49] Model Checkpointing finished.
[2017-12-15 07:37:48] Epoch 0286 mean train/dev loss: 121264.3492 / 123948.6328
[2017-12-15 07:38:47] Epoch 0287 mean train/dev loss: 121360.5789 / 123948.6328
[2017-12-15 07:39:43] Epoch 0288 mean train/dev loss: 121354.3422 / 123948.6328
[2017-12-15 07:40:40] Epoch 0289 mean train/dev loss: 121268.2304 / 123948.6328
[2017-12-15 07:41:38] Epoch 0290 mean train/dev loss: 121069.5713 / 123948.6328
[2017-12-15 07:41:38] Checkpointing model...
[2017-12-15 07:41:38] Model Checkpointing finished.
[2017-12-15 07:42:36] Epoch 0291 mean train/dev loss: 121520.8136 / 123948.6328
[2017-12-15 07:43:37] Epoch 0292 mean train/dev loss: 121354.9946 / 123948.6328
[2017-12-15 07:43:37] Early stopping training because validation loss did not improve for 40 epochs!
[2017-12-15 07:43:37] 
                       *** Training finished *** 
[2017-12-15 07:43:42] Dev MSE: 123948.6328
[2017-12-15 07:44:22] Experiment lstm.hs_20.nl_2.lr_0.01.wd_0.001.rl_linear logging ended.
